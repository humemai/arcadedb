{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ArcadeDB Python Bindings","text":"<ul> <li> <p> Production Ready</p> <p>Native Python bindings for ArcadeDB with full test coverage</p> <p>Status: \u2705 Production Ready | Tests: 41/41 Passing (100%)</p> </li> <li> <p> Pure Python API</p> <p>Pythonic interface to ArcadeDB's multi-model database</p> <p> Quick Start</p> </li> <li> <p> Multi-Model Database</p> <p>Graph, Document, Key/Value, Vector, Time Series in one database</p> <p> Learn More</p> </li> <li> <p> High Performance</p> <p>Direct JVM integration via JPype for maximum speed</p> <p> Architecture</p> </li> </ul>"},{"location":"#what-is-arcadedb","title":"What is ArcadeDB?","text":"<p>ArcadeDB is a next-generation multi-model database that supports:</p> <ul> <li>Graph: Native property graphs with vertices and edges</li> <li>Document: Schema-less JSON documents</li> <li>Key/Value: Fast key-value pairs</li> <li>Vector: Embeddings with HNSW similarity search</li> <li>Time Series: Temporal data with efficient indexing</li> <li>Search Engine: Full-text search with Lucene</li> </ul>"},{"location":"#why-python-bindings","title":"Why Python Bindings?","text":"<p>These bindings provide native Python access to ArcadeDB's full capabilities:</p> <ul> <li>Embedded Mode: Run database directly in your Python process (no external server)</li> <li>Server Mode: Optional HTTP server with Studio web UI for development</li> <li>Multiple Query Languages: SQL, Cypher, Gremlin (full distribution), MongoDB syntax</li> <li>ACID Transactions: Full transactional guarantees</li> <li>Type Safety: Pythonic API with proper error handling</li> </ul>"},{"location":"#features","title":"Features","text":"<p>Core Features</p> <ul> <li>\ud83d\ude80 Embedded Mode - Direct database access in Python process</li> <li>\ud83c\udf10 Server Mode - Optional HTTP server with Studio UI</li> <li>\ud83d\udce6 Self-contained - All JARs bundled, just needs JRE</li> <li>\ud83d\udd04 Multi-model - Graph, Document, Key/Value, Vector</li> <li>\ud83d\udd0d Multiple languages - SQL, Cypher, Gremlin, MongoDB</li> </ul> <p>Advanced Features</p> <ul> <li>\u26a1 High performance - Direct JVM integration via JPype</li> <li>\ud83d\udd12 ACID transactions - Full transaction support</li> <li>\ud83c\udfaf Vector storage - HNSW indexing for embeddings</li> <li>\ud83d\udce5 Data import - CSV, JSON, JSONL, Neo4j importers</li> <li>\ud83d\udd0e Full-text search - Lucene integration</li> <li>\ud83d\uddfa\ufe0f Geospatial - JTS for spatial queries</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create database (context manager for automatic cleanup)\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    # Create schema\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\n    # Insert data (requires transaction)\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n\n    # Query data\n    result = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n    for record in result:\n        print(f\"Name: {record.get_property('name')}\")\n</code></pre> <p>Resource Management</p> <p>Always use context managers (<code>with</code> statements) for automatic resource cleanup!</p>"},{"location":"#package-coverage","title":"Package Coverage","text":"<p>These bindings provide ~85% coverage of ArcadeDB's Java API, focusing on features most relevant to Python developers:</p> Module Coverage Description Core Operations \u2705 100% Database, queries, transactions Server Mode \u2705 100% HTTP server, Studio UI Vector Search \u2705 100% HNSW indexing, similarity search Data Import \u2705 100% CSV, JSON, JSONL, Neo4j Graph API \u26a0\ufe0f 60% Basic graph operations (Python-relevant subset) Gremlin \u26a0\ufe0f 70% Query execution (full dist only) <p>See Java API Coverage for detailed comparison.</p>"},{"location":"#distribution-options","title":"Distribution Options","text":"<p>Choose the package that fits your needs:</p> Distribution Package Name Size What's Included Studio UI Headless <code>arcadedb-embedded-headless</code> ~94MB SQL, Cypher, PostgreSQL, HTTP \u274c Minimal <code>arcadedb-embedded-minimal</code> ~97MB Headless + Studio UI \u2705 Full <code>arcadedb-embedded</code> ~158MB Minimal + Gremlin, GraphQL \u2705 <p>All distributions use the same import:</p> <pre><code>import arcadedb_embedded as arcadedb\n</code></pre> <p>Choosing a Distribution</p> <ul> <li>Headless: Recommended for production - core database functionality</li> <li>Minimal: Adds Studio UI (~2MB) - great for development</li> <li>Full: Adds Gremlin (~64MB) + GraphQL - only if you need those query languages</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li> <p> Install</p> <p>Installation instructions for all three distributions</p> </li> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes</p> </li> <li> <p> User Guide</p> <p>Comprehensive guide to all features</p> </li> <li> <p> API Reference</p> <p>Detailed API documentation</p> </li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python: 3.8 - 3.12</li> <li>Java: JRE 11+ (OpenJDK recommended)</li> <li>JPype: 1.5.0+ (automatically installed)</li> </ul> <p>Java Required</p> <p>You need Java Runtime Environment (JRE) installed. The wheels bundle all JAR files, but need a JVM to run them.</p> <pre><code># Ubuntu/Debian\nsudo apt-get install default-jre-headless\n\n# macOS\nbrew install openjdk\n\n# Windows\n# Download from https://adoptium.net/\n</code></pre>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub: humemai/arcadedb</li> <li>Issues: Report bugs</li> <li>PyPI: arcadedb-embedded-headless</li> <li>ArcadeDB Docs: docs.arcadedb.com</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache License 2.0 - see LICENSE</p>"},{"location":"java-api-coverage/","title":"Java API Coverage","text":""},{"location":"java-api-coverage/#java-api-coverage-analysis","title":"\ufffd Java API Coverage Analysis","text":"<p>This section provides a comprehensive comparison of the ArcadeDB Java API and what's been implemented in the Python bindings.</p>"},{"location":"java-api-coverage/#executive-summary","title":"Executive Summary","text":"<p>Overall Coverage: ~40-45% of Java API</p> <p>The Python bindings provide excellent coverage for common use cases (~85% of typical operations), but limited coverage of advanced Java-specific APIs (~15-20% of advanced features).</p>"},{"location":"java-api-coverage/#coverage-by-category","title":"Coverage by Category","text":"Category Coverage Status Core Database Operations 85% \u2705 Excellent Query Execution 100% \u2705 Complete Transactions 90% \u2705 Excellent Server Mode 70% \u2705 Good Data Import 30% \u26a0\ufe0f Limited Graph API 10% \u274c Minimal Schema API 0% \u274c Not Implemented Index Management 5% \u274c Minimal Advanced Features 5% \u274c Minimal"},{"location":"java-api-coverage/#detailed-coverage","title":"Detailed Coverage","text":""},{"location":"java-api-coverage/#1-core-database-operations-85","title":"1. Core Database Operations - 85%","text":"<p>DatabaseFactory: - \u2705 <code>create()</code> - Create new database - \u2705 <code>open()</code> - Open existing database - \u2705 <code>exists()</code> - Check if database exists - \u274c <code>setAutoTransaction()</code> - Not exposed (use config) - \u274c <code>setSecurity()</code> - Not exposed (server-managed)</p> <p>Database: - \u2705 <code>query(language, query, *args)</code> - Full support for all query languages - \u2705 <code>command(language, command, *args)</code> - Full support for write operations - \u2705 <code>begin()</code>, <code>commit()</code>, <code>rollback()</code> - Full transaction support - \u2705 <code>transaction()</code> - Python context manager (enhancement) - \u2705 <code>newDocument(type)</code>, <code>newVertex(type)</code> - Record creation - \u2705 <code>getName()</code>, <code>getDatabasePath()</code>, <code>isOpen()</code>, <code>close()</code> - Database info - \u274c <code>scanType()</code>, <code>scanBucket()</code> - Use SQL SELECT instead - \u274c <code>lookupByKey()</code> - Use SQL WHERE clause instead - \u274c <code>async()</code> - Async operations not exposed</p>"},{"location":"java-api-coverage/#2-query-execution-100","title":"2. Query Execution - 100%","text":"<p>All query languages fully supported: - \u2705 SQL - \u2705 Cypher - \u2705 Gremlin (full distribution) - \u2705 MongoDB query syntax - \u2705 GraphQL (full distribution)</p> <p>ResultSet &amp; Results: - \u2705 Pythonic iteration (<code>__iter__</code>, <code>__next__</code>) - \u2705 <code>has_next()</code>, <code>next()</code> - \u2705 <code>get_property()</code>, <code>has_property()</code>, <code>get_property_names()</code> - \u2705 <code>to_json()</code>, <code>to_dict()</code> (Python enhancement)</p>"},{"location":"java-api-coverage/#3-graph-api-10","title":"3. Graph API - 10%","text":"<p>Most graph operations done via SQL/Cypher instead of direct API: - \u2705 <code>db.new_vertex(type)</code> - Vertex creation - \u274c Vertex methods (<code>getEdges()</code>, <code>getVertices()</code>, etc.) - Use Cypher/SQL queries - \u274c Edge methods - Use SQL CREATE EDGE or Cypher - \u274c Graph traversal API - Use Cypher MATCH or SQL traversal</p> <p>Workaround via Queries: <pre><code># Create edges via SQL\ndb.command(\"sql\", \"\"\"\n    CREATE EDGE Follows\n    FROM (SELECT FROM User WHERE id = 1)\n    TO (SELECT FROM User WHERE id = 2)\n\"\"\")\n\n# Or via Cypher\ndb.command(\"cypher\", \"\"\"\n    MATCH (a:User {id: 1}), (b:User {id: 2})\n    CREATE (a)-[:FOLLOWS]-&gt;(b)\n\"\"\")\n\n# Traverse via Cypher\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (user:User {name: 'Alice'})-[:FOLLOWS]-&gt;(friend)\n    RETURN friend.name\n\"\"\")\n</code></pre></p>"},{"location":"java-api-coverage/#4-schema-management-0","title":"4. Schema Management - 0%","text":"<p>All schema operations done via SQL DDL: - \u274c No direct Schema API - \u2705 Use SQL: <code>CREATE VERTEX TYPE User</code> - \u2705 Use SQL: <code>CREATE PROPERTY User.email STRING</code> - \u2705 Use SQL: <code>ALTER PROPERTY User.email MANDATORY true</code> - \u2705 Use SQL: <code>DROP TYPE User</code></p>"},{"location":"java-api-coverage/#5-index-management-5","title":"5. Index Management - 5%","text":"<ul> <li>\u2705 Vector indexes via <code>create_vector_index()</code> - High-level Python API</li> <li>\u274c Type indexes - Use SQL: <code>CREATE INDEX ON User (email) UNIQUE</code></li> <li>\u274c Full-text indexes - Use SQL: <code>CREATE INDEX ON Article (content) FULL_TEXT</code></li> <li>\u274c Composite indexes - Use SQL: <code>CREATE INDEX ON User (name, age) NOTUNIQUE</code></li> </ul>"},{"location":"java-api-coverage/#6-server-mode-70","title":"6. Server Mode - 70%","text":"<ul> <li>\u2705 <code>ArcadeDBServer(root_path, config)</code> - Server initialization</li> <li>\u2705 <code>start()</code>, <code>stop()</code> - Server lifecycle</li> <li>\u2705 <code>get_database()</code>, <code>create_database()</code> - Database management</li> <li>\u2705 Context manager support</li> <li>\u2705 <code>get_studio_url()</code>, <code>get_http_port()</code> - Python enhancements</li> <li>\u274c Plugin management - Not exposed</li> <li>\u274c HA/Replication - Not exposed</li> <li>\u274c Security API - Server-managed only</li> </ul>"},{"location":"java-api-coverage/#7-data-import-30-4-of-14-formats","title":"7. Data Import - 30% (4 of 14 formats)","text":"<p>Supported: - \u2705 CSV - <code>import_csv()</code> - \u2705 JSON - <code>import_json()</code> - \u2705 JSONL - <code>import_jsonl()</code> - \u2705 Neo4j - <code>import_neo4j()</code></p> <p>Not Implemented: - \u274c XML, RDF, OrientDB, GloVe, Word2Vec - \u274c TextEmbeddings, GraphImporter - \u274c SQL import via Importer</p>"},{"location":"java-api-coverage/#8-vector-search-80","title":"8. Vector Search - 80%","text":"<ul> <li>\u2705 HNSW index creation - <code>create_vector_index()</code></li> <li>\u2705 NumPy array support - <code>to_java_float_array()</code>, <code>to_python_array()</code></li> <li>\u2705 Similarity search - <code>index.find_nearest()</code></li> <li>\u2705 Add/remove vectors - <code>index.add_vertex()</code>, <code>index.remove_vertex()</code></li> <li>\u2705 Distance functions - cosine, euclidean, inner_product</li> <li>\u2705 HNSW parameters - m, ef, ef_construction</li> </ul>"},{"location":"java-api-coverage/#9-advanced-features-5","title":"9. Advanced Features - 5%","text":"<p>Not Implemented: - \u274c Callbacks &amp; Events (DocumentCallback, RecordCallback, DatabaseEvents) - \u274c Low-Level APIs (WAL, bucket scanning, binary protocol) - \u274c Async operations &amp; parallel queries - \u274c Security management (SecurityManager, user management) - \u274c High Availability (HAServer, replication) - \u274c Custom query engines - \u274c Schema builders &amp; DSL</p>"},{"location":"java-api-coverage/#design-philosophy-query-first-approach","title":"Design Philosophy: Query-First Approach","text":"<p>The Python bindings follow a \"query-first, API-second\" philosophy, which is ideal for Python developers. Instead of exposing every Java object, operations are enabled through:</p> <ul> <li>SQL DDL for schema management</li> <li>Cypher/SQL for graph operations  </li> <li>High-level wrappers for common tasks (transactions, vector search)</li> </ul> <p>This approach is actually cleaner and more maintainable than direct API exposure:</p> <pre><code># Python way (clean):\ndb.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\ndb.query(\"cypher\", \"MATCH (a)-[:FOLLOWS]-&gt;(b) RETURN b\")\n\n# vs. hypothetical direct API (complex):\nschema = db.getSchema()\ntype = schema.getType(\"User\")\nindex_builder = schema.buildTypeIndex(\"User\", [\"email\"])\nindex = index_builder.withUnique(true).create()\n</code></pre>"},{"location":"java-api-coverage/#use-case-suitability","title":"Use Case Suitability","text":"Use Case Suitable? Notes Embedded database in Python app \u2705 Perfect Core use case Graph analytics with Cypher \u2705 Excellent All query languages work Document store \u2705 Excellent Full SQL support Vector similarity search \u2705 Excellent Native NumPy integration Development with Studio UI \u2705 Excellent Server mode included Data migration (CSV/JSON import) \u2705 Good Most formats covered Real-time event processing \u26a0\ufe0f Limited No async, no callbacks Advanced graph algorithms \u26a0\ufe0f Limited Use Cypher, no direct API Multi-master replication \u274c Not supported Java/Server only Custom query language \u274c Not supported Use built-in languages"},{"location":"java-api-coverage/#conclusion","title":"Conclusion","text":"<p>For 90% of Python developers: These bindings are production-ready and provide everything needed for: - Embedded multi-model database - Graph, document, vector, and time-series data - SQL, Cypher, and Gremlin queries - Development and production deployment</p> <p>Not suitable for: - Applications requiring async/await patterns - Custom database extensions or plugins - Direct manipulation of Graph API objects - High-availability clustering from Python</p> <p>The practical coverage for real-world applications is 85%+, which is excellent. The 40-45% \"total coverage\" number is misleading because it counts low-level Java APIs that Python developers shouldn't use anyway.</p>"},{"location":"java-api-coverage/#future-work","title":"\ufffd\ud83d\udea7 Future Work","text":"<p>This Python binding is actively being developed. Here are the planned improvements:</p>"},{"location":"java-api-coverage/#1-high-level-sql-support-for-vectors","title":"1. High-Level SQL Support for Vectors","text":"<p>Goal: Simplify vector operations with SQL-based API</p> <p>Currently, vector similarity search requires direct interaction with Java APIs (creating HNSW indexes, converting arrays, managing vertices manually). This works but isn't as user-friendly as it could be.</p> <p>Current approach (requires understanding Java internals):</p> <pre><code># Lots of Java API calls\njava_embedding = arcadedb.to_java_float_array(embedding)\nvertex = db._java_db.newVertex(\"Document\")\nvertex.set(\"embedding\", java_embedding)\nindex = db.create_vector_index(...)\n</code></pre> <p>Future approach (with SQL support):</p> <pre><code># Clean SQL-based API\ndb.command(\"sql\", \"\"\"\n    CREATE VECTOR INDEX ON Document(embedding)\n    WITH (dimensions=768, distance='cosine')\n\"\"\")\n\nresult = db.query(\"sql\", \"\"\"\n    SELECT FROM Document\n    WHERE embedding NEAR [0.1, 0.2, ...]\n    LIMIT 10\n\"\"\")\n</code></pre> <p>Once ArcadeDB adds native SQL syntax for vector operations, we'll adapt the Python bindings to expose this cleaner interface.</p>"},{"location":"java-api-coverage/#2-comprehensive-testing-performance-benchmarks","title":"2. Comprehensive Testing &amp; Performance Benchmarks","text":"<p>Goal: Validate stability and performance at scale</p> <p>Current testing covers basic functionality (14/14 tests passing), but we need:</p> <ul> <li>Load testing: Insert/query millions of records</li> <li>Vector performance: Benchmark HNSW search with large datasets (100K+ vectors)</li> <li>Concurrency testing: Multiple transactions, thread safety</li> <li>Memory profiling: Long-running processes, leak detection</li> <li>Platform testing: Verify behavior across Linux, macOS, Windows</li> <li>Python version matrix: Test Python 3.8-3.12</li> </ul> <p>This will ensure production readiness for high-volume applications.</p>"},{"location":"java-api-coverage/#3-upstream-contribution","title":"3. Upstream Contribution","text":"<p>Goal: Merge into official ArcadeDB repository</p> <p>Once the bindings are thoroughly tested and PyPI-ready, we plan to submit a pull request to the official ArcadeDB repository. This will:</p> <ul> <li>Make Python bindings an officially supported feature</li> <li>Ensure long-term maintenance and updates</li> <li>Benefit the broader ArcadeDB community</li> <li>Keep bindings in sync with Java releases</li> </ul> <p>Timeline: Waiting for items 1-3 to be completed and validated before proposing upstream integration.</p>"},{"location":"java-api-coverage/#license","title":"\ud83d\udcdd License","text":"<p>Apache License 2.0</p>"},{"location":"java-api-coverage/#contributing","title":"\ud83d\ude4f Contributing","text":"<p>Contributions welcome! Please:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Run tests: <code>python3 -m pytest tests/ -v</code></li> <li>Submit a pull request</li> </ol>"},{"location":"api/database/","title":"Database API Reference","text":"<p>Complete API reference for working with ArcadeDB databases in Python.</p>"},{"location":"api/database/#module-functions","title":"Module Functions","text":""},{"location":"api/database/#create_database","title":"create_database","text":"<pre><code>arcadedb.create_database(path: str) -&gt; Database\n</code></pre> <p>Create a new database at the specified path.</p> <p>Parameters:</p> <ul> <li><code>path</code> (str): File system path where the database will be created</li> </ul> <p>Returns:</p> <ul> <li><code>Database</code>: Database instance</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If database creation fails or path already exists</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"/tmp/mydb\")\ntry:\n    # Use database\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\nfinally:\n    db.close()\n</code></pre> <p>Use Context Manager</p> <p>Prefer using <code>with</code> statement for automatic cleanup: <pre><code>with arcadedb.create_database(\"/tmp/mydb\") as db:\n    # Database automatically closed on exit\n    pass\n</code></pre></p>"},{"location":"api/database/#open_database","title":"open_database","text":"<pre><code>arcadedb.open_database(path: str) -&gt; Database\n</code></pre> <p>Open an existing database.</p> <p>Parameters:</p> <ul> <li><code>path</code> (str): Path to the existing database</li> </ul> <p>Returns:</p> <ul> <li><code>Database</code>: Database instance</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If database doesn't exist or can't be opened</li> </ul> <p>Example:</p> <pre><code>with arcadedb.open_database(\"/tmp/mydb\") as db:\n    result = db.query(\"sql\", \"SELECT FROM Person\")\n    print(f\"Found {len(result)} records\")\n</code></pre>"},{"location":"api/database/#database_exists","title":"database_exists","text":"<pre><code>arcadedb.database_exists(path: str) -&gt; bool\n</code></pre> <p>Check if a database exists at the given path.</p> <p>Parameters:</p> <ul> <li><code>path</code> (str): Path to check</li> </ul> <p>Returns:</p> <ul> <li><code>bool</code>: True if database exists, False otherwise</li> </ul> <p>Example:</p> <pre><code>if arcadedb.database_exists(\"/tmp/mydb\"):\n    db = arcadedb.open_database(\"/tmp/mydb\")\nelse:\n    db = arcadedb.create_database(\"/tmp/mydb\")\n</code></pre>"},{"location":"api/database/#database-class","title":"Database Class","text":"<p>The main database interface for executing queries, managing transactions, and creating records.</p>"},{"location":"api/database/#constructor","title":"Constructor","text":"<pre><code>Database(java_database)\n</code></pre> <p>Parameters:</p> <ul> <li><code>java_database</code>: Java Database object (internal use - use factory functions instead)</li> </ul> <p>Direct Construction</p> <p>Don't create <code>Database</code> instances directly. Use <code>create_database()</code>, <code>open_database()</code>, or <code>DatabaseFactory</code> instead.</p>"},{"location":"api/database/#query","title":"query","text":"<pre><code>db.query(language: str, command: str, *args) -&gt; ResultSet\n</code></pre> <p>Execute a query and return results. Queries are read-only and don't require a transaction.</p> <p>Parameters:</p> <ul> <li><code>language</code> (str): Query language - <code>\"sql\"</code>, <code>\"cypher\"</code>, <code>\"gremlin\"</code>, <code>\"mongo\"</code>, <code>\"graphql\"</code></li> <li><code>command</code> (str): Query string</li> <li><code>*args</code>: Optional parameters to bind to the query</li> </ul> <p>Returns:</p> <ul> <li><code>ResultSet</code>: Iterable result set</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If query fails or database is closed</li> </ul> <p>Example:</p> <pre><code># Simple query\nresult = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\nfor record in result:\n    print(record.get_property('name'))\n\n# Parameterized query\nresult = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; ?\", 25)\n\n# Cypher query\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (p:Person)-[:Knows]-&gt;(friend)\n    WHERE p.age &gt; $min_age\n    RETURN friend.name\n\"\"\", {\"min_age\": 25})\n</code></pre> <p>Supported Languages:</p> Language Distribution Notes <code>sql</code> All ArcadeDB SQL <code>cypher</code> All OpenCypher graph query language <code>mongo</code> Full MongoDB query syntax <code>gremlin</code> Full Apache TinkerPop traversal <code>graphql</code> Full GraphQL queries"},{"location":"api/database/#command","title":"command","text":"<pre><code>db.command(language: str, command: str, *args) -&gt; Optional[ResultSet]\n</code></pre> <p>Execute a command (write operation). Commands modify data and require a transaction.</p> <p>Parameters:</p> <ul> <li><code>language</code> (str): Command language (usually <code>\"sql\"</code> or <code>\"cypher\"</code>)</li> <li><code>command</code> (str): Command string</li> <li><code>*args</code>: Optional parameters</li> </ul> <p>Returns:</p> <ul> <li><code>ResultSet</code> or <code>None</code>: Result set if command returns data, None otherwise</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If command fails, database is closed, or no transaction is active</li> </ul> <p>Example:</p> <pre><code># Must be in a transaction\nwith db.transaction():\n    # Create type\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\n    # Insert data\n    db.command(\"sql\", \"INSERT INTO Person SET name = ?, age = ?\", \"Alice\", 30)\n\n    # Update data\n    db.command(\"sql\", \"UPDATE Person SET age = 31 WHERE name = 'Alice'\")\n\n    # Delete data\n    db.command(\"sql\", \"DELETE FROM Person WHERE name = 'Alice'\")\n</code></pre> <p>Transaction Required</p> <p>Write operations must be wrapped in a transaction: <pre><code># \u2705 Correct\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n\n# \u274c Will fail\ndb.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n</code></pre></p>"},{"location":"api/database/#transaction","title":"transaction","text":"<pre><code>db.transaction() -&gt; TransactionContext\n</code></pre> <p>Create a transaction context manager.</p> <p>Returns:</p> <ul> <li><code>TransactionContext</code>: Context manager for transaction</li> </ul> <p>Example:</p> <pre><code>with db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob'\")\n    # Automatic commit on success, rollback on exception\n</code></pre> <p>Manual Transaction Control:</p> <pre><code># Alternative: manual control\ndb.begin()\ntry:\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob'\")\n    db.commit()\nexcept Exception as e:\n    db.rollback()\n    raise\n</code></pre>"},{"location":"api/database/#begin","title":"begin","text":"<pre><code>db.begin()\n</code></pre> <p>Begin a new transaction. Prefer using <code>transaction()</code> context manager.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If transaction cannot be started</li> </ul>"},{"location":"api/database/#commit","title":"commit","text":"<pre><code>db.commit()\n</code></pre> <p>Commit the current transaction.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If commit fails or no transaction is active</li> </ul>"},{"location":"api/database/#rollback","title":"rollback","text":"<pre><code>db.rollback()\n</code></pre> <p>Rollback the current transaction.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If rollback fails</li> </ul>"},{"location":"api/database/#new_vertex","title":"new_vertex","text":"<pre><code>db.new_vertex(type_name: str) -&gt; MutableVertex\n</code></pre> <p>Create a new vertex (graph node). Requires a transaction.</p> <p>Parameters:</p> <ul> <li><code>type_name</code> (str): Vertex type name (must be defined in schema)</li> </ul> <p>Returns:</p> <ul> <li><code>MutableVertex</code>: Java vertex object with <code>.set()</code>, <code>.save()</code> methods</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If type doesn't exist or transaction not active</li> </ul> <p>Example:</p> <pre><code>with db.transaction():\n    vertex = db.new_vertex(\"Person\")\n    vertex.set(\"name\", \"Alice\")\n    vertex.set(\"age\", 30)\n    vertex.save()\n\n    print(f\"Created: {vertex.getIdentity()}\")\n</code></pre> <p>Creating Edges</p> <p>There is no <code>db.new_edge()</code> method. Edges are created from vertices: <pre><code>edge = vertex1.newEdge(\"Knows\", vertex2)\nedge.save()\n</code></pre> See Graph Operations for details.</p>"},{"location":"api/database/#new_document","title":"new_document","text":"<pre><code>db.new_document(type_name: str) -&gt; MutableDocument\n</code></pre> <p>Create a new document (non-graph record). Requires a transaction.</p> <p>Parameters:</p> <ul> <li><code>type_name</code> (str): Document type name</li> </ul> <p>Returns:</p> <ul> <li><code>MutableDocument</code>: Java document object</li> </ul> <p>Example:</p> <pre><code>with db.transaction():\n    doc = db.new_document(\"Person\")\n    doc.set(\"name\", \"Alice\")\n    doc.set(\"email\", \"alice@example.com\")\n    doc.save()\n</code></pre>"},{"location":"api/database/#create_vector_index","title":"create_vector_index","text":"<pre><code>db.create_vector_index(\n    vertex_type: str,\n    vector_property: str,\n    dimensions: int,\n    id_property: str = \"id\",\n    edge_type: str = \"VectorProximity\",\n    deleted_property: str = \"deleted\",\n    distance_function: str = \"cosine\",\n    m: int = 16,\n    ef: int = 128,\n    ef_construction: int = 128,\n    max_items: int = 10000\n) -&gt; VectorIndex\n</code></pre> <p>Create an HNSW vector index for similarity search.</p> <p>Parameters:</p> <ul> <li><code>vertex_type</code> (str): Vertex type containing vectors</li> <li><code>vector_property</code> (str): Property storing vector arrays</li> <li><code>dimensions</code> (int): Vector dimensionality</li> <li><code>id_property</code> (str): Unique ID property (default: <code>\"id\"</code>)</li> <li><code>edge_type</code> (str): Edge type for proximity graph (default: <code>\"VectorProximity\"</code>)</li> <li><code>deleted_property</code> (str): Soft delete marker (default: <code>\"deleted\"</code>)</li> <li><code>distance_function</code> (str): <code>\"cosine\"</code>, <code>\"euclidean\"</code>, or <code>\"inner_product\"</code></li> <li><code>m</code> (int): HNSW M parameter - connections per node (default: 16)</li> <li><code>ef</code> (int): Search candidate list size (default: 128)</li> <li><code>ef_construction</code> (int): Construction candidate list size (default: 128)</li> <li><code>max_items</code> (int): Maximum index size (default: 10000)</li> </ul> <p>Returns:</p> <ul> <li><code>VectorIndex</code>: Index object for similarity search</li> </ul> <p>Example:</p> <pre><code>import numpy as np\n\n# Create schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.id STRING\")\n\n# Create vector index\nindex = db.create_vector_index(\"Document\", \"embedding\", dimensions=384)\n\n# Add vectors\nwith db.transaction():\n    for i, embedding in enumerate(embeddings):\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"id\", f\"doc_{i}\")\n        vertex.set(\"embedding\", arcadedb.to_java_float_array(embedding))\n        vertex.save()\n        index.add_vertex(vertex)\n\n# Search\nquery_vector = np.random.rand(384)\nresults = index.find_nearest(query_vector, k=5)\n</code></pre> <p>See Vector Search Guide for details.</p>"},{"location":"api/database/#close","title":"close","text":"<pre><code>db.close()\n</code></pre> <p>Close the database connection.</p> <p>Example:</p> <pre><code>db = arcadedb.create_database(\"/tmp/mydb\")\ntry:\n    # Use database\n    pass\nfinally:\n    db.close()\n</code></pre> <p>Context Manager</p> <p>Prefer using <code>with</code> statement for automatic cleanup</p>"},{"location":"api/database/#is_open","title":"is_open","text":"<pre><code>db.is_open() -&gt; bool\n</code></pre> <p>Check if database connection is open.</p> <p>Returns:</p> <ul> <li><code>bool</code>: True if database is open</li> </ul>"},{"location":"api/database/#get_name","title":"get_name","text":"<pre><code>db.get_name() -&gt; str\n</code></pre> <p>Get the database name.</p> <p>Returns:</p> <ul> <li><code>str</code>: Database name</li> </ul>"},{"location":"api/database/#get_database_path","title":"get_database_path","text":"<pre><code>db.get_database_path() -&gt; str\n</code></pre> <p>Get the file system path to the database.</p> <p>Returns:</p> <ul> <li><code>str</code>: Database path</li> </ul>"},{"location":"api/database/#databasefactory-class","title":"DatabaseFactory Class","text":"<p>Factory for creating and opening databases with custom configuration.</p>"},{"location":"api/database/#constructor_1","title":"Constructor","text":"<pre><code>DatabaseFactory(path: str)\n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code> (str): Database path</li> </ul> <p>Example:</p> <pre><code>factory = arcadedb.DatabaseFactory(\"/tmp/mydb\")\nif factory.exists():\n    db = factory.open()\nelse:\n    db = factory.create()\n</code></pre>"},{"location":"api/database/#create","title":"create","text":"<pre><code>factory.create() -&gt; Database\n</code></pre> <p>Create a new database.</p>"},{"location":"api/database/#open","title":"open","text":"<pre><code>factory.open() -&gt; Database\n</code></pre> <p>Open an existing database.</p>"},{"location":"api/database/#exists","title":"exists","text":"<pre><code>factory.exists() -&gt; bool\n</code></pre> <p>Check if database exists.</p>"},{"location":"api/database/#context-manager-support","title":"Context Manager Support","text":"<p>All database objects support context managers:</p> <pre><code># Database\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    # Automatic cleanup\n    pass\n\n# Transaction\nwith db.transaction():\n    # Auto commit/rollback\n    pass\n</code></pre>"},{"location":"api/database/#query-languages","title":"Query Languages","text":""},{"location":"api/database/#sql","title":"SQL","text":"<p>ArcadeDB's extended SQL with graph and document support:</p> <pre><code># Documents\ndb.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n\n# Graph traversal\ndb.query(\"sql\", \"SELECT expand(out('Knows')) FROM Person WHERE name = 'Alice'\")\n\n# Aggregation\ndb.query(\"sql\", \"SELECT count(*) as total, avg(age) as avg_age FROM Person\")\n</code></pre>"},{"location":"api/database/#cypher","title":"Cypher","text":"<p>OpenCypher graph query language:</p> <pre><code>db.query(\"cypher\", \"\"\"\n    MATCH (person:Person)-[:Knows]-&gt;(friend)\n    WHERE person.age &gt; 25\n    RETURN friend.name, friend.age\n\"\"\")\n</code></pre>"},{"location":"api/database/#gremlin-full-distribution","title":"Gremlin (Full Distribution)","text":"<p>Apache TinkerPop graph traversals:</p> <pre><code>db.query(\"gremlin\", \"\"\"\n    g.V().has('Person', 'name', 'Alice')\n        .out('Knows')\n        .values('name')\n\"\"\")\n</code></pre>"},{"location":"api/database/#mongodb-full-distribution","title":"MongoDB (Full Distribution)","text":"<p>MongoDB query syntax:</p> <pre><code>db.query(\"mongo\", \"\"\"{\n    find: 'Person',\n    filter: { age: { $gt: 25 } }\n}\"\"\")\n</code></pre>"},{"location":"api/database/#error-handling","title":"Error Handling","text":"<p>All database operations can raise <code>ArcadeDBError</code>:</p> <pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    with arcadedb.create_database(\"/tmp/mydb\") as db:\n        db.command(\"sql\", \"INVALID SQL\")\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"api/database/#best-practices","title":"Best Practices","text":""},{"location":"api/database/#1-use-context-managers","title":"1. Use Context Managers","text":"<pre><code># \u2705 Good - automatic cleanup\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    pass\n\n# \u274c Avoid - manual cleanup\ndb = arcadedb.create_database(\"/tmp/mydb\")\ndb.close()\n</code></pre>"},{"location":"api/database/#2-always-use-transactions-for-writes","title":"2. Always Use Transactions for Writes","text":"<pre><code># \u2705 Good\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n\n# \u274c Will fail\ndb.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n</code></pre>"},{"location":"api/database/#3-use-parameterized-queries","title":"3. Use Parameterized Queries","text":"<pre><code># \u2705 Good - safe from injection\nname = user_input\ndb.query(\"sql\", \"SELECT FROM Person WHERE name = ?\", name)\n\n# \u274c Dangerous - SQL injection risk\ndb.query(\"sql\", f\"SELECT FROM Person WHERE name = '{user_input}'\")\n</code></pre>"},{"location":"api/database/#4-check-database-existence","title":"4. Check Database Existence","text":"<pre><code>if arcadedb.database_exists(\"/tmp/mydb\"):\n    db = arcadedb.open_database(\"/tmp/mydb\")\nelse:\n    db = arcadedb.create_database(\"/tmp/mydb\")\n</code></pre>"},{"location":"api/database/#see-also","title":"See Also","text":"<ul> <li>Graph Operations: Working with vertices and edges</li> <li>Vector Search: Similarity search with HNSW indexes</li> <li>Server Mode: HTTP API and Studio UI</li> <li>Quick Start: Getting started guide</li> </ul>"},{"location":"api/exceptions/","title":"Exceptions API","text":"<p>The <code>ArcadeDBError</code> exception is the base class for all errors raised by the ArcadeDB Python bindings. It wraps underlying Java exceptions and provides Pythonic error handling.</p>"},{"location":"api/exceptions/#overview","title":"Overview","text":"<p>All errors from ArcadeDB operations raise <code>ArcadeDBError</code> or its subclasses (currently just the base class). This provides a single exception type to catch for all ArcadeDB-related errors.</p> <p>Error Sources:</p> <ul> <li>Schema violations: Type mismatches, constraint failures, missing properties</li> <li>Transaction errors: Concurrent modifications, commit failures, rollbacks</li> <li>Query errors: Syntax errors, invalid queries, type errors</li> <li>Database errors: File I/O errors, corruption, not found</li> <li>Server errors: Connection failures, authentication errors, port conflicts</li> <li>Resource errors: Out of memory, too many open files</li> </ul>"},{"location":"api/exceptions/#arcadedberror-class","title":"ArcadeDBError Class","text":"<pre><code>class ArcadeDBError(Exception):\n    \"\"\"Base exception for ArcadeDB errors.\"\"\"\n    pass\n</code></pre> <p>Inheritance: <code>Exception</code> \u2192 <code>ArcadeDBError</code></p> <p>Usage:</p> <pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    # ArcadeDB operation\n    db.query(\"sql\", \"INVALID SYNTAX\")\nexcept ArcadeDBError as e:\n    print(f\"Database error: {e}\")\n</code></pre>"},{"location":"api/exceptions/#common-error-patterns","title":"Common Error Patterns","text":""},{"location":"api/exceptions/#database-not-found","title":"Database Not Found","text":"<pre><code>from arcadedb_embedded import ArcadeDBError, open_database\n\ntry:\n    db = open_database(\"./nonexistent_db\")\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\n    # Error: Database does not exist: ./nonexistent_db\n</code></pre> <p>Solution: Use <code>database_exists()</code> to check first, or use <code>create_database()</code>.</p>"},{"location":"api/exceptions/#query-syntax-error","title":"Query Syntax Error","text":"<pre><code>try:\n    result = db.query(\"sql\", \"SELCT FROM Person\")  # Typo: SELCT\nexcept ArcadeDBError as e:\n    print(f\"Query error: {e}\")\n    # Query error: ... syntax error near 'SELCT'\n</code></pre> <p>Solution: Check query syntax, use proper SQL/Cypher/Gremlin.</p>"},{"location":"api/exceptions/#schema-constraint-violation","title":"Schema Constraint Violation","text":"<pre><code># Assuming User.email has UNIQUE constraint\ntry:\n    with db.transaction():\n        user1 = db.new_document(\"User\")\n        user1.set(\"email\", \"alice@example.com\")\n        user1.save()\n\n        user2 = db.new_document(\"User\")\n        user2.set(\"email\", \"alice@example.com\")  # Duplicate!\n        user2.save()\n\nexcept ArcadeDBError as e:\n    print(f\"Constraint violation: {e}\")\n    # Constraint violation: ... duplicate key ... email\n</code></pre> <p>Solution: Check for existing records before insert, handle duplicates gracefully.</p>"},{"location":"api/exceptions/#type-mismatch","title":"Type Mismatch","text":"<pre><code># Assuming Person.age is INTEGER\ntry:\n    with db.transaction():\n        person = db.new_document(\"Person\")\n        person.set(\"age\", \"not a number\")  # Wrong type!\n        person.save()\n\nexcept ArcadeDBError as e:\n    print(f\"Type error: {e}\")\n    # Type error: ... cannot convert 'not a number' to INTEGER\n</code></pre> <p>Solution: Ensure data types match schema definitions.</p>"},{"location":"api/exceptions/#transaction-error","title":"Transaction Error","text":"<pre><code>try:\n    # Start transaction\n    db.begin()\n\n    doc = db.new_document(\"Test\")\n    doc.set(\"data\", \"value\")\n    doc.save()\n\n    # Try to start another (not allowed)\n    db.begin()  # Error!\n\nexcept ArcadeDBError as e:\n    print(f\"Transaction error: {e}\")\n    db.rollback()\n</code></pre> <p>Solution: Use context managers (<code>with db.transaction()</code>) to avoid manual transaction management errors.</p>"},{"location":"api/exceptions/#property-not-found","title":"Property Not Found","text":"<pre><code>try:\n    result = db.query(\"sql\", \"SELECT FROM Person LIMIT 1\")\n    person = result.next()\n\n    # Property might not exist\n    phone = person.get_property(\"phone_number\")  # Typo or missing\n\nexcept ArcadeDBError as e:\n    print(f\"Property error: {e}\")\n</code></pre> <p>Solution: Use <code>has_property()</code> before accessing, or handle exceptions.</p>"},{"location":"api/exceptions/#server-already-running","title":"Server Already Running","text":"<pre><code>from arcadedb_embedded import create_server, ArcadeDBError\n\nserver = create_server()\nserver.start()\n\ntry:\n    server.start()  # Already started!\nexcept ArcadeDBError as e:\n    print(f\"Server error: {e}\")\n    # Server error: Server is already started\nfinally:\n    server.stop()\n</code></pre> <p>Solution: Check <code>server.is_started()</code> before calling <code>start()</code>.</p>"},{"location":"api/exceptions/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>try:\n    server = create_server(config={\"http_port\": 2480})\n    server.start()\nexcept ArcadeDBError as e:\n    if \"bind\" in str(e).lower() or \"port\" in str(e).lower():\n        print(\"Port 2480 is already in use\")\n        print(\"Try a different port or stop conflicting process\")\n    else:\n        print(f\"Server error: {e}\")\n</code></pre> <p>Solution: Use a different port or stop the process using port 2480.</p>"},{"location":"api/exceptions/#error-handling-best-practices","title":"Error Handling Best Practices","text":""},{"location":"api/exceptions/#specific-error-handling","title":"Specific Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    db = open_database(\"./mydb\")\n    result = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n\nexcept ArcadeDBError as e:\n    error_msg = str(e).lower()\n\n    if \"does not exist\" in error_msg:\n        print(\"Database not found - creating new one\")\n        db = create_database(\"./mydb\")\n\n    elif \"syntax\" in error_msg:\n        print(\"Query syntax error - check your SQL\")\n\n    elif \"constraint\" in error_msg:\n        print(\"Constraint violation - check your data\")\n\n    else:\n        print(f\"Unknown error: {e}\")\n        raise\n</code></pre>"},{"location":"api/exceptions/#transaction-error-handling","title":"Transaction Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ndef safe_insert(db, record_data):\n    \"\"\"Insert with automatic retry on concurrent modification.\"\"\"\n    max_retries = 3\n\n    for attempt in range(max_retries):\n        try:\n            with db.transaction():\n                doc = db.new_document(\"Record\")\n                for key, value in record_data.items():\n                    doc.set(key, value)\n                doc.save()\n\n            return True  # Success\n\n        except ArcadeDBError as e:\n            if \"concurrent\" in str(e).lower() and attempt &lt; max_retries - 1:\n                # Retry on concurrent modification\n                import time\n                time.sleep(0.1 * (attempt + 1))\n                continue\n            else:\n                # Other error or max retries exceeded\n                raise\n\n    return False\n\n# Usage\ntry:\n    success = safe_insert(db, {\"name\": \"Alice\", \"age\": 30})\n    if success:\n        print(\"Insert successful\")\nexcept ArcadeDBError as e:\n    print(f\"Insert failed: {e}\")\n</code></pre>"},{"location":"api/exceptions/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ndef get_user_safely(db, email):\n    \"\"\"Get user with fallback on error.\"\"\"\n    try:\n        result = db.query(\"sql\", f\"SELECT FROM User WHERE email = '{email}'\")\n        if result.has_next():\n            return result.next()\n        else:\n            return None\n\n    except ArcadeDBError as e:\n        print(f\"Warning: Database query failed: {e}\")\n        # Return None or default value instead of crashing\n        return None\n\n# Usage\nuser = get_user_safely(db, \"alice@example.com\")\nif user:\n    print(f\"Found user: {user.get_property('name')}\")\nelse:\n    print(\"User not found or error occurred\")\n</code></pre>"},{"location":"api/exceptions/#cleanup-on-error","title":"Cleanup on Error","text":"<pre><code>from arcadedb_embedded import ArcadeDBError, create_server\n\nserver = None\ndb = None\n\ntry:\n    # Start server\n    server = create_server()\n    server.start()\n\n    # Create database\n    db = server.create_database(\"temp_db\")\n\n    # Do work\n    with db.transaction():\n        doc = db.new_document(\"Test\")\n        doc.set(\"data\", \"value\")\n        doc.save()\n\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\n\nfinally:\n    # Always cleanup\n    if db:\n        db.close()\n    if server and server.is_started():\n        server.stop()\n    print(\"Cleanup complete\")\n</code></pre>"},{"location":"api/exceptions/#logging-errors","title":"Logging Errors","text":"<pre><code>import logging\nfrom arcadedb_embedded import ArcadeDBError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    with db.transaction():\n        # Complex operation\n        result = db.query(\"sql\", \"SELECT FROM LargeTable\")\n        for record in result:\n            process(record)\n\nexcept ArcadeDBError as e:\n    logger.error(f\"Database operation failed: {e}\", exc_info=True)\n    # Log includes full stack trace\n    raise\n</code></pre>"},{"location":"api/exceptions/#complete-error-handling-example","title":"Complete Error Handling Example","text":"<pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import ArcadeDBError\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef safe_database_operation():\n    \"\"\"Comprehensive error handling example.\"\"\"\n    db = None\n\n    try:\n        # Check if database exists\n        if not arcadedb.database_exists(\"./mydb\"):\n            logger.info(\"Database not found - creating\")\n            db = arcadedb.create_database(\"./mydb\")\n\n            # Initialize schema\n            with db.transaction():\n                db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n                db.command(\"sql\", \"CREATE PROPERTY Person.name STRING\")\n                db.command(\"sql\", \"CREATE PROPERTY Person.email STRING\")\n                db.command(\"sql\", \"CREATE INDEX ON Person (email) UNIQUE\")\n        else:\n            db = arcadedb.open_database(\"./mydb\")\n\n        # Insert records with error handling\n        people = [\n            {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n            {\"name\": \"Bob\", \"email\": \"bob@example.com\"},\n            {\"name\": \"Charlie\", \"email\": \"alice@example.com\"},  # Duplicate!\n        ]\n\n        success_count = 0\n        error_count = 0\n\n        for person in people:\n            try:\n                with db.transaction():\n                    doc = db.new_document(\"Person\")\n                    doc.set(\"name\", person[\"name\"])\n                    doc.set(\"email\", person[\"email\"])\n                    doc.save()\n\n                success_count += 1\n                logger.info(f\"Inserted: {person['name']}\")\n\n            except ArcadeDBError as e:\n                error_count += 1\n                error_msg = str(e).lower()\n\n                if \"duplicate\" in error_msg or \"unique\" in error_msg:\n                    logger.warning(f\"Skipped duplicate: {person['email']}\")\n                else:\n                    logger.error(f\"Failed to insert {person['name']}: {e}\")\n\n        logger.info(f\"Completed: {success_count} success, {error_count} errors\")\n\n        # Query with error handling\n        try:\n            result = db.query(\"sql\", \"SELECT * FROM Person\")\n            count = len(list(result))\n            logger.info(f\"Total people in database: {count}\")\n        except ArcadeDBError as e:\n            logger.error(f\"Query failed: {e}\")\n\n        return True\n\n    except ArcadeDBError as e:\n        logger.error(f\"Database operation failed: {e}\", exc_info=True)\n        return False\n\n    finally:\n        if db:\n            try:\n                db.close()\n                logger.info(\"Database closed successfully\")\n            except ArcadeDBError as e:\n                logger.error(f\"Error closing database: {e}\")\n\n# Run\nif __name__ == \"__main__\":\n    success = safe_database_operation()\n    if success:\n        print(\"Operation completed successfully\")\n    else:\n        print(\"Operation failed - check logs\")\n</code></pre>"},{"location":"api/exceptions/#debugging-tips","title":"Debugging Tips","text":""},{"location":"api/exceptions/#print-full-exception-details","title":"Print Full Exception Details","text":"<pre><code>import traceback\nfrom arcadedb_embedded import ArcadeDBError\n\ntry:\n    db.query(\"sql\", \"INVALID QUERY\")\nexcept ArcadeDBError as e:\n    print(\"Error occurred:\")\n    print(f\"  Message: {e}\")\n    print(f\"  Type: {type(e).__name__}\")\n    print(\"\\nFull traceback:\")\n    traceback.print_exc()\n</code></pre>"},{"location":"api/exceptions/#check-java-exception","title":"Check Java Exception","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    # Operation that might fail\n    db.query(\"sql\", \"SELECT FROM NonExistentType\")\nexcept ArcadeDBError as e:\n    print(f\"Python error: {e}\")\n\n    # The __cause__ attribute contains the original Java exception\n    if e.__cause__:\n        print(f\"Java cause: {e.__cause__}\")\n        print(f\"Java type: {type(e.__cause__).__name__}\")\n</code></pre>"},{"location":"api/exceptions/#validate-before-operations","title":"Validate Before Operations","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ndef validate_schema(db, type_name, properties):\n    \"\"\"Validate schema before operations.\"\"\"\n    try:\n        # Check if type exists\n        schema_info = db.command(\"sql\", f\"SELECT FROM schema:types WHERE name = '{type_name}'\")\n\n        if not schema_info:\n            raise ValueError(f\"Type {type_name} does not exist\")\n\n        # Check if properties exist\n        for prop in properties:\n            result = db.command(\"sql\", \n                f\"SELECT FROM schema:properties WHERE type = '{type_name}' AND name = '{prop}'\")\n            if not result:\n                raise ValueError(f\"Property {type_name}.{prop} does not exist\")\n\n        return True\n\n    except ArcadeDBError as e:\n        print(f\"Schema validation error: {e}\")\n        return False\n\n# Usage\nif validate_schema(db, \"Person\", [\"name\", \"email\"]):\n    # Safe to proceed\n    with db.transaction():\n        person = db.new_document(\"Person\")\n        person.set(\"name\", \"Alice\")\n        person.set(\"email\", \"alice@example.com\")\n        person.save()\n</code></pre>"},{"location":"api/exceptions/#error-categories","title":"Error Categories","text":""},{"location":"api/exceptions/#schema-errors","title":"Schema Errors","text":"<ul> <li>Type doesn't exist</li> <li>Property doesn't exist</li> <li>Type mismatch (e.g., string \u2192 integer)</li> <li>Constraint violation (unique, mandatory, etc.)</li> </ul> <p>Prevention:</p> <ul> <li>Define schema upfront with <code>CREATE TYPE</code></li> <li>Use schema validation before operations</li> <li>Handle type conversion explicitly</li> </ul>"},{"location":"api/exceptions/#transaction-errors","title":"Transaction Errors","text":"<ul> <li>Transaction already active</li> <li>No active transaction</li> <li>Concurrent modification</li> <li>Commit failure</li> <li>Rollback failure</li> </ul> <p>Prevention:</p> <ul> <li>Use context managers (<code>with db.transaction()</code>)</li> <li>Keep transactions short</li> <li>Implement retry logic for concurrent modifications</li> </ul>"},{"location":"api/exceptions/#query-errors","title":"Query Errors","text":"<ul> <li>Syntax errors</li> <li>Invalid language</li> <li>Type not found</li> <li>Invalid property reference</li> <li>Invalid function usage</li> </ul> <p>Prevention:</p> <ul> <li>Validate queries with test data first</li> <li>Use parameterized queries when possible</li> <li>Test query syntax in Studio UI</li> </ul>"},{"location":"api/exceptions/#resource-errors","title":"Resource Errors","text":"<ul> <li>Database not found</li> <li>Database already exists</li> <li>Cannot create database</li> <li>File I/O errors</li> <li>Out of memory</li> </ul> <p>Prevention:</p> <ul> <li>Check <code>database_exists()</code> before operations</li> <li>Ensure sufficient disk space</li> <li>Use appropriate batch sizes for imports</li> </ul>"},{"location":"api/exceptions/#server-errors","title":"Server Errors","text":"<ul> <li>Server already running</li> <li>Port in use</li> <li>Cannot bind to address</li> <li>Database not accessible</li> </ul> <p>Prevention:</p> <ul> <li>Check <code>is_started()</code> before operations</li> <li>Use available ports</li> <li>Ensure proper permissions</li> </ul>"},{"location":"api/exceptions/#see-also","title":"See Also","text":"<ul> <li>Database API - Database operations that may raise errors</li> <li>Transactions API - Transaction error handling</li> <li>Server API - Server-related errors</li> <li>Troubleshooting Guide - Common issues and solutions</li> </ul>"},{"location":"api/importer/","title":"Importer API","text":"<p>The <code>Importer</code> class and convenience functions provide high-performance data import capabilities for ArcadeDB, supporting multiple formats including JSON, JSONL, CSV, and Neo4j exports.</p>"},{"location":"api/importer/#overview","title":"Overview","text":"<p>The importer uses streaming parsers for memory efficiency and performs batch transactions (default 1000 records per commit) for optimal performance. It can import data as documents, vertices, or edges depending on your schema needs.</p> <p>Supported Formats: - JSON: Single or multiple objects - JSONL: Line-delimited JSON (one object per line) - CSV/TSV: Comma or tab-separated values - Neo4j: JSONL export format from Neo4j</p>"},{"location":"api/importer/#module-functions","title":"Module Functions","text":"<p>Convenience functions for common import tasks without creating an <code>Importer</code> instance:</p>"},{"location":"api/importer/#import_jsondatabase-file_path-options","title":"<code>import_json(database, file_path, **options)</code>","text":"<p>Import a JSON file containing one or more objects.</p> <p>Parameters: - <code>database</code> (Database): Database instance to import into - <code>file_path</code> (str): Path to JSON file - <code>**options</code>: Additional options   - <code>commit_every</code> (int): Records per transaction (default: 1000)   - <code>mapping</code> (Dict): JSON path to database type mappings (optional)</p> <p>Returns: - <code>Dict[str, Any]</code>: Import statistics with keys:   - <code>documents</code>: Number of documents imported   - <code>vertices</code>: Number of vertices imported   - <code>edges</code>: Number of edges imported   - <code>errors</code>: Number of errors encountered   - <code>duration_ms</code>: Import duration in milliseconds</p> <p>Example: <pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./mydb\")\nstats = arcadedb.import_json(db, \"data.json\")\nprint(f\"Imported {stats['documents']} documents in {stats['duration_ms']}ms\")\n</code></pre></p>"},{"location":"api/importer/#import_jsonldatabase-file_path-type_name-options","title":"<code>import_jsonl(database, file_path, type_name, **options)</code>","text":"<p>Import a JSONL (line-delimited JSON) file where each line is a separate JSON object.</p> <p>Parameters: - <code>database</code> (Database): Database instance - <code>file_path</code> (str): Path to JSONL file - <code>type_name</code> (str): Target document/vertex type name - <code>**options</code>: Additional options   - <code>commit_every</code> (int): Records per transaction (default: 1000)   - <code>vertex_type</code> (str): Import as vertices instead of documents (optional)   - <code>parse_rids</code> (bool): Parse RID references (default: True)</p> <p>Returns: - <code>Dict[str, Any]</code>: Import statistics</p> <p>Example: <pre><code># Import as documents\nstats = arcadedb.import_jsonl(db, \"users.jsonl\", \"User\")\n\n# Import as vertices\nstats = arcadedb.import_jsonl(\n    db, \"people.jsonl\", \"Person\",\n    vertex_type=\"Person\"\n)\n</code></pre></p>"},{"location":"api/importer/#import_csvdatabase-file_path-type_name-options","title":"<code>import_csv(database, file_path, type_name, **options)</code>","text":"<p>Import CSV or TSV files as documents, vertices, or edges.</p> <p>Parameters: - <code>database</code> (Database): Database instance - <code>file_path</code> (str): Path to CSV file - <code>type_name</code> (str): Target type name - <code>**options</code>: Format-specific options   - <code>delimiter</code> (str): Field delimiter (default: ',', use '\\t' for TSV)   - <code>header</code> (bool): File has header row (default: True)   - <code>commit_every</code> (int): Records per transaction (default: 1000)   - <code>vertex_type</code> (str): Import as vertices (optional)   - <code>edge_type</code> (str): Import as edges (optional)   - <code>from_property</code> (str): Source column for edges (default: 'from')   - <code>to_property</code> (str): Target column for edges (default: 'to')   - <code>verbose</code> (bool): Print errors during import (default: False)</p> <p>Returns: - <code>Dict[str, Any]</code>: Import statistics</p> <p>Examples:</p> <p>Import as Documents: <pre><code>stats = arcadedb.import_csv(db, \"people.csv\", \"Person\")\n</code></pre></p> <p>Import as Vertices: <pre><code>stats = arcadedb.import_csv(\n    db, \"users.csv\", \"User\",\n    vertex_type=\"User\",\n    commit_every=500\n)\n</code></pre></p> <p>Import as Edges: <pre><code># CSV must have columns for source and target RIDs\nstats = arcadedb.import_csv(\n    db, \"follows.csv\", \"Follows\",\n    edge_type=\"Follows\",\n    from_property=\"user_rid\",  # Column containing source RID\n    to_property=\"follows_rid\",  # Column containing target RID\n    header=True\n)\n</code></pre></p> <p>Import TSV: <pre><code>stats = arcadedb.import_csv(\n    db, \"data.tsv\", \"Data\",\n    delimiter='\\t'\n)\n</code></pre></p>"},{"location":"api/importer/#import_neo4jdatabase-file_path-options","title":"<code>import_neo4j(database, file_path, **options)</code>","text":"<p>Import Neo4j JSONL export files (created with <code>neo4j-admin export</code>).</p> <p>Parameters: - <code>database</code> (Database): Database instance - <code>file_path</code> (str): Path to Neo4j export file - <code>**options</code>: Additional options   - <code>commit_every</code> (int): Records per transaction (default: 1000)   - <code>verbose</code> (bool): Show detailed progress (default: False)</p> <p>Returns: - <code>Dict[str, Any]</code>: Import statistics</p> <p>Example: <pre><code>stats = arcadedb.import_neo4j(db, \"neo4j_export.jsonl\", verbose=True)\nprint(f\"Imported {stats['vertices']} vertices and {stats['edges']} edges\")\n</code></pre></p> <p>Note: Neo4j imports use Java's <code>Neo4jImporter</code> which performs a 3-pass import: 1. Schema analysis 2. Vertex import 3. Edge import</p>"},{"location":"api/importer/#importer-class","title":"Importer Class","text":"<p>For more control over the import process, use the <code>Importer</code> class directly.</p>"},{"location":"api/importer/#importerdatabase","title":"<code>Importer(database)</code>","text":"<p>Constructor:</p> <p>Parameters: - <code>database</code> (Database): Database instance to import into</p> <p>Example: <pre><code>from arcadedb_embedded import Importer\n\ndb = arcadedb.open_database(\"./mydb\")\nimporter = Importer(db)\n</code></pre></p>"},{"location":"api/importer/#import_filefile_path-format_typenone-type_namenone-commit_every1000-options","title":"<code>import_file(file_path, format_type=None, type_name=None, commit_every=1000, **options)</code>","text":"<p>Import data from a file with auto-detection or explicit format specification.</p> <p>Parameters: - <code>file_path</code> (str): Path to file to import - <code>format_type</code> (Optional[str]): Format type ('json', 'jsonl', 'csv', 'neo4j')   - If None, auto-detects from file extension:     - <code>.json</code> \u2192 'json'     - <code>.jsonl</code>, <code>.txt</code> \u2192 'jsonl'     - <code>.csv</code>, <code>.tsv</code> \u2192 'csv' - <code>type_name</code> (Optional[str]): Target type name (required for CSV/JSONL) - <code>commit_every</code> (int): Records per transaction (default: 1000) - <code>**options</code>: Format-specific options (see individual format documentation)</p> <p>Returns: - <code>Dict[str, Any]</code>: Import statistics</p> <p>Raises: - <code>ArcadeDBError</code>: If file not found, format unsupported, or import fails</p> <p>Example: <pre><code>importer = Importer(db)\n\n# Auto-detect format from extension\nstats = importer.import_file(\"data.json\")\nstats = importer.import_file(\"users.csv\", type_name=\"User\")\n\n# Explicit format\nstats = importer.import_file(\n    \"data.txt\",\n    format_type='jsonl',\n    type_name=\"Record\"\n)\n</code></pre></p>"},{"location":"api/importer/#format-specific-details","title":"Format-Specific Details","text":""},{"location":"api/importer/#json-format","title":"JSON Format","text":"<p>File Structure: - Single JSON object: <code>{...}</code> - Array of objects: <code>[{...}, {...}]</code> - Multiple root objects: <code>{...}\\n{...}</code></p> <p>Options: - <code>mapping</code> (Dict): Map JSON paths to database types (advanced)</p> <p>Type Inference: The importer uses Java's <code>JSONImporterFormat</code> which automatically creates schema based on JSON structure.</p> <p>Example: <pre><code># data.json:\n# [\n#   {\"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\"},\n#   {\"name\": \"Bob\", \"age\": 25, \"city\": \"LA\"}\n# ]\n\nstats = arcadedb.import_json(db, \"data.json\", commit_every=1000)\n</code></pre></p>"},{"location":"api/importer/#jsonl-format","title":"JSONL Format","text":"<p>File Structure: Each line is a complete JSON object: <pre><code>{\"id\": 1, \"name\": \"Alice\"}\n{\"id\": 2, \"name\": \"Bob\"}\n</code></pre></p> <p>Options: - <code>vertex_type</code> (str): Import as vertices instead of documents - <code>parse_rids</code> (bool): Parse RID string references (default: True)</p> <p>Type Inference: Values are converted to Python types: - Strings remain strings - Numbers remain numbers - Booleans remain booleans - Objects/arrays remain as-is</p> <p>Example: <pre><code># Import as documents\nstats = arcadedb.import_jsonl(db, \"events.jsonl\", \"Event\")\n\n# Import as vertices for graph data\nstats = arcadedb.import_jsonl(\n    db, \"nodes.jsonl\", \"Node\",\n    vertex_type=\"Node\",\n    commit_every=500\n)\n</code></pre></p>"},{"location":"api/importer/#csv-format","title":"CSV Format","text":"<p>File Structure: <pre><code>name,age,city\nAlice,30,NYC\nBob,25,LA\n</code></pre></p> <p>Options: - <code>delimiter</code> (str): Field separator (default: ',')   - Use <code>'\\t'</code> for tab-separated (TSV) - <code>header</code> (bool): First row contains column names (default: True)   - If False, columns named <code>col_0</code>, <code>col_1</code>, etc. - <code>vertex_type</code> (str): Import as vertices - <code>edge_type</code> (str): Import as edges (requires <code>from_property</code> and <code>to_property</code>) - <code>from_property</code> (str): Column name for edge source RID (default: 'from') - <code>to_property</code> (str): Column name for edge target RID (default: 'to')</p> <p>Type Inference: String values are automatically converted: - <code>\"true\"</code>, <code>\"false\"</code> \u2192 boolean - Valid integers \u2192 int - Valid floats \u2192 float - Everything else \u2192 string - Empty strings \u2192 None</p> <p>Documents Example: <pre><code># people.csv:\n# name,age,email\n# Alice,30,alice@example.com\n# Bob,25,bob@example.com\n\nstats = arcadedb.import_csv(db, \"people.csv\", \"Person\")\n</code></pre></p> <p>Vertices Example: <pre><code>stats = arcadedb.import_csv(\n    db, \"users.csv\", \"User\",\n    vertex_type=\"User\",\n    delimiter=','\n)\n</code></pre></p> <p>Edges Example: <pre><code># relationships.csv:\n# from_rid,to_rid,type,since\n# #1:0,#1:1,FRIEND,2020\n# #1:1,#1:2,COLLEAGUE,2021\n\n# First create the schema\ndb.command(\"sql\", \"CREATE EDGE TYPE Relationship\")\n\n# Then import\nstats = arcadedb.import_csv(\n    db, \"relationships.csv\", \"Relationship\",\n    edge_type=\"Relationship\",\n    from_property=\"from_rid\",\n    to_property=\"to_rid\"\n)\n</code></pre></p> <p>Important for Edge Imports: - CSV must have header row (<code>header=True</code>) - Source and target columns must contain valid RIDs (e.g., <code>#1:0</code>) - Edge type must exist in schema before import - Additional columns become edge properties</p>"},{"location":"api/importer/#neo4j-format","title":"Neo4j Format","text":"<p>Imports Neo4j JSONL exports created with: <pre><code>neo4j-admin export --to=export.jsonl\n</code></pre></p> <p>Process: 1. Schema Pass: Analyzes structure, creates types 2. Vertex Pass: Imports all nodes as vertices 3. Edge Pass: Imports all relationships as edges</p> <p>Options: - <code>verbose</code> (bool): Show detailed progress (default: False)</p> <p>Example: <pre><code># Export from Neo4j:\n# neo4j-admin export --to=/tmp/mydb_export.jsonl\n\n# Import to ArcadeDB:\nstats = arcadedb.import_neo4j(db, \"/tmp/mydb_export.jsonl\", verbose=True)\n\nprint(f\"Vertices: {stats['vertices']}\")\nprint(f\"Edges: {stats['edges']}\")\nprint(f\"Time: {stats['duration_ms']}ms\")\n</code></pre></p>"},{"location":"api/importer/#performance-tips","title":"Performance Tips","text":""},{"location":"api/importer/#batch-size","title":"Batch Size","text":"<p>The <code>commit_every</code> parameter controls transaction size:</p> <pre><code># Smaller batches (safer, slower)\nstats = arcadedb.import_csv(db, \"data.csv\", \"Data\", commit_every=100)\n\n# Larger batches (faster, more memory)\nstats = arcadedb.import_csv(db, \"data.csv\", \"Data\", commit_every=5000)\n</code></pre> <p>Guidelines: - Small files (&lt;10K records): 1000-2000 - Medium files (10K-1M records): 2000-5000 - Large files (&gt;1M records): 5000-10000</p>"},{"location":"api/importer/#memory-efficiency","title":"Memory Efficiency","text":"<p>The importer uses streaming parsers: - JSONL/CSV: Line-by-line processing (very efficient) - JSON: Uses Java's streaming parser - Neo4j: Multi-pass streaming</p>"},{"location":"api/importer/#schema-pre-creation","title":"Schema Pre-Creation","text":"<p>Create types before import for better performance:</p> <pre><code># Create schema first\ndb.command(\"sql\", \"\"\"\n    CREATE DOCUMENT TYPE Person\n    IF NOT EXISTS\n\"\"\")\ndb.command(\"sql\", \"\"\"\n    CREATE PROPERTY Person.email STRING\n\"\"\")\ndb.command(\"sql\", \"\"\"\n    CREATE INDEX ON Person (email) UNIQUE\n\"\"\")\n\n# Then import (type already exists)\nstats = arcadedb.import_csv(db, \"people.csv\", \"Person\")\n</code></pre>"},{"location":"api/importer/#indexing-strategy","title":"Indexing Strategy","text":"<p>Create indexes AFTER import for faster loading:</p> <pre><code># Import without indexes\nstats = arcadedb.import_csv(db, \"users.csv\", \"User\", vertex_type=\"User\")\n\n# Create indexes after import\ndb.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\ndb.command(\"sql\", \"CREATE INDEX ON User (username) UNIQUE\")\n</code></pre>"},{"location":"api/importer/#error-handling","title":"Error Handling","text":"<p>The importer continues on row-level errors and reports them in statistics:</p> <pre><code>stats = arcadedb.import_csv(\n    db, \"data.csv\", \"Data\",\n    verbose=True  # Print errors as they occur\n)\n\nif stats['errors'] &gt; 0:\n    print(f\"Warning: {stats['errors']} records failed to import\")\n    print(f\"Successfully imported: {stats['documents'] + stats['vertices']}\")\n</code></pre> <p>Common Errors: - Type mismatch: Value doesn't match schema constraint - Missing required fields: Schema requires field not in data - Invalid RIDs (edges): Referenced vertex doesn't exist - JSON parse errors (JSONL): Malformed JSON line - Encoding issues: Non-UTF-8 characters</p> <p>Error Recovery: <pre><code>try:\n    stats = importer.import_file(\"data.csv\", type_name=\"Data\")\nexcept arcadedb.ArcadeDBError as e:\n    print(f\"Import failed: {e}\")\n    # File not found, format error, or critical failure\n</code></pre></p>"},{"location":"api/importer/#complete-examples","title":"Complete Examples","text":""},{"location":"api/importer/#multi-format-import-pipeline","title":"Multi-Format Import Pipeline","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Open or create database\ndb = arcadedb.create_database(\"./import_demo\")\n\n# Create schema\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE User\")\ndb.command(\"sql\", \"CREATE VERTEX TYPE Person\")\ndb.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n\n# Import documents from JSON\nstats1 = arcadedb.import_json(db, \"users.json\")\nprint(f\"Users: {stats1['documents']}\")\n\n# Import vertices from CSV\nstats2 = arcadedb.import_csv(\n    db, \"people.csv\", \"Person\",\n    vertex_type=\"Person\"\n)\nprint(f\"People: {stats2['vertices']}\")\n\n# Import edges from CSV\nstats3 = arcadedb.import_csv(\n    db, \"relationships.csv\", \"Knows\",\n    edge_type=\"Knows\",\n    from_property=\"person1_rid\",\n    to_property=\"person2_rid\"\n)\nprint(f\"Relationships: {stats3['edges']}\")\n\ndb.close()\n</code></pre>"},{"location":"api/importer/#large-scale-import-with-progress-tracking","title":"Large-Scale Import with Progress Tracking","text":"<pre><code>import arcadedb_embedded as arcadedb\nimport time\n\ndb = arcadedb.create_database(\"./large_import\")\n\n# Create schema\ndb.command(\"sql\", \"CREATE VERTEX TYPE Product\")\n\n# Import with progress monitoring\nprint(\"Starting import...\")\nstart = time.time()\n\nstats = arcadedb.import_csv(\n    db, \"products.csv\", \"Product\",\n    vertex_type=\"Product\",\n    commit_every=10000,  # Large batches for performance\n    verbose=True  # Show errors\n)\n\nelapsed = time.time() - start\n\nprint(f\"\\nImport complete!\")\nprint(f\"Records: {stats['vertices']:,}\")\nprint(f\"Errors: {stats['errors']}\")\nprint(f\"Time: {elapsed:.2f}s\")\nprint(f\"Rate: {stats['vertices'] / elapsed:.0f} records/sec\")\n\n# Create indexes after import\nprint(\"\\nCreating indexes...\")\ndb.command(\"sql\", \"CREATE INDEX ON Product (sku) UNIQUE\")\ndb.command(\"sql\", \"CREATE INDEX ON Product (category) NOTUNIQUE\")\n\ndb.close()\n</code></pre>"},{"location":"api/importer/#neo4j-migration","title":"Neo4j Migration","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Export from Neo4j (run in Neo4j):\n# neo4j-admin export --to=/exports/mydb.jsonl\n\n# Import to ArcadeDB\ndb = arcadedb.create_database(\"./migrated_db\")\n\nstats = arcadedb.import_neo4j(\n    db, \"/exports/mydb.jsonl\",\n    commit_every=5000,\n    verbose=True\n)\n\nprint(f\"Migration complete!\")\nprint(f\"Vertices: {stats['vertices']:,}\")\nprint(f\"Edges: {stats['edges']:,}\")\nprint(f\"Time: {stats['duration_ms'] / 1000:.2f}s\")\n\ndb.close()\n</code></pre>"},{"location":"api/importer/#see-also","title":"See Also","text":"<ul> <li>Data Import Guide - Comprehensive import strategies</li> <li>Database API - Database operations</li> <li>Graph Operations Guide - Working with graph data</li> <li>Import Examples - More practical examples</li> </ul>"},{"location":"api/results/","title":"Results API","text":"<p>The <code>ResultSet</code> and <code>Result</code> classes provide Python-friendly interfaces for working with query results from ArcadeDB. They handle iteration, property access, and type conversion automatically.</p>"},{"location":"api/results/#overview","title":"Overview","text":"<p>When you execute a query, ArcadeDB returns a <code>ResultSet</code> that can be iterated to access individual <code>Result</code> objects. Each <code>Result</code> represents one row/record from your query.</p> <p>Key Features:</p> <ul> <li>Pythonic iteration: Use <code>for</code> loops or iterators</li> <li>Property access: Get values by property name</li> <li>Type conversion: Automatic conversion from Java to Python types</li> <li>Multiple access patterns: Dict-like access, JSON export, direct properties</li> </ul>"},{"location":"api/results/#resultset-class","title":"ResultSet Class","text":"<p>Iterable wrapper for query results. Supports both Python iteration (<code>for</code>) and manual iteration (<code>has_next()</code>/<code>next()</code>).</p>"},{"location":"api/results/#creation","title":"Creation","text":"<p><code>ResultSet</code> objects are returned by query operations:</p> <pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./mydb\")\n\n# query() returns ResultSet\nresult_set = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n\n# command() also returns ResultSet for SELECT queries\nresult_set = db.command(\"sql\", \"SELECT * FROM Person LIMIT 10\")\n</code></pre>"},{"location":"api/results/#iteration","title":"Iteration","text":"<p>Python-style iteration (recommended):</p> <pre><code># Using for loop (most Pythonic)\nfor result in result_set:\n    name = result.get_property(\"name\")\n    age = result.get_property(\"age\")\n    print(f\"{name}: {age}\")\n\n# As iterator\nresult_set = db.query(\"sql\", \"SELECT FROM Product\")\nresults = list(result_set)  # Convert to list\n</code></pre> <p>Manual iteration:</p> <pre><code># Check and iterate manually\nwhile result_set.has_next():\n    result = result_set.next()\n    print(result.to_dict())\n</code></pre>"},{"location":"api/results/#has_next-bool","title":"<code>has_next() -&gt; bool</code>","text":"<p>Check if there are more results available.</p> <p>Returns:</p> <ul> <li><code>bool</code>: <code>True</code> if more results exist, <code>False</code> otherwise</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT FROM User LIMIT 5\")\n\ncount = 0\nwhile result_set.has_next():\n    result = result_set.next()\n    count += 1\n\nprint(f\"Found {count} results\")\n</code></pre>"},{"location":"api/results/#next-result","title":"<code>next() -&gt; Result</code>","text":"<p>Get the next result.</p> <p>Returns:</p> <ul> <li><code>Result</code>: Next result object</li> </ul> <p>Raises:</p> <ul> <li><code>StopIteration</code>: When no more results available</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT FROM Document\")\n\nif result_set.has_next():\n    first = result_set.next()\n    print(first.to_dict())\n</code></pre>"},{"location":"api/results/#close","title":"<code>close()</code>","text":"<p>Close the result set and release resources.</p> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT FROM LargeTable\")\n\ntry:\n    for result in result_set:\n        process(result)\nfinally:\n    result_set.close()  # Ensure cleanup\n</code></pre> <p>Note: In most cases, result sets are automatically cleaned up when they go out of scope. Explicit closing is only needed for long-running operations or very large result sets.</p>"},{"location":"api/results/#result-class","title":"Result Class","text":"<p>Represents a single result row/record from a query.</p>"},{"location":"api/results/#creation_1","title":"Creation","text":"<p><code>Result</code> objects are created automatically when iterating a <code>ResultSet</code>:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT FROM Person\")\n\n# Each iteration gives you a Result\nfor result in result_set:\n    # result is a Result object\n    pass\n</code></pre>"},{"location":"api/results/#get_propertyname-str-any","title":"<code>get_property(name: str) -&gt; Any</code>","text":"<p>Get the value of a property by name.</p> <p>Parameters:</p> <ul> <li><code>name</code> (str): Property name</li> </ul> <p>Returns:</p> <ul> <li><code>Any</code>: Property value (type depends on the data)</li> <li>Automatically converts Java types to Python types</li> <li>Java <code>Boolean</code> \u2192 Python <code>bool</code></li> <li>Java <code>Integer</code>/<code>Long</code> \u2192 Python <code>int</code></li> <li>Java <code>Float</code>/<code>Double</code> \u2192 Python <code>float</code></li> <li>Java <code>String</code> \u2192 Python <code>str</code></li> <li>Java collections \u2192 Python lists/dicts</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If property doesn't exist or access fails</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT name, age, active FROM User\")\n\nfor result in result_set:\n    name = result.get_property(\"name\")     # str\n    age = result.get_property(\"age\")       # int\n    active = result.get_property(\"active\") # bool (converted from Java Boolean)\n\n    print(f\"{name} is {age} years old, active: {active}\")\n</code></pre>"},{"location":"api/results/#has_propertyname-str-bool","title":"<code>has_property(name: str) -&gt; bool</code>","text":"<p>Check if a property exists in the result.</p> <p>Parameters:</p> <ul> <li><code>name</code> (str): Property name to check</li> </ul> <p>Returns:</p> <ul> <li><code>bool</code>: <code>True</code> if property exists, <code>False</code> otherwise</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT * FROM Person\")\n\nfor result in result_set:\n    if result.has_property(\"email\"):\n        email = result.get_property(\"email\")\n        print(f\"Email: {email}\")\n    else:\n        print(\"No email address\")\n</code></pre>"},{"location":"api/results/#get_property_names-liststr","title":"<code>get_property_names() -&gt; List[str]</code>","text":"<p>Get list of all property names in the result.</p> <p>Returns:</p> <ul> <li><code>List[str]</code>: List of property names</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT * FROM Document LIMIT 1\")\n\nfor result in result_set:\n    properties = result.get_property_names()\n    print(f\"Properties: {', '.join(properties)}\")\n\n    for prop in properties:\n        value = result.get_property(prop)\n        print(f\"  {prop}: {value}\")\n</code></pre>"},{"location":"api/results/#to_dict-dictstr-any","title":"<code>to_dict() -&gt; Dict[str, Any]</code>","text":"<p>Convert the result to a Python dictionary.</p> <p>Returns:</p> <ul> <li><code>Dict[str, Any]</code>: Dictionary with property names as keys</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT name, age, city FROM Person\")\n\n# Convert all results to list of dicts\npeople = [result.to_dict() for result in result_set]\n\nfor person in people:\n    print(person)\n    # {'name': 'Alice', 'age': 30, 'city': 'NYC'}\n</code></pre> <p>Use Cases:</p> <ul> <li>Converting to pandas DataFrame</li> <li>Serialization to JSON (via <code>json.dumps()</code>)</li> <li>Passing data to other libraries</li> <li>Debugging/inspection</li> </ul>"},{"location":"api/results/#to_json-str","title":"<code>to_json() -&gt; str</code>","text":"<p>Convert the result to a JSON string.</p> <p>Returns:</p> <ul> <li><code>str</code>: JSON representation of the result</li> </ul> <p>Example:</p> <pre><code>result_set = db.query(\"sql\", \"SELECT * FROM Product WHERE price &gt; 100\")\n\nfor result in result_set:\n    json_str = result.to_json()\n    print(json_str)\n    # {\"@rid\":\"#1:0\",\"@type\":\"Product\",\"name\":\"Laptop\",\"price\":999.99}\n</code></pre> <p>Note: The JSON includes ArcadeDB metadata like <code>@rid</code> (record ID) and <code>@type</code> (type name).</p>"},{"location":"api/results/#common-patterns","title":"Common Patterns","text":""},{"location":"api/results/#converting-to-lists-and-dicts","title":"Converting to Lists and Dicts","text":"<pre><code># List of dictionaries (most common)\nresult_set = db.query(\"sql\", \"SELECT FROM User\")\nusers = [result.to_dict() for result in result_set]\n\n# List of specific property values\nresult_set = db.query(\"sql\", \"SELECT name FROM User\")\nnames = [result.get_property(\"name\") for result in result_set]\n\n# Dictionary keyed by ID\nresult_set = db.query(\"sql\", \"SELECT id, name FROM User\")\nuser_map = {\n    result.get_property(\"id\"): result.get_property(\"name\")\n    for result in result_set\n}\n</code></pre>"},{"location":"api/results/#pandas-integration","title":"Pandas Integration","text":"<pre><code>import pandas as pd\nimport arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./mydb\")\n\n# Query and convert to DataFrame\nresult_set = db.query(\"sql\", \"SELECT name, age, city FROM Person\")\ndf = pd.DataFrame([result.to_dict() for result in result_set])\n\nprint(df.head())\n#      name  age    city\n# 0   Alice   30     NYC\n# 1     Bob   25      LA\n# 2 Charlie   35  Boston\n</code></pre>"},{"location":"api/results/#processing-large-result-sets","title":"Processing Large Result Sets","text":"<p>For memory efficiency with large datasets:</p> <pre><code># Process in batches\nresult_set = db.query(\"sql\", \"SELECT FROM LargeTable\")\n\nbatch = []\nbatch_size = 1000\n\nfor result in result_set:\n    batch.append(result.to_dict())\n\n    if len(batch) &gt;= batch_size:\n        # Process batch\n        process_batch(batch)\n        batch = []\n\n# Process remaining\nif batch:\n    process_batch(batch)\n</code></pre>"},{"location":"api/results/#conditional-property-access","title":"Conditional Property Access","text":"<pre><code>result_set = db.query(\"sql\", \"SELECT * FROM Product\")\n\nfor result in result_set:\n    # Safely get optional properties\n    discount = (\n        result.get_property(\"discount\") \n        if result.has_property(\"discount\") \n        else 0.0\n    )\n\n    price = result.get_property(\"price\")\n    final_price = price * (1 - discount)\n    print(f\"Price: ${final_price:.2f}\")\n</code></pre>"},{"location":"api/results/#extracting-rids-and-types","title":"Extracting RIDs and Types","text":"<pre><code>result_set = db.query(\"sql\", \"SELECT FROM Person\")\n\nfor result in result_set:\n    # Get ArcadeDB metadata\n    rid = result.get_property(\"@rid\")      # Record ID (e.g., \"#1:0\")\n    rec_type = result.get_property(\"@type\") # Type name (e.g., \"Person\")\n\n    # Get user properties\n    name = result.get_property(\"name\")\n\n    print(f\"[{rid}] {rec_type}: {name}\")\n</code></pre>"},{"location":"api/results/#complete-examples","title":"Complete Examples","text":""},{"location":"api/results/#user-search-and-display","title":"User Search and Display","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./users_db\")\n\ndef search_users(name_pattern):\n    \"\"\"Search users by name pattern.\"\"\"\n    query = f\"\"\"\n        SELECT name, email, created_at\n        FROM User\n        WHERE name LIKE '%{name_pattern}%'\n        ORDER BY name\n    \"\"\"\n\n    result_set = db.query(\"sql\", query)\n    users = []\n\n    for result in result_set:\n        user = {\n            'name': result.get_property(\"name\"),\n            'email': result.get_property(\"email\"),\n            'created_at': result.get_property(\"created_at\")\n        }\n        users.append(user)\n\n    return users\n\n# Search\nresults = search_users(\"John\")\n\nprint(f\"Found {len(results)} users:\")\nfor user in results:\n    print(f\"  {user['name']} &lt;{user['email']}&gt;\")\n\ndb.close()\n</code></pre>"},{"location":"api/results/#graph-traversal-results","title":"Graph Traversal Results","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./social_graph\")\n\n# Find friends of friends\nquery = \"\"\"\n    SELECT \n        @rid as person_rid,\n        name,\n        out('Follows').out('Follows').name as friends_of_friends\n    FROM Person\n    WHERE name = 'Alice'\n\"\"\"\n\nresult_set = db.query(\"sql\", query)\n\nfor result in result_set:\n    person_name = result.get_property(\"name\")\n    friends_of_friends = result.get_property(\"friends_of_friends\")\n\n    print(f\"{person_name}'s extended network:\")\n\n    # friends_of_friends is a Java collection, convert to Python\n    if friends_of_friends:\n        fof_list = list(friends_of_friends)\n        for friend in fof_list:\n            print(f\"  - {friend}\")\n\ndb.close()\n</code></pre>"},{"location":"api/results/#aggregation-results","title":"Aggregation Results","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./analytics_db\")\n\n# Group by and aggregation\nquery = \"\"\"\n    SELECT \n        category,\n        COUNT(*) as product_count,\n        AVG(price) as avg_price,\n        MAX(price) as max_price\n    FROM Product\n    GROUP BY category\n    ORDER BY product_count DESC\n\"\"\"\n\nresult_set = db.query(\"sql\", query)\n\nprint(\"Product Statistics by Category:\")\nprint(\"-\" * 60)\n\nfor result in result_set:\n    category = result.get_property(\"category\")\n    count = result.get_property(\"product_count\")\n    avg_price = result.get_property(\"avg_price\")\n    max_price = result.get_property(\"max_price\")\n\n    print(f\"{category}:\")\n    print(f\"  Products: {count}\")\n    print(f\"  Avg Price: ${avg_price:.2f}\")\n    print(f\"  Max Price: ${max_price:.2f}\")\n    print()\n\ndb.close()\n</code></pre>"},{"location":"api/results/#export-to-json-file","title":"Export to JSON File","text":"<pre><code>import arcadedb_embedded as arcadedb\nimport json\n\ndb = arcadedb.open_database(\"./mydb\")\n\n# Export query results to JSON file\nresult_set = db.query(\"sql\", \"SELECT * FROM Document\")\n\n# Method 1: Using to_dict()\ndocuments = [result.to_dict() for result in result_set]\n\nwith open(\"export.json\", \"w\") as f:\n    json.dump(documents, f, indent=2, default=str)\n\n# Method 2: Using to_json() directly\nresult_set = db.query(\"sql\", \"SELECT * FROM Document\")\n\nwith open(\"export_raw.jsonl\", \"w\") as f:\n    for result in result_set:\n        f.write(result.to_json() + \"\\n\")\n\ndb.close()\n</code></pre>"},{"location":"api/results/#cypher-query-results","title":"Cypher Query Results","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./graph_db\")\n\n# Cypher queries also return ResultSet\ncypher_query = \"\"\"\n    MATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\n    WHERE c.name = 'TechCorp'\n    RETURN p.name AS employee, p.role AS position\n\"\"\"\n\nresult_set = db.query(\"cypher\", cypher_query)\n\nprint(\"TechCorp Employees:\")\nfor result in result_set:\n    employee = result.get_property(\"employee\")\n    position = result.get_property(\"position\")\n    print(f\"  {employee} - {position}\")\n\ndb.close()\n</code></pre>"},{"location":"api/results/#error-handling","title":"Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\nresult_set = db.query(\"sql\", \"SELECT * FROM Person\")\n\nfor result in result_set:\n    try:\n        # Safe property access\n        name = result.get_property(\"name\")\n\n        # May not exist\n        if result.has_property(\"phone\"):\n            phone = result.get_property(\"phone\")\n        else:\n            phone = \"N/A\"\n\n        print(f\"{name}: {phone}\")\n\n    except ArcadeDBError as e:\n        print(f\"Error accessing properties: {e}\")\n        continue\n</code></pre>"},{"location":"api/results/#type-handling","title":"Type Handling","text":"<p>ArcadeDB returns Java types that are automatically converted:</p> Java Type Python Type Notes <code>java.lang.String</code> <code>str</code> Direct conversion <code>java.lang.Integer</code>, <code>Long</code> <code>int</code> Numeric conversion <code>java.lang.Float</code>, <code>Double</code> <code>float</code> Numeric conversion <code>java.lang.Boolean</code> <code>bool</code> Explicitly converted <code>java.util.ArrayList</code> <code>list</code> Iterable conversion <code>java.util.HashMap</code> <code>dict</code> Key-value conversion <code>null</code> <code>None</code> Direct mapping <p>Boolean Conversion:</p> <p>The <code>Result</code> class explicitly converts Java <code>Boolean</code> to Python <code>bool</code>:</p> <pre><code># This is handled automatically\nresult_set = db.query(\"sql\", \"SELECT active FROM User\")\n\nfor result in result_set:\n    active = result.get_property(\"active\")  # Python bool\n    if active:  # Works as expected\n        print(\"User is active\")\n</code></pre>"},{"location":"api/results/#performance-tips","title":"Performance Tips","text":""},{"location":"api/results/#minimize-property-access","title":"Minimize Property Access","text":"<pre><code># Less efficient: Multiple property accesses\nfor result in result_set:\n    if result.get_property(\"age\") &gt; 25:\n        name = result.get_property(\"name\")\n        age = result.get_property(\"age\")\n        print(f\"{name}: {age}\")\n\n# More efficient: Access once, reuse\nfor result in result_set:\n    age = result.get_property(\"age\")\n    if age &gt; 25:\n        name = result.get_property(\"name\")\n        print(f\"{name}: {age}\")\n</code></pre>"},{"location":"api/results/#use-to_dict-for-multiple-properties","title":"Use to_dict() for Multiple Properties","text":"<pre><code># When accessing many properties, convert to dict once\nfor result in result_set:\n    data = result.to_dict()\n\n    # Now access from Python dict (faster)\n    process(\n        data[\"name\"],\n        data[\"age\"],\n        data[\"email\"],\n        data[\"phone\"]\n    )\n</code></pre>"},{"location":"api/results/#stream-processing","title":"Stream Processing","text":"<pre><code># Don't collect all results if you can process incrementally\nresult_set = db.query(\"sql\", \"SELECT * FROM LargeTable\")\n\n# Process as you iterate (memory efficient)\ntotal = 0\nfor result in result_set:\n    value = result.get_property(\"amount\")\n    total += value\n\n# Better than:\n# results = list(result_set)  # Loads everything into memory\n</code></pre>"},{"location":"api/results/#see-also","title":"See Also","text":"<ul> <li>Database API - Query and command methods</li> <li>Query Guide - Writing effective queries</li> <li>Transaction API - Transaction context</li> <li>Graph Operations Guide - Working with graph results</li> </ul>"},{"location":"api/server/","title":"Server API","text":"<p>The <code>ArcadeDBServer</code> class enables HTTP API access and the Studio web interface for managing and querying ArcadeDB databases. Perfect for interactive exploration, debugging, and web applications.</p>"},{"location":"api/server/#overview","title":"Overview","text":"<p>The server provides:</p> <ul> <li>HTTP REST API: Query databases via HTTP endpoints</li> <li>Studio Web UI: Visual database exploration and query editor</li> <li>Multi-database Management: Create and access multiple databases</li> <li>Remote Access: Access from other applications via HTTP</li> <li>GraphQL/Gremlin Support: Extended query languages (with full distribution)</li> </ul> <p>When to Use Server Mode:</p> <ul> <li>Interactive development and debugging</li> <li>Web applications needing HTTP API</li> <li>Visual data exploration via Studio</li> <li>Remote database access</li> <li>GraphQL or Gremlin queries</li> </ul> <p>When to Use Embedded Mode:</p> <ul> <li>Python-only applications</li> <li>Maximum performance (no HTTP overhead)</li> <li>Simplified deployment</li> <li>Reduced memory footprint</li> </ul>"},{"location":"api/server/#module-function","title":"Module Function","text":""},{"location":"api/server/#create_serverroot_pathdatabases-root_passwordnone-confignone","title":"<code>create_server(root_path=\"./databases\", root_password=None, config=None)</code>","text":"<p>Create an ArcadeDB server instance.</p> <p>Parameters:</p> <ul> <li><code>root_path</code> (str): Root directory for databases (default: <code>\"./databases\"</code>)</li> <li>All databases will be created under this directory</li> <li>Automatically created if it doesn't exist</li> <li><code>root_password</code> (Optional[str]): Root user password (default: <code>None</code>)</li> <li>Strongly recommended for production</li> <li>If <code>None</code>, uses default password (insecure!)</li> <li><code>config</code> (Optional[Dict[str, Any]]): Configuration dictionary (default: <code>None</code>)</li> <li><code>http_port</code> (int): HTTP API port (default: 2480)</li> <li><code>binary_port</code> (int): Binary protocol port (default: 2424)</li> <li><code>host</code> (str): Host to bind to (default: \"0.0.0.0\")</li> <li><code>mode</code> (str): Server mode - \"development\" or \"production\" (default: \"development\")</li> <li>Additional ArcadeDB configuration keys (see Advanced Configuration)</li> </ul> <p>Returns:</p> <ul> <li><code>ArcadeDBServer</code>: Server instance (not started)</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\n\n# Basic server (development)\nserver = arcadedb.create_server()\n\n# Custom root path and password\nserver = arcadedb.create_server(\n    root_path=\"./my_databases\",\n    root_password=\"my_secure_password123\"\n)\n\n# Custom configuration\nserver = arcadedb.create_server(\n    root_path=\"./dbs\",\n    root_password=\"secret\",\n    config={\n        \"http_port\": 8080,\n        \"host\": \"127.0.0.1\",\n        \"mode\": \"production\"\n    }\n)\n</code></pre>"},{"location":"api/server/#arcadedbserver-class","title":"ArcadeDBServer Class","text":""},{"location":"api/server/#constructor","title":"Constructor","text":"<pre><code>ArcadeDBServer(\n    root_path: str = \"./databases\",\n    root_password: Optional[str] = None,\n    config: Optional[Dict[str, Any]] = None\n)\n</code></pre> <p>Prefer using <code>create_server()</code> function instead.</p> <p>Parameters: Same as <code>create_server()</code></p>"},{"location":"api/server/#start","title":"<code>start()</code>","text":"<p>Start the ArcadeDB server and begin listening for connections.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If server is already started or fails to start</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\n\nserver = arcadedb.create_server()\nserver.start()\n\nprint(f\"Server running at: {server.get_studio_url()}\")\n\n# ... do work ...\n\nserver.stop()\n</code></pre>"},{"location":"api/server/#stop","title":"<code>stop()</code>","text":"<p>Stop the ArcadeDB server and release resources.</p> <p>Note: It's safe to call even if server isn't started.</p> <p>Example:</p> <pre><code>server = arcadedb.create_server()\nserver.start()\n\ntry:\n    # Do work\n    pass\nfinally:\n    server.stop()  # Always stop to clean up\n</code></pre>"},{"location":"api/server/#is_started-bool","title":"<code>is_started() -&gt; bool</code>","text":"<p>Check if the server is currently running.</p> <p>Returns:</p> <ul> <li><code>bool</code>: <code>True</code> if server is running, <code>False</code> otherwise</li> </ul> <p>Example:</p> <pre><code>server = arcadedb.create_server()\nprint(server.is_started())  # False\n\nserver.start()\nprint(server.is_started())  # True\n\nserver.stop()\nprint(server.is_started())  # False\n</code></pre>"},{"location":"api/server/#get_databasename-str-database","title":"<code>get_database(name: str) -&gt; Database</code>","text":"<p>Get an existing database from the server.</p> <p>Parameters:</p> <ul> <li><code>name</code> (str): Database name</li> </ul> <p>Returns:</p> <ul> <li><code>Database</code>: Database instance</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If server not started or database doesn't exist</li> </ul> <p>Example:</p> <pre><code>server = arcadedb.create_server()\nserver.start()\n\n# Get existing database\ndb = server.get_database(\"mydb\")\n\n# Use database\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nfor record in result:\n    print(record.to_dict())\n\ndb.close()\nserver.stop()\n</code></pre>"},{"location":"api/server/#create_databasename-str-database","title":"<code>create_database(name: str) -&gt; Database</code>","text":"<p>Create a new database on the server.</p> <p>Parameters:</p> <ul> <li><code>name</code> (str): Database name</li> <li>Alphanumeric and underscores recommended</li> <li>Will be created under <code>root_path/{name}/</code></li> </ul> <p>Returns:</p> <ul> <li><code>Database</code>: New database instance</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If server not started or creation fails</li> </ul> <p>Example:</p> <pre><code>server = arcadedb.create_server()\nserver.start()\n\n# Create new database\ndb = server.create_database(\"products_db\")\n\n# Create schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Product\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.name STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.price DECIMAL\")\n\ndb.close()\nserver.stop()\n</code></pre> <p>Important: This method properly registers the database with the server, making it immediately visible in Studio UI.</p>"},{"location":"api/server/#get_http_port-int","title":"<code>get_http_port() -&gt; int</code>","text":"<p>Get the HTTP port the server is listening on.</p> <p>Returns:</p> <ul> <li><code>int</code>: HTTP port number</li> </ul> <p>Example:</p> <pre><code>server = arcadedb.create_server(config={\"http_port\": 8080})\nprint(server.get_http_port())  # 8080\n</code></pre>"},{"location":"api/server/#get_studio_url-str","title":"<code>get_studio_url() -&gt; str</code>","text":"<p>Get the full URL for the Studio web interface.</p> <p>Returns:</p> <ul> <li><code>str</code>: Studio URL (e.g., <code>\"http://localhost:2480/\"</code>)</li> </ul> <p>Example:</p> <pre><code>server = arcadedb.create_server()\nserver.start()\n\nprint(f\"Open Studio at: {server.get_studio_url()}\")\n# Open Studio at: http://localhost:2480/\n</code></pre>"},{"location":"api/server/#context-manager-support","title":"Context Manager Support","text":"<p>The server supports Python context managers for automatic start/stop:</p> <pre><code>import arcadedb_embedded as arcadedb\n\nwith arcadedb.create_server() as server:\n    # Server automatically started\n    db = server.create_database(\"temp_db\")\n\n    # Use database\n    with db.transaction():\n        doc = db.new_document(\"Test\")\n        doc.set(\"value\", 42)\n        doc.save()\n\n    db.close()\n\n# Server automatically stopped when exiting 'with' block\n</code></pre>"},{"location":"api/server/#configuration-options","title":"Configuration Options","text":""},{"location":"api/server/#basic-configuration","title":"Basic Configuration","text":"<pre><code>config = {\n    \"http_port\": 2480,           # HTTP API port\n    \"binary_port\": 2424,         # Binary protocol port (for Java clients)\n    \"host\": \"0.0.0.0\",           # Bind address (0.0.0.0 = all interfaces)\n    \"mode\": \"development\",       # \"development\" or \"production\"\n}\n\nserver = arcadedb.create_server(config=config)\n</code></pre>"},{"location":"api/server/#mode-comparison","title":"Mode Comparison","text":"Setting Development Production CORS Enabled Disabled Debug Logging Verbose Minimal Error Details Full stack traces Generic messages Performance Checks Enabled Disabled <p>Recommendation: Use <code>\"development\"</code> for local dev, <code>\"production\"</code> for deployment.</p>"},{"location":"api/server/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can pass any ArcadeDB configuration via the <code>config</code> dict:</p> <pre><code>config = {\n    \"http_port\": 8080,\n    \"mode\": \"production\",\n    # Additional ArcadeDB settings (with _ instead of .)\n    \"server_database_directory\": \"./custom_dbs\",\n    \"server_http_session_expire\": \"30m\",\n    \"profile_default\": \"high-performance\"\n}\n\nserver = arcadedb.create_server(config=config)\n</code></pre> <p>Note: Python uses underscores (<code>_</code>), which are automatically converted to dots (<code>.</code>) for Java config keys:</p> <ul> <li><code>server_http_session_expire</code> \u2192 <code>arcadedb.server.http.session.expire</code></li> </ul>"},{"location":"api/server/#logging-configuration","title":"Logging Configuration","text":"<p>ArcadeDB writes logs to multiple locations:</p>"},{"location":"api/server/#1-application-logs","title":"1. Application Logs","text":"<p>Location: <code>./log/arcadedb.log.*</code> (relative to working directory)</p> <p>Content: Server startup, database operations, errors</p> <p>Cannot be changed (hardcoded in Java)</p>"},{"location":"api/server/#2-server-event-logs","title":"2. Server Event Logs","text":"<p>Location: <code>{root_path}/log/server-event-log-*.jsonl</code></p> <p>Content: HTTP requests, connections, events</p> <p>Example: <code>./databases/log/server-event-log-2024-01-15.jsonl</code></p>"},{"location":"api/server/#3-jvm-crash-logs","title":"3. JVM Crash Logs","text":"<p>Location: <code>./log/hs_err_pid*.log</code> (default)</p> <p>Customize BEFORE importing:</p> <pre><code>import os\n\n# Set custom crash log location\nos.environ[\"ARCADEDB_JVM_ERROR_FILE\"] = \"/var/log/arcade/errors.log\"\n\n# Now import and use\nimport arcadedb_embedded as arcadedb\n\nserver = arcadedb.create_server()\n# Crash logs will go to /var/log/arcade/errors.log\n</code></pre> <p>Important: Must be set before importing <code>arcadedb_embedded</code>.</p>"},{"location":"api/server/#complete-examples","title":"Complete Examples","text":""},{"location":"api/server/#basic-server-with-studio","title":"Basic Server with Studio","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create and start server\nserver = arcadedb.create_server(\n    root_path=\"./databases\",\n    root_password=\"admin123\"\n)\nserver.start()\n\nprint(f\"Studio available at: {server.get_studio_url()}\")\nprint(\"Press Ctrl+C to stop...\")\n\ntry:\n    # Keep server running\n    import time\n    while True:\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    print(\"\\nStopping server...\")\n    server.stop()\n</code></pre> <p>Usage:</p> <ol> <li>Run the script</li> <li>Open browser to <code>http://localhost:2480/</code></li> <li>Login with username <code>root</code> and password <code>admin123</code></li> <li>Create and query databases via Studio UI</li> </ol>"},{"location":"api/server/#web-application-pattern","title":"Web Application Pattern","text":"<pre><code>import arcadedb_embedded as arcadedb\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n# Create server (singleton)\nserver = arcadedb.create_server(\n    root_path=\"./app_databases\",\n    root_password=\"secure_password\",\n    config={\"http_port\": 2480, \"mode\": \"production\"}\n)\n\n@app.before_first_request\ndef startup():\n    \"\"\"Start ArcadeDB server on first request.\"\"\"\n    server.start()\n\n    # Create database if needed\n    try:\n        db = server.get_database(\"app_db\")\n    except:\n        db = server.create_database(\"app_db\")\n        with db.transaction():\n            db.command(\"sql\", \"CREATE DOCUMENT TYPE User\")\n            db.command(\"sql\", \"CREATE PROPERTY User.email STRING\")\n            db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n    finally:\n        db.close()\n\n@app.route(\"/users\")\ndef get_users():\n    \"\"\"Get all users via ArcadeDB Python API.\"\"\"\n    db = server.get_database(\"app_db\")\n\n    try:\n        result_set = db.query(\"sql\", \"SELECT * FROM User\")\n        users = [result.to_dict() for result in result_set]\n        return jsonify(users)\n    finally:\n        db.close()\n\n@app.route(\"/studio\")\ndef studio_link():\n    \"\"\"Provide link to Studio for admins.\"\"\"\n    return jsonify({\"studio_url\": server.get_studio_url()})\n\nif __name__ == \"__main__\":\n    try:\n        app.run(host=\"0.0.0.0\", port=5000)\n    finally:\n        server.stop()\n</code></pre>"},{"location":"api/server/#multi-database-server","title":"Multi-Database Server","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Context manager for automatic cleanup\nwith arcadedb.create_server() as server:\n    # Create multiple databases\n    users_db = server.create_database(\"users\")\n    products_db = server.create_database(\"products\")\n    analytics_db = server.create_database(\"analytics\")\n\n    # Initialize schemas\n    with users_db.transaction():\n        users_db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n        users_db.command(\"sql\", \"CREATE PROPERTY User.email STRING\")\n\n    with products_db.transaction():\n        products_db.command(\"sql\", \"CREATE DOCUMENT TYPE Product\")\n        products_db.command(\"sql\", \"CREATE PROPERTY Product.sku STRING\")\n\n    # Use databases\n    with users_db.transaction():\n        user = users_db.new_vertex(\"User\")\n        user.set(\"email\", \"alice@example.com\")\n        user.save()\n\n    with products_db.transaction():\n        product = products_db.new_document(\"Product\")\n        product.set(\"sku\", \"PROD-001\")\n        product.save()\n\n    # Query different databases\n    print(\"Users:\")\n    result = users_db.query(\"sql\", \"SELECT FROM User\")\n    for r in result:\n        print(f\"  {r.get_property('email')}\")\n\n    print(\"Products:\")\n    result = products_db.query(\"sql\", \"SELECT FROM Product\")\n    for r in result:\n        print(f\"  {r.get_property('sku')}\")\n\n    # Close databases\n    users_db.close()\n    products_db.close()\n    analytics_db.close()\n\n# Server automatically stopped\nprint(\"All databases shut down cleanly\")\n</code></pre>"},{"location":"api/server/#development-server-with-auto-reload","title":"Development Server with Auto-Reload","text":"<pre><code>import arcadedb_embedded as arcadedb\nimport time\nimport signal\nimport sys\n\n# Global server instance\nserver = None\n\ndef shutdown_handler(signum, frame):\n    \"\"\"Handle Ctrl+C gracefully.\"\"\"\n    print(\"\\nShutting down server...\")\n    if server:\n        server.stop()\n    sys.exit(0)\n\n# Register signal handler\nsignal.signal(signal.SIGINT, shutdown_handler)\n\n# Start server\nserver = arcadedb.create_server(\n    root_path=\"./dev_databases\",\n    root_password=\"dev\",\n    config={\n        \"http_port\": 2480,\n        \"mode\": \"development\"\n    }\n)\nserver.start()\n\n# Create/open dev database\ntry:\n    db = server.get_database(\"dev\")\nexcept:\n    db = server.create_database(\"dev\")\n    print(\"Created new dev database\")\n\n# Initialize schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE TestNode IF NOT EXISTS\")\n    db.command(\"sql\", \"CREATE EDGE TYPE TestEdge IF NOT EXISTS\")\n\ndb.close()\n\nprint(f\"\\n{'=' * 60}\")\nprint(f\"Development Server Running\")\nprint(f\"{'=' * 60}\")\nprint(f\"Studio UI:  {server.get_studio_url()}\")\nprint(f\"HTTP API:   http://localhost:{server.get_http_port()}/api/v1/\")\nprint(f\"Database:   'dev' (password: 'dev')\")\nprint(f\"\\nPress Ctrl+C to stop\")\nprint(f\"{'=' * 60}\\n\")\n\n# Keep running\nwhile True:\n    time.sleep(1)\n</code></pre>"},{"location":"api/server/#production-deployment","title":"Production Deployment","text":"<pre><code>import arcadedb_embedded as arcadedb\nimport os\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Production configuration\nROOT_PASSWORD = os.environ.get(\"ARCADEDB_ROOT_PASSWORD\", \"changeme\")\nROOT_PATH = os.environ.get(\"ARCADEDB_ROOT_PATH\", \"/var/lib/arcadedb\")\nHTTP_PORT = int(os.environ.get(\"ARCADEDB_HTTP_PORT\", \"2480\"))\n\nif ROOT_PASSWORD == \"changeme\":\n    logger.warning(\"Using default password - INSECURE for production!\")\n\n# Create production server\nserver = arcadedb.create_server(\n    root_path=ROOT_PATH,\n    root_password=ROOT_PASSWORD,\n    config={\n        \"http_port\": HTTP_PORT,\n        \"host\": \"0.0.0.0\",\n        \"mode\": \"production\",\n        \"server_http_session_expire\": \"30m\",\n        \"profile_default\": \"high-performance\"\n    }\n)\n\ntry:\n    server.start()\n    logger.info(f\"Production server started on port {HTTP_PORT}\")\n    logger.info(f\"Database path: {ROOT_PATH}\")\n\n    # Keep running\n    import time\n    while True:\n        time.sleep(60)\n        logger.debug(\"Server heartbeat - still running\")\n\nexcept KeyboardInterrupt:\n    logger.info(\"Shutdown signal received\")\nexcept Exception as e:\n    logger.error(f\"Server error: {e}\")\nfinally:\n    server.stop()\n    logger.info(\"Server stopped\")\n</code></pre> <p>Deployment:</p> <pre><code># Set environment variables\nexport ARCADEDB_ROOT_PASSWORD=\"super_secure_password_123\"\nexport ARCADEDB_ROOT_PATH=\"/data/arcadedb\"\nexport ARCADEDB_HTTP_PORT=\"8080\"\n\n# Run server\npython production_server.py\n</code></pre>"},{"location":"api/server/#http-rest-api","title":"HTTP REST API","text":"<p>Once the server is running, you can access databases via HTTP:</p>"},{"location":"api/server/#query-via-http","title":"Query via HTTP","text":"<pre><code># POST query\ncurl -X POST http://localhost:2480/api/v1/query/mydb \\\n  -u root:password \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"language\": \"sql\",\n    \"command\": \"SELECT FROM Person WHERE age &gt; 25\"\n  }'\n\n# GET simple query\ncurl \"http://localhost:2480/api/v1/query/mydb/sql/SELECT%20*%20FROM%20Person\" \\\n  -u root:password\n</code></pre>"},{"location":"api/server/#create-record-via-http","title":"Create Record via HTTP","text":"<pre><code>curl -X POST http://localhost:2480/api/v1/command/mydb \\\n  -u root:password \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"language\": \"sql\",\n    \"command\": \"INSERT INTO Person SET name = '\\''Alice'\\'', age = 30\"\n  }'\n</code></pre>"},{"location":"api/server/#full-rest-api-documentation","title":"Full REST API Documentation","text":"<p>See the official ArcadeDB HTTP API documentation for complete endpoint reference.</p>"},{"location":"api/server/#error-handling","title":"Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    server = arcadedb.create_server()\n    server.start()\n\n    # May fail if database doesn't exist\n    db = server.get_database(\"nonexistent\")\n\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\nfinally:\n    if server.is_started():\n        server.stop()\n</code></pre> <p>Common Errors:</p> <ul> <li>Port already in use: Another process using port 2480</li> <li>Solution: Change <code>http_port</code> in config or stop conflicting process</li> <li>Permission denied: Cannot write to <code>root_path</code></li> <li>Solution: Check directory permissions</li> <li>Database not found: <code>get_database()</code> on non-existent DB</li> <li>Solution: Use <code>create_database()</code> first</li> </ul>"},{"location":"api/server/#see-also","title":"See Also","text":"<ul> <li>Server Mode Guide - Comprehensive server usage guide</li> <li>Database API - Database operations</li> <li>Getting Started - Quick start tutorial</li> <li>ArcadeDB HTTP API Docs - Official REST API reference</li> </ul>"},{"location":"api/transactions/","title":"Transactions API","text":"<p>The <code>TransactionContext</code> class and <code>Database.transaction()</code> method provide ACID-compliant transaction management with automatic commit/rollback via Python context managers.</p>"},{"location":"api/transactions/#overview","title":"Overview","text":"<p>ArcadeDB transactions provide:</p> <ul> <li>Atomicity: All changes commit together or none commit</li> <li>Consistency: Schema validation and constraint enforcement</li> <li>Isolation: Read committed isolation level</li> <li>Durability: Changes persisted to disk on commit</li> </ul> <p>Key Concepts:</p> <ul> <li>Auto-commit queries read latest data but don't create transactions</li> <li>Explicit transactions required for write operations</li> <li>Context managers automatically handle commit/rollback</li> <li>Rollback on exception ensures data integrity</li> </ul>"},{"location":"api/transactions/#transaction-methods","title":"Transaction Methods","text":"<p>All transaction methods are on the <code>Database</code> class:</p>"},{"location":"api/transactions/#databasetransaction-transactioncontext","title":"<code>Database.transaction() -&gt; TransactionContext</code>","text":"<p>Create a transaction context manager.</p> <p>Returns:</p> <ul> <li><code>TransactionContext</code>: Context manager for transaction scope</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./mydb\")\n\n# Context manager handles begin/commit/rollback\nwith db.transaction():\n    # All operations in this block are transactional\n    doc = db.new_document(\"Person\")\n    doc.set(\"name\", \"Alice\")\n    doc.set(\"age\", 30)\n    doc.save()\n\n# Automatically commits on successful exit\n# Automatically rolls back on exception\n</code></pre>"},{"location":"api/transactions/#databasebegin","title":"<code>Database.begin()</code>","text":"<p>Manually begin a transaction.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If transaction already active</li> </ul> <p>Example:</p> <pre><code>db.begin()\n\ntry:\n    doc = db.new_document(\"Person\")\n    doc.set(\"name\", \"Bob\")\n    doc.save()\n\n    db.commit()\nexcept Exception as e:\n    db.rollback()\n    raise\n</code></pre> <p>Recommendation: Use <code>db.transaction()</code> context manager instead for automatic handling.</p>"},{"location":"api/transactions/#databasecommit","title":"<code>Database.commit()</code>","text":"<p>Commit the current transaction and persist changes.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If no active transaction or commit fails</li> </ul> <p>Example:</p> <pre><code>db.begin()\n\ndoc = db.new_document(\"Item\")\ndoc.set(\"value\", 42)\ndoc.save()\n\ndb.commit()  # Changes persisted\n</code></pre>"},{"location":"api/transactions/#databaserollback","title":"<code>Database.rollback()</code>","text":"<p>Roll back the current transaction and discard all changes.</p> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If no active transaction</li> </ul> <p>Example:</p> <pre><code>db.begin()\n\ndoc = db.new_document(\"Test\")\ndoc.set(\"data\", \"temporary\")\ndoc.save()\n\n# Oops, need to undo\ndb.rollback()  # Changes discarded\n</code></pre>"},{"location":"api/transactions/#transactioncontext-class","title":"TransactionContext Class","text":"<p>Context manager returned by <code>db.transaction()</code>. Automatically manages transaction lifecycle.</p>"},{"location":"api/transactions/#behavior","title":"Behavior","text":"<pre><code>with db.transaction():\n    # db.begin() called automatically\n\n    # ... your code ...\n\n    # On normal exit: db.commit() called\n    # On exception: db.rollback() called\n</code></pre>"},{"location":"api/transactions/#implementation","title":"Implementation","text":"<p>The <code>TransactionContext</code> class is simple but powerful:</p> <pre><code>class TransactionContext:\n    def __enter__(self):\n        self.database.begin()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is None:\n            self.database.commit()  # Success\n        else:\n            self.database.rollback()  # Exception occurred\n</code></pre>"},{"location":"api/transactions/#usage-patterns","title":"Usage Patterns","text":""},{"location":"api/transactions/#basic-transaction","title":"Basic Transaction","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./txn_demo\")\n\n# Create schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Account\")\n    db.command(\"sql\", \"CREATE PROPERTY Account.name STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Account.balance DECIMAL\")\n\n# Insert data\nwith db.transaction():\n    account = db.new_document(\"Account\")\n    account.set(\"name\", \"Alice\")\n    account.set(\"balance\", 1000.00)\n    account.save()\n\ndb.close()\n</code></pre>"},{"location":"api/transactions/#multiple-operations-in-transaction","title":"Multiple Operations in Transaction","text":"<pre><code>with db.transaction():\n    # All these operations are atomic\n\n    # Create multiple records\n    for i in range(10):\n        doc = db.new_document(\"Item\")\n        doc.set(\"id\", f\"item_{i}\")\n        doc.set(\"value\", i * 10)\n        doc.save()\n\n    # Query within transaction (sees uncommitted changes)\n    result = db.query(\"sql\", \"SELECT COUNT(*) as cnt FROM Item\")\n    count = result.next().get_property(\"cnt\")\n    print(f\"Created {count} items\")\n\n# All commits together or none commit\n</code></pre>"},{"location":"api/transactions/#conditional-commit","title":"Conditional Commit","text":"<pre><code>with db.transaction():\n    account = db.query(\"sql\", \"SELECT FROM Account WHERE name = 'Alice'\").next()\n\n    current_balance = float(account.get_property(\"balance\"))\n    withdrawal = 500.00\n\n    if current_balance &gt;= withdrawal:\n        # Update balance\n        new_balance = current_balance - withdrawal\n        db.command(\"sql\", \n                   f\"UPDATE Account SET balance = {new_balance} \"\n                   f\"WHERE @rid = {account.get_property('@rid')}\")\n        print(f\"Withdrawal successful. New balance: {new_balance}\")\n    else:\n        # Raise exception to trigger rollback\n        raise ValueError(f\"Insufficient funds: {current_balance}\")\n</code></pre>"},{"location":"api/transactions/#nested-context-not-nested-transactions","title":"Nested Context (Not Nested Transactions)","text":"<p>Important: ArcadeDB doesn't support true nested transactions. Nested contexts use the same transaction:</p> <pre><code># This uses ONE transaction\nwith db.transaction():\n    doc1 = db.new_document(\"Outer\")\n    doc1.set(\"layer\", \"outer\")\n    doc1.save()\n\n    # This does NOT create a new transaction\n    # It uses the same transaction as above\n    with db.transaction():\n        doc2 = db.new_document(\"Inner\")\n        doc2.set(\"layer\", \"inner\")\n        doc2.save()\n\n    # Both doc1 and doc2 commit together\n\n# Both commits together or both roll back\n</code></pre> <p>Recommendation: Avoid nesting <code>db.transaction()</code> - it's confusing and doesn't create nested transactions.</p>"},{"location":"api/transactions/#manual-transaction-control","title":"Manual Transaction Control","text":"<p>For more control, use <code>begin()</code>, <code>commit()</code>, <code>rollback()</code> directly:</p> <pre><code>db.begin()\n\ntry:\n    # Operation 1\n    doc = db.new_document(\"Step1\")\n    doc.set(\"status\", \"processing\")\n    doc.save()\n\n    # Operation 2 (may fail)\n    result = db.command(\"sql\", \"UPDATE Step1 SET status = 'complete'\")\n\n    # Check condition\n    if not result:\n        raise Exception(\"Update failed\")\n\n    # Success - commit\n    db.commit()\n    print(\"Transaction committed\")\n\nexcept Exception as e:\n    # Failure - rollback\n    db.rollback()\n    print(f\"Transaction rolled back: {e}\")\n</code></pre>"},{"location":"api/transactions/#error-handling","title":"Error Handling","text":""},{"location":"api/transactions/#automatic-rollback","title":"Automatic Rollback","text":"<pre><code>try:\n    with db.transaction():\n        doc = db.new_document(\"Test\")\n        doc.set(\"value\", \"data\")\n        doc.save()\n\n        # Simulate error\n        raise ValueError(\"Something went wrong!\")\n\n        # This won't execute\n        db.command(\"sql\", \"UPDATE Test SET value = 'updated'\")\n\nexcept ValueError as e:\n    # Transaction automatically rolled back\n    print(f\"Error: {e}\")\n    print(\"Changes were rolled back\")\n</code></pre>"},{"location":"api/transactions/#partial-success-handling","title":"Partial Success Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\nsuccess_count = 0\nerror_count = 0\n\nrecords = [\n    {\"name\": \"Valid1\", \"age\": 30},\n    {\"name\": \"Valid2\", \"age\": 25},\n    {\"name\": \"Invalid\", \"age\": \"not_a_number\"},  # Will fail\n    {\"name\": \"Valid3\", \"age\": 35},\n]\n\nfor record in records:\n    try:\n        with db.transaction():\n            doc = db.new_document(\"Person\")\n            doc.set(\"name\", record[\"name\"])\n            doc.set(\"age\", record[\"age\"])\n            doc.save()\n\n        success_count += 1\n\n    except (ArcadeDBError, ValueError) as e:\n        error_count += 1\n        print(f\"Failed to insert {record['name']}: {e}\")\n\nprint(f\"Success: {success_count}, Errors: {error_count}\")\n</code></pre>"},{"location":"api/transactions/#validation-before-commit","title":"Validation Before Commit","text":"<pre><code>with db.transaction():\n    # Create records\n    items = []\n    for i in range(5):\n        doc = db.new_document(\"Product\")\n        doc.set(\"sku\", f\"PROD-{i:03d}\")\n        doc.set(\"price\", i * 10.0)\n        doc.save()\n        items.append(doc)\n\n    # Validation check\n    result = db.query(\"sql\", \"SELECT COUNT(*) as cnt FROM Product\")\n    count = result.next().get_property(\"cnt\")\n\n    if count &lt; 5:\n        # Trigger rollback by raising exception\n        raise AssertionError(f\"Expected 5 products, got {count}\")\n\n    # Validation passed, commit happens automatically\n</code></pre>"},{"location":"api/transactions/#acid-guarantees","title":"ACID Guarantees","text":""},{"location":"api/transactions/#atomicity-example","title":"Atomicity Example","text":"<pre><code># Transfer money between accounts (atomic)\nwith db.transaction():\n    # Debit from Alice\n    db.command(\"sql\", \n               \"UPDATE Account SET balance = balance - 100 \"\n               \"WHERE name = 'Alice'\")\n\n    # Credit to Bob\n    db.command(\"sql\",\n               \"UPDATE Account SET balance = balance + 100 \"\n               \"WHERE name = 'Bob'\")\n\n# Both updates commit together or neither commits\n</code></pre>"},{"location":"api/transactions/#consistency-example","title":"Consistency Example","text":"<pre><code># Schema constraints enforced in transactions\nwith db.transaction():\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE User\")\n    db.command(\"sql\", \"CREATE PROPERTY User.email STRING (mandatory true)\")\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n\n# This will fail - email is mandatory\ntry:\n    with db.transaction():\n        user = db.new_document(\"User\")\n        user.set(\"name\", \"Alice\")\n        # Missing email!\n        user.save()\nexcept Exception as e:\n    print(f\"Constraint violation: {e}\")\n    # Transaction rolled back automatically\n\n# This will fail - email must be unique\ntry:\n    with db.transaction():\n        user1 = db.new_document(\"User\")\n        user1.set(\"email\", \"alice@example.com\")\n        user1.save()\n\n        user2 = db.new_document(\"User\")\n        user2.set(\"email\", \"alice@example.com\")  # Duplicate!\n        user2.save()\nexcept Exception as e:\n    print(f\"Unique constraint violation: {e}\")\n    # Both user1 and user2 rolled back\n</code></pre>"},{"location":"api/transactions/#isolation-example","title":"Isolation Example","text":"<pre><code>import threading\nimport time\n\ndef writer_thread():\n    \"\"\"Writer updates balance.\"\"\"\n    with db.transaction():\n        time.sleep(0.5)  # Simulate slow operation\n        db.command(\"sql\", \"UPDATE Account SET balance = 2000 WHERE name = 'Alice'\")\n\ndef reader_thread():\n    \"\"\"Reader sees consistent data.\"\"\"\n    # Read before transaction commits\n    result = db.query(\"sql\", \"SELECT balance FROM Account WHERE name = 'Alice'\")\n    balance = result.next().get_property(\"balance\")\n    print(f\"Balance: {balance}\")  # Sees old value (1000)\n\n    time.sleep(1)  # Wait for writer to commit\n\n    # Read after transaction commits\n    result = db.query(\"sql\", \"SELECT balance FROM Account WHERE name = 'Alice'\")\n    balance = result.next().get_property(\"balance\")\n    print(f\"Balance: {balance}\")  # Sees new value (2000)\n\n# Start threads\nt1 = threading.Thread(target=writer_thread)\nt2 = threading.Thread(target=reader_thread)\nt1.start()\nt2.start()\nt1.join()\nt2.join()\n</code></pre>"},{"location":"api/transactions/#durability-example","title":"Durability Example","text":"<pre><code># Changes survive process crash\nwith db.transaction():\n    doc = db.new_document(\"Critical\")\n    doc.set(\"data\", \"important\")\n    doc.save()\n\n# After commit, data is on disk\n# Even if process crashes here, data is safe\n\ndb.close()\n\n# Reopen database\ndb = arcadedb.open_database(\"./mydb\")\n\n# Data is still there\nresult = db.query(\"sql\", \"SELECT FROM Critical WHERE data = 'important'\")\nassert result.has_next()\nprint(\"Data survived!\")\n</code></pre>"},{"location":"api/transactions/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/transactions/#batch-operations","title":"Batch Operations","text":"<pre><code># Inefficient: Many small transactions\nfor i in range(1000):\n    with db.transaction():\n        doc = db.new_document(\"Item\")\n        doc.set(\"value\", i)\n        doc.save()\n# 1000 commits = slow\n\n# Efficient: One large transaction\nwith db.transaction():\n    for i in range(1000):\n        doc = db.new_document(\"Item\")\n        doc.set(\"value\", i)\n        doc.save()\n# 1 commit = fast\n</code></pre> <p>Guideline: Batch related operations in a single transaction for better performance.</p>"},{"location":"api/transactions/#transaction-size-limits","title":"Transaction Size Limits","text":"<pre><code># For very large batches, commit periodically\nbatch_size = 10000\ncount = 0\n\ndb.begin()\ntry:\n    for i in range(100000):\n        doc = db.new_document(\"BigData\")\n        doc.set(\"index\", i)\n        doc.save()\n\n        count += 1\n        if count &gt;= batch_size:\n            db.commit()\n            db.begin()\n            count = 0\n\n    # Commit remaining\n    if count &gt; 0:\n        db.commit()\n\nexcept Exception as e:\n    db.rollback()\n    raise\n</code></pre> <p>Guideline: Commit every 10K-100K records for very large imports.</p>"},{"location":"api/transactions/#common-patterns","title":"Common Patterns","text":""},{"location":"api/transactions/#read-modify-write","title":"Read-Modify-Write","text":"<pre><code>with db.transaction():\n    # Read\n    result = db.query(\"sql\", \"SELECT FROM Counter WHERE name = 'page_views'\")\n    counter = result.next()\n\n    # Modify\n    current_value = counter.get_property(\"value\")\n    new_value = current_value + 1\n\n    # Write\n    rid = counter.get_property(\"@rid\")\n    db.command(\"sql\", f\"UPDATE {rid} SET value = {new_value}\")\n</code></pre>"},{"location":"api/transactions/#conditional-create","title":"Conditional Create","text":"<pre><code>with db.transaction():\n    # Check if exists\n    result = db.query(\"sql\", \"SELECT FROM User WHERE email = 'alice@example.com'\")\n\n    if result.has_next():\n        print(\"User already exists\")\n    else:\n        # Create if not exists\n        user = db.new_document(\"User\")\n        user.set(\"email\", \"alice@example.com\")\n        user.set(\"name\", \"Alice\")\n        user.save()\n        print(\"User created\")\n</code></pre>"},{"location":"api/transactions/#optimistic-locking","title":"Optimistic Locking","text":"<pre><code>def update_with_retry(db, rid, new_value, max_retries=3):\n    \"\"\"Update with optimistic locking and retry.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            with db.transaction():\n                # Read current version\n                result = db.query(\"sql\", f\"SELECT FROM {rid}\")\n                if not result.has_next():\n                    raise ValueError(\"Record not found\")\n\n                record = result.next()\n\n                # Update (ArcadeDB handles version checking)\n                db.command(\"sql\", f\"UPDATE {rid} SET value = '{new_value}'\")\n\n                return True\n\n        except Exception as e:\n            if \"concurrent\" in str(e).lower() and attempt &lt; max_retries - 1:\n                # Retry on concurrent modification\n                time.sleep(0.1 * (attempt + 1))\n                continue\n            raise\n\n    return False\n</code></pre>"},{"location":"api/transactions/#best-practices","title":"Best Practices","text":"<ol> <li>Use Context Managers: Prefer <code>with db.transaction()</code> over manual <code>begin()</code>/<code>commit()</code></li> <li>Keep Transactions Short: Long-running transactions can block other operations</li> <li>Batch Related Operations: Group related writes in one transaction</li> <li>Handle Exceptions: Always handle exceptions to ensure rollback</li> <li>Avoid Nested Contexts: Don't nest <code>db.transaction()</code> - it's confusing</li> <li>Don't Hold Transactions: Don't keep transactions open during I/O or network calls</li> <li>Commit Regularly for Large Batches: For imports &gt;100K records, commit periodically</li> </ol>"},{"location":"api/transactions/#see-also","title":"See Also","text":"<ul> <li>Database API - Database operations</li> <li>Getting Started - Basic transaction examples</li> <li>Graph Operations Guide - Transactions with graphs</li> <li>Importer API - Bulk import with transactions</li> </ul>"},{"location":"api/vector/","title":"Vector API","text":"<p>Vector search capabilities in ArcadeDB use HNSW (Hierarchical Navigable Small World) indexing for fast approximate nearest neighbor search. Perfect for semantic search, recommendation systems, and similarity-based queries.</p>"},{"location":"api/vector/#overview","title":"Overview","text":"<p>ArcadeDB's vector support enables:</p> <ul> <li>Semantic Search: Find similar documents, images, or any embedded content</li> <li>Recommendation Systems: Find similar items based on feature vectors</li> <li>Clustering: Group similar vectors together</li> <li>Anomaly Detection: Find outliers in vector space</li> </ul> <p>Key Features:</p> <ul> <li>HNSW indexing for O(log N) search performance</li> <li>Multiple distance metrics (cosine, euclidean, inner product)</li> <li>Native NumPy integration (optional)</li> <li>Configurable precision/performance trade-offs</li> </ul>"},{"location":"api/vector/#module-functions","title":"Module Functions","text":"<p>Utility functions for converting between Python and Java vector representations:</p>"},{"location":"api/vector/#to_java_float_arrayvector","title":"<code>to_java_float_array(vector)</code>","text":"<p>Convert a Python array-like object to a Java float array compatible with ArcadeDB's vector indexing.</p> <p>Parameters:</p> <ul> <li><code>vector</code>: Array-like object containing float values</li> <li>Python list: <code>[0.1, 0.2, 0.3]</code></li> <li>NumPy array: <code>np.array([0.1, 0.2, 0.3])</code></li> <li>Any iterable: <code>(0.1, 0.2, 0.3)</code></li> </ul> <p>Returns:</p> <ul> <li>Java float array (<code>JArray&lt;JFloat&gt;</code>)</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\nimport numpy as np\n\n# From Python list\nvec_list = [0.1, 0.2, 0.3, 0.4]\njava_vec = to_java_float_array(vec_list)\n\n# From NumPy array (if NumPy installed)\nvec_np = np.array([0.5, 0.6, 0.7, 0.8], dtype=np.float32)\njava_vec = to_java_float_array(vec_np)\n\n# Use with vertex\nvertex = db.new_vertex(\"Document\")\nvertex.set(\"embedding\", java_vec)\nvertex.save()\n</code></pre>"},{"location":"api/vector/#to_python_arrayjava_vector-use_numpytrue","title":"<code>to_python_array(java_vector, use_numpy=True)</code>","text":"<p>Convert a Java array or ArrayList to a Python array.</p> <p>Parameters:</p> <ul> <li><code>java_vector</code>: Java array or ArrayList of floats</li> <li><code>use_numpy</code> (bool): Return NumPy array if available (default: <code>True</code>)</li> <li>If <code>True</code> and NumPy is installed: returns <code>np.ndarray</code></li> <li>If <code>False</code> or NumPy unavailable: returns Python <code>list</code></li> </ul> <p>Returns:</p> <ul> <li><code>np.ndarray</code> (if <code>use_numpy=True</code> and NumPy available)</li> <li><code>list</code> (otherwise)</li> </ul> <p>Example:</p> <pre><code>from arcadedb_embedded import to_python_array\n\n# Get vector from vertex\nvertex = result_set.next()\njava_vec = vertex.get(\"embedding\")\n\n# Convert to NumPy array\nnp_vec = to_python_array(java_vec, use_numpy=True)\nprint(type(np_vec))  # &lt;class 'numpy.ndarray'&gt;\n\n# Convert to Python list\npy_list = to_python_array(java_vec, use_numpy=False)\nprint(type(py_list))  # &lt;class 'list'&gt;\n</code></pre>"},{"location":"api/vector/#vectorindex-class","title":"VectorIndex Class","text":"<p>Wrapper for ArcadeDB's HNSW vector index, providing similarity search capabilities.</p>"},{"location":"api/vector/#creation-via-database","title":"Creation via Database","text":"<p>Vector indexes are created using the <code>Database.create_vector_index()</code> method:</p> <p>Signature:</p> <pre><code>db.create_vector_index(\n    vertex_type: str,\n    vector_property: str,\n    dimensions: int,\n    id_property: str = \"id\",\n    edge_type: str = \"VectorProximity\",\n    deleted_property: str = \"deleted\",\n    distance_function: str = \"cosine\",\n    m: int = 16,\n    ef: int = 128,\n    ef_construction: int = 128,\n    max_items: int = 10000\n) -&gt; VectorIndex\n</code></pre> <p>Parameters:</p> <ul> <li><code>vertex_type</code> (str): Vertex type containing vectors</li> <li><code>vector_property</code> (str): Property name storing vector arrays</li> <li><code>dimensions</code> (int): Vector dimensionality (must match your embeddings)</li> <li><code>id_property</code> (str): Property used as unique ID (default: <code>\"id\"</code>)</li> <li><code>edge_type</code> (str): Edge type for proximity graph (default: <code>\"VectorProximity\"</code>)</li> <li><code>deleted_property</code> (str): Property marking deleted items (default: <code>\"deleted\"</code>)</li> <li><code>distance_function</code> (str): Distance metric (default: <code>\"cosine\"</code>)</li> <li><code>\"cosine\"</code>: Cosine distance (1 - cosine similarity)</li> <li><code>\"euclidean\"</code>: Euclidean distance (L2 norm)</li> <li><code>\"inner_product\"</code>: Negative inner product</li> <li><code>m</code> (int): HNSW M parameter - bidirectional links per node (default: 16)</li> <li>Higher = better recall, more memory</li> <li>Typical range: 12-48</li> <li><code>ef</code> (int): Search candidate list size (default: 128)</li> <li>Higher = better recall, slower search</li> <li>Typical range: 100-400</li> <li><code>ef_construction</code> (int): Build candidate list size (default: 128)</li> <li>Higher = better quality index, slower build</li> <li>Typical range: 100-400</li> <li><code>max_items</code> (int): Maximum indexed items (default: 10000)</li> </ul> <p>Returns:</p> <ul> <li><code>VectorIndex</code>: Index object for searching</li> </ul> <p>Example:</p> <pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\nimport numpy as np\n\n# Create database and schema\ndb = arcadedb.create_database(\"./vector_db\")\n\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.text STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE INDEX ON Document (id) UNIQUE\")\n\n# Create vector index\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384,  # Match your embedding model\n    distance_function=\"cosine\",\n    m=16,\n    ef=128\n)\n\nprint(f\"Created vector index: {index}\")\n</code></pre>"},{"location":"api/vector/#vectorindexfind_nearestquery_vector-k10-use_numpytrue","title":"<code>VectorIndex.find_nearest(query_vector, k=10, use_numpy=True)</code>","text":"<p>Find k-nearest neighbors to the query vector.</p> <p>Parameters:</p> <ul> <li><code>query_vector</code>: Query vector as:</li> <li>Python list: <code>[0.1, 0.2, ...]</code></li> <li>NumPy array: <code>np.array([0.1, 0.2, ...])</code></li> <li>Any array-like iterable</li> <li><code>k</code> (int): Number of neighbors to return (default: 10)</li> <li><code>use_numpy</code> (bool): Return vectors as NumPy if available (default: <code>True</code>)</li> </ul> <p>Returns:</p> <ul> <li><code>List[Tuple[vertex, float]]</code>: List of <code>(vertex, distance)</code> tuples</li> <li><code>vertex</code>: Matched vertex object (MutableVertex)</li> <li><code>distance</code>: Similarity score (float)<ul> <li>Lower = more similar</li> <li>Range depends on distance function</li> </ul> </li> </ul> <p>Example:</p> <pre><code># Generate query vector (in practice, from your embedding model)\nquery_text = \"machine learning tutorial\"\nquery_vector = generate_embedding(query_text)  # Your embedding function\n\n# Search for 5 most similar documents\nneighbors = index.find_nearest(query_vector, k=5)\n\nfor vertex, distance in neighbors:\n    doc_id = vertex.get(\"id\")\n    text = vertex.get(\"text\")\n    print(f\"Distance: {distance:.4f} | ID: {doc_id}\")\n    print(f\"  Text: {text[:100]}...\")\n</code></pre> <p>Distance Interpretation:</p> Function Range Lower = More Similar cosine [0, 2] \u2713 (0 = identical) euclidean [0, \u221e) \u2713 (0 = identical) inner_product (-\u221e, \u221e) \u2717 (higher = more similar)"},{"location":"api/vector/#vectorindexadd_vertexvertex","title":"<code>VectorIndex.add_vertex(vertex)</code>","text":"<p>Add a single vertex to the index.</p> <p>Parameters:</p> <ul> <li><code>vertex</code>: Vertex object with vector property set</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If vertex cannot be added</li> </ul> <p>Example:</p> <pre><code># Add during vertex creation\nwith db.transaction():\n    doc = db.new_vertex(\"Document\")\n    doc.set(\"id\", \"doc_001\")\n    doc.set(\"text\", \"Introduction to vector search\")\n    doc.set(\"embedding\", to_java_float_array(embedding))\n    doc.save()\n\n    # Add to index\n    index.add_vertex(doc)\n</code></pre> <p>Important: </p> <ul> <li>Vertex must have the vector property populated</li> <li>Vector dimensionality must match index dimensions</li> <li>Call within a transaction for consistency</li> </ul>"},{"location":"api/vector/#vectorindexremove_vertexvertex_id","title":"<code>VectorIndex.remove_vertex(vertex_id)</code>","text":"<p>Remove a vertex from the index.</p> <p>Parameters:</p> <ul> <li><code>vertex_id</code>: ID of the vertex to remove (typically string or int)</li> </ul> <p>Raises:</p> <ul> <li><code>ArcadeDBError</code>: If removal fails</li> </ul> <p>Example:</p> <pre><code># Remove by ID\nvertex_id = \"doc_001\"\nindex.remove_vertex(vertex_id)\n</code></pre> <p>Note: This removes from the vector index only, not from the database. To fully delete:</p> <pre><code>with db.transaction():\n    # Remove from index\n    index.remove_vertex(doc_id)\n\n    # Delete from database\n    db.command(\"sql\", f\"DELETE FROM Document WHERE id = '{doc_id}'\")\n</code></pre>"},{"location":"api/vector/#complete-examples","title":"Complete Examples","text":""},{"location":"api/vector/#semantic-search-with-sentence-transformers","title":"Semantic Search with Sentence Transformers","text":"<pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\n# Load embedding model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\n\n# Create database and schema\ndb = arcadedb.create_database(\"./semantic_search\")\n\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.title STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.content STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE INDEX ON Document (id) UNIQUE\")\n\n# Create vector index (384 dimensions for all-MiniLM-L6-v2)\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    distance_function=\"cosine\",\n    m=16,\n    ef=200  # Higher for better recall\n)\n\n# Sample documents\ndocuments = [\n    {\"id\": \"doc1\", \"title\": \"Python Tutorial\", \n     \"content\": \"Learn Python programming basics\"},\n    {\"id\": \"doc2\", \"title\": \"Machine Learning Guide\", \n     \"content\": \"Introduction to ML algorithms\"},\n    {\"id\": \"doc3\", \"title\": \"Database Systems\", \n     \"content\": \"Understanding relational databases\"},\n]\n\n# Index documents\nprint(\"Indexing documents...\")\nwith db.transaction():\n    for doc in documents:\n        # Generate embedding\n        text = f\"{doc['title']} {doc['content']}\"\n        embedding = model.encode(text)\n\n        # Create vertex\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"id\", doc[\"id\"])\n        vertex.set(\"title\", doc[\"title\"])\n        vertex.set(\"content\", doc[\"content\"])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        # Add to vector index\n        index.add_vertex(vertex)\n\nprint(f\"Indexed {len(documents)} documents\")\n\n# Search\nquery = \"How to learn programming\"\nquery_embedding = model.encode(query)\n\nprint(f\"\\nQuery: '{query}'\")\nresults = index.find_nearest(query_embedding, k=3)\n\nfor vertex, distance in results:\n    print(f\"\\nDistance: {distance:.4f}\")\n    print(f\"Title: {vertex.get('title')}\")\n    print(f\"Content: {vertex.get('content')}\")\n\ndb.close()\n</code></pre>"},{"location":"api/vector/#hybrid-search-vector-filters","title":"Hybrid Search (Vector + Filters)","text":"<p>Combine vector similarity with property filters using SQL:</p> <pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\nimport numpy as np\n\ndb = arcadedb.open_database(\"./products_db\")\n\n# Create schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Product\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.name STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.category STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.price DECIMAL\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.features ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE INDEX ON Product (category) NOTUNIQUE\")\n\n# Create vector index\nindex = db.create_vector_index(\n    vertex_type=\"Product\",\n    vector_property=\"features\",\n    dimensions=128\n)\n\n# Add products with feature vectors\nproducts = [\n    {\"id\": \"p1\", \"name\": \"Laptop\", \"category\": \"Electronics\", \n     \"price\": 999.99, \"features\": np.random.rand(128)},\n    {\"id\": \"p2\", \"name\": \"Mouse\", \"category\": \"Electronics\", \n     \"price\": 29.99, \"features\": np.random.rand(128)},\n    {\"id\": \"p3\", \"name\": \"Desk\", \"category\": \"Furniture\", \n     \"price\": 299.99, \"features\": np.random.rand(128)},\n]\n\nwith db.transaction():\n    for prod in products:\n        v = db.new_vertex(\"Product\")\n        v.set(\"id\", prod[\"id\"])\n        v.set(\"name\", prod[\"name\"])\n        v.set(\"category\", prod[\"category\"])\n        v.set(\"price\", prod[\"price\"])\n        v.set(\"features\", to_java_float_array(prod[\"features\"]))\n        v.save()\n        index.add_vertex(v)\n\n# Hybrid search: vector similarity + filters\nquery_features = np.random.rand(128)\ncandidates = index.find_nearest(query_features, k=100)  # Get many candidates\n\n# Filter by category and price\nfiltered_results = []\nfor vertex, distance in candidates:\n    category = vertex.get(\"category\")\n    price = float(vertex.get(\"price\"))\n\n    if category == \"Electronics\" and price &lt; 500:\n        filtered_results.append((vertex, distance))\n\n    if len(filtered_results) &gt;= 5:  # Want top 5 after filtering\n        break\n\nprint(\"Filtered Results:\")\nfor vertex, distance in filtered_results:\n    print(f\"{vertex.get('name')} - ${vertex.get('price')} - {distance:.4f}\")\n\ndb.close()\n</code></pre>"},{"location":"api/vector/#image-similarity-search","title":"Image Similarity Search","text":"<pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\nfrom PIL import Image\nimport numpy as np\n\n# Assuming you have a function to generate image embeddings\ndef get_image_embedding(image_path):\n    \"\"\"\n    Generate embedding for image using your model\n    (e.g., ResNet, CLIP, etc.)\n    \"\"\"\n    # Placeholder - use your actual embedding model\n    return np.random.rand(512)  # Example: 512-dim embedding\n\ndb = arcadedb.create_database(\"./image_search\")\n\n# Schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Image\")\n    db.command(\"sql\", \"CREATE PROPERTY Image.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Image.filename STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Image.path STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Image.embedding ARRAY_OF_FLOATS\")\n\n# Create index\nindex = db.create_vector_index(\n    vertex_type=\"Image\",\n    vector_property=\"embedding\",\n    dimensions=512,\n    distance_function=\"cosine\",\n    m=24,  # Higher for image search\n    ef=200\n)\n\n# Index images\nimage_files = [\"img1.jpg\", \"img2.jpg\", \"img3.jpg\"]\n\nwith db.transaction():\n    for idx, img_file in enumerate(image_files):\n        embedding = get_image_embedding(img_file)\n\n        v = db.new_vertex(\"Image\")\n        v.set(\"id\", f\"img_{idx}\")\n        v.set(\"filename\", img_file)\n        v.set(\"path\", f\"/images/{img_file}\")\n        v.set(\"embedding\", to_java_float_array(embedding))\n        v.save()\n\n        index.add_vertex(v)\n\n# Search for similar images\nquery_image = \"query.jpg\"\nquery_embedding = get_image_embedding(query_image)\n\nsimilar_images = index.find_nearest(query_embedding, k=5)\n\nprint(f\"Similar images to {query_image}:\")\nfor vertex, distance in similar_images:\n    print(f\"  {vertex.get('filename')} - similarity: {1 - distance:.4f}\")\n\ndb.close()\n</code></pre>"},{"location":"api/vector/#performance-tuning","title":"Performance Tuning","text":""},{"location":"api/vector/#hnsw-parameters","title":"HNSW Parameters","text":"<p>M (connections per node):</p> <ul> <li>Lower (8-12): Faster build, less memory, lower recall</li> <li>Medium (16-24): Balanced (recommended)</li> <li>Higher (32-48): Better recall, more memory, slower build</li> </ul> <p>ef (search size):</p> <ul> <li>Lower (50-100): Faster search, lower recall</li> <li>Medium (128-200): Balanced (recommended)</li> <li>Higher (200-400): Better recall, slower search</li> </ul> <p>ef_construction:</p> <ul> <li>Lower (100-150): Faster build, lower quality</li> <li>Medium (128-256): Balanced</li> <li>Higher (300-500): Better quality, slower build</li> </ul>"},{"location":"api/vector/#distance-functions","title":"Distance Functions","text":"<p>Cosine Distance:</p> <ul> <li>Best for: Text embeddings, normalized vectors</li> <li>Range: [0, 2], lower is better</li> <li>Use when: Direction matters more than magnitude</li> </ul> <p>Euclidean Distance:</p> <ul> <li>Best for: Image embeddings, spatial data</li> <li>Range: [0, \u221e), lower is better</li> <li>Use when: Absolute distance matters</li> </ul> <p>Inner Product:</p> <ul> <li>Best for: Collaborative filtering, when vectors aren't normalized</li> <li>Range: (-\u221e, \u221e), higher is better (note: inverted!)</li> <li>Use when: Magnitude information is important</li> </ul>"},{"location":"api/vector/#memory-considerations","title":"Memory Considerations","text":"<p>Approximate memory per vertex:</p> <pre><code>memory_per_vertex = dimensions * 4 bytes + M * 8 bytes + overhead\n</code></pre> <p>Example for 384-dim vectors with M=16:</p> <pre><code>384 * 4 + 16 * 8 + ~100 bytes \u2248 1.8 KB per vertex\n</code></pre> <p>For 1 million vectors: ~1.8 GB RAM</p>"},{"location":"api/vector/#error-handling","title":"Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError, to_java_float_array\nimport numpy as np\n\ntry:\n    # Dimension mismatch\n    index = db.create_vector_index(\"Doc\", \"emb\", dimensions=384)\n\n    v = db.new_vertex(\"Doc\")\n    v.set(\"emb\", to_java_float_array(np.random.rand(512)))  # Wrong size!\n    v.save()\n    index.add_vertex(v)  # Will fail\n\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\n    # Handle dimension mismatch\n\ntry:\n    # Missing vector property\n    v = db.new_vertex(\"Doc\")\n    v.set(\"id\", \"doc1\")\n    # Forgot to set embedding!\n    v.save()\n    index.add_vertex(v)  # Will fail\n\nexcept ArcadeDBError as e:\n    print(f\"Error: {e}\")\n    # Handle missing property\n</code></pre>"},{"location":"api/vector/#see-also","title":"See Also","text":"<ul> <li>Vector Search Guide - Comprehensive vector search strategies</li> <li>Vector Examples - More practical examples</li> <li>Database API - Database operations</li> <li>Query Guide - Combining vectors with queries</li> </ul>"},{"location":"development/architecture/","title":"Architecture","text":"<p>Technical documentation for the ArcadeDB Python bindings architecture, JPype integration, and implementation details.</p>"},{"location":"development/architecture/#overview","title":"Overview","text":"<p>The ArcadeDB Python bindings are a thin wrapper around the ArcadeDB Java library using JPype for JVM integration. This design provides:</p> <ul> <li>Full API Coverage: Access to all ArcadeDB features</li> <li>Performance: Minimal Python overhead</li> <li>Maintenance: Automatic feature parity with Java releases</li> <li>Type Safety: Python type hints with Java type conversion</li> </ul>"},{"location":"development/architecture/#module-structure","title":"Module Structure","text":"<pre><code>arcadedb_embedded/\n\u251c\u2500\u2500 __init__.py          # Package initialization, JPype startup\n\u251c\u2500\u2500 core.py              # Database, DatabaseFactory, Vertex, Edge, Document\n\u251c\u2500\u2500 server.py            # ArcadeDBServer, HTTP API\n\u251c\u2500\u2500 importer.py          # Importer, data import utilities\n\u251c\u2500\u2500 vector.py            # VectorIndex, embedding utilities\n\u251c\u2500\u2500 results.py           # ResultSet, Result (query results)\n\u251c\u2500\u2500 transactions.py      # TransactionContext (ACID transactions)\n\u2514\u2500\u2500 exceptions.py        # ArcadeDBError (unified exceptions)\n</code></pre>"},{"location":"development/architecture/#module-responsibilities","title":"Module Responsibilities","text":"<p><code>__init__.py</code> - JVM startup and configuration - Package-level exports - Version management - Distribution variant detection (headless/minimal/full)</p> <p><code>core.py</code> - <code>DatabaseFactory</code>: Database creation/opening - <code>Database</code>: Main database interface (query, command, transactions) - <code>Vertex</code>, <code>Edge</code>, <code>Document</code>: Record types - Schema management (types, properties, indexes)</p> <p><code>server.py</code> - <code>ArcadeDBServer</code>: HTTP server lifecycle - Studio UI access - Multi-database support - Server configuration</p> <p><code>importer.py</code> - <code>Importer</code>: Data import orchestration - Format handlers (CSV, JSON, JSONL, Neo4j) - Batch processing - Type inference</p> <p><code>vector.py</code> - <code>VectorIndex</code>: HNSW vector indexing - NumPy \u2194 Java array conversion - Nearest neighbor search - Distance metrics</p> <p><code>results.py</code> - <code>ResultSet</code>: Query result iteration - <code>Result</code>: Single record wrapper - Type conversion (Java \u2192 Python) - JSON serialization</p> <p><code>transactions.py</code> - <code>TransactionContext</code>: Transaction management - Context manager protocol - ACID guarantees - Auto-rollback on exception</p> <p><code>exceptions.py</code> - <code>ArcadeDBError</code>: Base exception - Java exception wrapping - Error categorization</p>"},{"location":"development/architecture/#jpype-integration","title":"JPype Integration","text":""},{"location":"development/architecture/#jvm-lifecycle","title":"JVM Lifecycle","text":"<pre><code># Simplified from __init__.py\n\ndef _start_jvm():\n    \"\"\"Initialize JVM with ArcadeDB JARs.\"\"\"\n    if jpype.isJVMStarted():\n        return\n\n    # Find JAR files\n    jar_path = find_package_jars()\n\n    # Start JVM\n    jpype.startJVM(\n        classpath=[jar_path],\n        convertStrings=False  # Manual string conversion for safety\n    )\n</code></pre> <p>JVM Startup: 1. Package installation places JARs in site-packages 2. First import triggers JVM startup 3. JVM remains active for process lifetime 4. Cannot restart JVM in same process</p> <p>Implications: - JVM settings must be configured before first import - Server mode requires careful JVM configuration - Testing requires separate processes for isolation</p>"},{"location":"development/architecture/#type-conversion","title":"Type Conversion","text":"<p>Python \u2192 Java:</p> <pre><code># String\npython_str = \"hello\"\njava_str = jpype.JString(python_str)\n\n# Array\npython_array = [1.0, 2.0, 3.0]\njava_array = jpype.JArray(jpype.JFloat)(python_array)\n\n# NumPy \u2192 Java (vectors)\nimport numpy as np\nfrom arcadedb_embedded import to_java_float_array\n\nnumpy_array = np.array([1.0, 2.0, 3.0], dtype=np.float32)\njava_array = to_java_float_array(numpy_array)\n</code></pre> <p>Java \u2192 Python:</p> <pre><code># Automatic for primitives\njava_int = some_java_method()  # Returns Java int\npython_int = int(java_int)      # Automatic conversion\n\n# Manual for complex types\njava_list = some_java_method()\npython_list = [item for item in java_list]\n\n# Java array \u2192 NumPy\nfrom arcadedb_embedded import to_python_array\n\njava_array = vertex.get(\"embedding\")\nnumpy_array = to_python_array(java_array)\n</code></pre> <p>Type Mapping:</p> Python Type Java Type Notes <code>str</code> <code>String</code> Manual with <code>JString()</code> <code>int</code> <code>Integer</code>/<code>Long</code> Automatic <code>float</code> <code>Float</code>/<code>Double</code> Automatic <code>bool</code> <code>Boolean</code> Automatic <code>None</code> <code>null</code> Automatic <code>list</code> <code>ArrayList</code> Manual conversion <code>dict</code> <code>HashMap</code> Manual conversion <code>np.ndarray</code> <code>float[]</code> via <code>to_java_float_array()</code>"},{"location":"development/architecture/#memory-management","title":"Memory Management","text":"<p>Garbage Collection: - Python GC: Manages Python objects - Java GC: Manages Java objects - JPype: Bridges both, uses Java GC for wrapped objects</p> <p>Best Practices:</p> <pre><code># Good: Explicit cleanup\ndb = arcadedb.open_database(\"./mydb\")\ntry:\n    # Use database\n    pass\nfinally:\n    db.close()\n\n# Better: Context manager\ndb = arcadedb.open_database(\"./mydb\")\nwith db.transaction():\n    # Work with database\ndb.close()\n\n# Long-running processes: Periodic GC\nimport gc\nfor batch in large_dataset:\n    process_batch(batch)\n    gc.collect()  # Trigger Python GC\n</code></pre> <p>Memory Leaks: - Holding references to Java objects prevents GC - Large ResultSets should be consumed and released - Server mode: Monitor JVM heap usage</p>"},{"location":"development/architecture/#class-hierarchy","title":"Class Hierarchy","text":"<pre><code>DatabaseFactory (core.py)\n    \u251c\u2500 create_database() \u2192 Database\n    \u2514\u2500 open_database() \u2192 Database\n\nDatabase (core.py)\n    \u251c\u2500 query() \u2192 ResultSet\n    \u251c\u2500 command() \u2192 None\n    \u251c\u2500 transaction() \u2192 TransactionContext\n    \u251c\u2500 new_vertex() \u2192 Vertex\n    \u251c\u2500 new_document() \u2192 Document\n    \u251c\u2500 get_importer() \u2192 Importer\n    \u2514\u2500 create_vector_index() \u2192 VectorIndex\n\nRecord (Java: MutableDocument)\n    \u251c\u2500 Vertex\n    \u2502   \u251c\u2500 new_edge() \u2192 Edge\n    \u2502   \u251c\u2500 get_edges() \u2192 Iterator[Edge]\n    \u2502   \u2514\u2500 get_vertices() \u2192 Iterator[Vertex]\n    \u251c\u2500 Edge\n    \u2502   \u251c\u2500 get_out() \u2192 Vertex\n    \u2502   \u2514\u2500 get_in() \u2192 Vertex\n    \u2514\u2500 Document\n        \u251c\u2500 get() \u2192 Any\n        \u251c\u2500 set() \u2192 None\n        \u2514\u2500 save() \u2192 None\n\nResultSet (results.py)\n    \u251c\u2500 __iter__() \u2192 Iterator[Result]\n    \u251c\u2500 has_next() \u2192 bool\n    \u2514\u2500 next() \u2192 Result\n\nResult (results.py)\n    \u251c\u2500 get() \u2192 Any\n    \u251c\u2500 get_property() \u2192 Any\n    \u251c\u2500 to_dict() \u2192 dict\n    \u2514\u2500 to_json() \u2192 str\n</code></pre>"},{"location":"development/architecture/#threading-model","title":"Threading Model","text":""},{"location":"development/architecture/#thread-safety","title":"Thread Safety","text":"<p>Database: - <code>Database</code> instances are NOT thread-safe - Each thread needs its own <code>Database</code> instance - Transactions are thread-local</p> <p>Example:</p> <pre><code>import threading\nimport arcadedb_embedded as arcadedb\n\ndef worker(db_path, worker_id):\n    \"\"\"Worker thread with own database instance.\"\"\"\n    db = arcadedb.open_database(db_path)\n\n    try:\n        with db.transaction():\n            vertex = db.new_vertex(\"Worker\")\n            vertex.set(\"id\", worker_id)\n            vertex.save()\n    finally:\n        db.close()\n\n# Spawn workers\nthreads = []\nfor i in range(5):\n    t = threading.Thread(target=worker, args=(\"./mydb\", i))\n    t.start()\n    threads.append(t)\n\nfor t in threads:\n    t.join()\n</code></pre> <p>Server Mode: - <code>ArcadeDBServer</code> is thread-safe - HTTP requests handled by internal thread pool - Each request gets isolated transaction</p>"},{"location":"development/architecture/#multiprocessing","title":"Multiprocessing","text":"<p>Safe: - Separate processes with separate JVMs - No shared state - Ideal for parallel imports</p> <p>Example:</p> <pre><code>import multiprocessing as mp\nimport arcadedb_embedded as arcadedb\n\ndef process_chunk(db_path, chunk):\n    \"\"\"Process chunk in separate process.\"\"\"\n    # Each process has own JVM\n    db = arcadedb.open_database(db_path)\n\n    with db.transaction():\n        for record in chunk:\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"data\", record)\n            vertex.save()\n\n    db.close()\n\n# Split work across processes\nif __name__ == \"__main__\":\n    chunks = split_data_into_chunks()\n\n    with mp.Pool(processes=4) as pool:\n        pool.starmap(process_chunk, \n                     [(\"./mydb\", chunk) for chunk in chunks])\n</code></pre>"},{"location":"development/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"development/architecture/#bottlenecks","title":"Bottlenecks","text":"<ol> <li>JVM Boundary Crossing</li> <li>Cost: ~1-10 \u03bcs per Java method call</li> <li>Impact: High-frequency calls (loops)</li> <li> <p>Solution: Batch operations, use Java bulk APIs</p> </li> <li> <p>Type Conversion</p> </li> <li>Cost: Varies by type (arrays expensive)</li> <li>Impact: Large data transfers</li> <li> <p>Solution: Minimize conversions, use efficient formats</p> </li> <li> <p>Transaction Overhead</p> </li> <li>Cost: ~100 \u03bcs per transaction</li> <li>Impact: Many small transactions</li> <li>Solution: Batch into larger transactions</li> </ol>"},{"location":"development/architecture/#optimization-strategies","title":"Optimization Strategies","text":"<p>Batch Operations:</p> <pre><code># Bad: Many small transactions\nfor record in records:\n    with db.transaction():\n        vertex = db.new_vertex(\"Data\")\n        vertex.set(\"data\", record)\n        vertex.save()\n# 1000 records = 1000 transactions\n\n# Good: One large transaction\nwith db.transaction():\n    for record in records:\n        vertex = db.new_vertex(\"Data\")\n        vertex.set(\"data\", record)\n        vertex.save()\n# 1000 records = 1 transaction\n</code></pre> <p>Query Optimization:</p> <pre><code># Bad: N+1 queries\nusers = db.query(\"sql\", \"SELECT FROM User\")\nfor user in users:\n    # Separate query per user!\n    orders = db.query(\"sql\", f\"SELECT FROM Order WHERE user_id = '{user.get('id')}'\")\n\n# Good: Single query with traversal\nresult = db.query(\"sql\", \"\"\"\n    SELECT \n        name,\n        out('Placed').name as orders\n    FROM User\n\"\"\")\n</code></pre> <p>ResultSet Streaming:</p> <pre><code># Bad: Load all results\nresult = db.query(\"sql\", \"SELECT FROM LargeTable\")\nall_results = list(result)  # Loads everything into memory\n\n# Good: Stream results\nresult = db.query(\"sql\", \"SELECT FROM LargeTable\")\nfor row in result:\n    process(row)\n    # Only one row in memory at a time\n</code></pre>"},{"location":"development/architecture/#profiling","title":"Profiling","text":"<p>Python Side:</p> <pre><code>import cProfile\nimport pstats\n\ndef benchmark():\n    db = arcadedb.create_database(\"./bench\")\n    with db.transaction():\n        for i in range(10000):\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"id\", i)\n            vertex.save()\n    db.close()\n\n# Profile\ncProfile.run('benchmark()', 'stats.prof')\nstats = pstats.Stats('stats.prof')\nstats.sort_stats('cumulative')\nstats.print_stats(20)\n</code></pre> <p>Java Side:</p> <pre><code># Enable JVM profiling\nimport jpype\n\n# Before starting JVM (in package __init__.py):\njpype.startJVM(\n    classpath=[jar_path],\n    convertStrings=False,\n    # JVM profiling options:\n    \"-XX:+PrintGCDetails\",\n    \"-Xloggc:gc.log\"\n)\n</code></pre>"},{"location":"development/architecture/#distribution-variants","title":"Distribution Variants","text":""},{"location":"development/architecture/#headless","title":"Headless","text":"<p>Size: ~94 MB Features: SQL, Cypher, HTTP API, Studio UI Excludes: Gremlin, GraphQL, MongoDB syntax</p> <pre><code># pip install arcadedb-embedded-headless\nimport arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./mydb\")\ndb.query(\"sql\", \"SELECT FROM User\")      # \u2713\ndb.query(\"cypher\", \"MATCH (n) RETURN n\")  # \u2713\ndb.query(\"gremlin\", \"g.V()\")              # \u2717 Error\n</code></pre>"},{"location":"development/architecture/#minimal","title":"Minimal","text":"<p>Size: ~97 MB Features: SQL, Cypher, HTTP API, Studio UI Excludes: Gremlin, GraphQL, MongoDB syntax  </p> <p>Same as headless with different packaging.</p>"},{"location":"development/architecture/#full","title":"Full","text":"<p>Size: ~158 MB Features: Everything (SQL, Cypher, Gremlin, GraphQL, MongoDB)</p> <pre><code># pip install arcadedb-embedded\nimport arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./mydb\")\ndb.query(\"sql\", \"SELECT FROM User\")              # \u2713\ndb.query(\"cypher\", \"MATCH (n) RETURN n\")         # \u2713\ndb.query(\"gremlin\", \"g.V()\")                     # \u2713\ndb.query(\"graphql\", \"{users{name}}\")             # \u2713\ndb.query(\"mongodb\", \"db.User.find()\")            # \u2713\n</code></pre>"},{"location":"development/architecture/#extension-points","title":"Extension Points","text":""},{"location":"development/architecture/#custom-vertexedge-classes","title":"Custom Vertex/Edge Classes","text":"<pre><code>from arcadedb_embedded import Database\n\nclass CustomVertex:\n    \"\"\"Custom vertex wrapper with helper methods.\"\"\"\n\n    def __init__(self, java_vertex):\n        self._java_vertex = java_vertex\n\n    def get_friends(self):\n        \"\"\"Get all friends (out edges of type 'Knows').\"\"\"\n        edges = self._java_vertex.getEdges(\n            jpype.JClass('com.arcadedata.engine.api.graph.Vertex$DIRECTION').OUT,\n            \"Knows\"\n        )\n        return [edge.getVertex() for edge in edges]\n\n# Usage with wrapped database\n</code></pre>"},{"location":"development/architecture/#custom-importers","title":"Custom Importers","text":"<pre><code>class CustomImporter:\n    \"\"\"Custom import format handler.\"\"\"\n\n    def __init__(self, db):\n        self.db = db\n\n    def import_xml(self, file_path, vertex_type):\n        \"\"\"Import XML format.\"\"\"\n        import xml.etree.ElementTree as ET\n\n        tree = ET.parse(file_path)\n        root = tree.getroot()\n\n        with self.db.transaction():\n            for elem in root.findall('.//record'):\n                vertex = self.db.new_vertex(vertex_type)\n                for child in elem:\n                    vertex.set(child.tag, child.text)\n                vertex.save()\n\n# Usage\nimporter = CustomImporter(db)\nimporter.import_xml(\"data.xml\", \"Data\")\n</code></pre>"},{"location":"development/architecture/#testing","title":"Testing","text":""},{"location":"development/architecture/#unit-tests","title":"Unit Tests","text":"<pre><code>import unittest\nimport arcadedb_embedded as arcadedb\nimport tempfile\nimport shutil\n\nclass TestDatabase(unittest.TestCase):\n    def setUp(self):\n        \"\"\"Create temp database for each test.\"\"\"\n        self.db_path = tempfile.mkdtemp()\n        self.db = arcadedb.create_database(self.db_path)\n\n    def tearDown(self):\n        \"\"\"Clean up.\"\"\"\n        self.db.close()\n        shutil.rmtree(self.db_path)\n\n    def test_create_vertex(self):\n        \"\"\"Test vertex creation.\"\"\"\n        with self.db.transaction():\n            vertex = self.db.new_vertex(\"User\")\n            vertex.set(\"name\", \"Alice\")\n            vertex.save()\n\n        result = self.db.query(\"sql\", \"SELECT count(*) as count FROM User\")\n        count = result.next().get(\"count\")\n        self.assertEqual(count, 1)\n</code></pre>"},{"location":"development/architecture/#integration-tests","title":"Integration Tests","text":"<pre><code>import pytest\nimport arcadedb_embedded as arcadedb\n\n@pytest.fixture(scope=\"module\")\ndef database():\n    \"\"\"Shared database for integration tests.\"\"\"\n    db = arcadedb.create_database(\"./test_db\")\n    yield db\n    db.close()\n\ndef test_graph_traversal(database):\n    \"\"\"Test complex graph operations.\"\"\"\n    # Setup\n    with database.transaction():\n        alice = database.new_vertex(\"User\")\n        alice.set(\"name\", \"Alice\")\n        alice.save()\n\n        bob = database.new_vertex(\"User\")\n        bob.set(\"name\", \"Bob\")\n        bob.save()\n\n        edge = alice.new_edge(\"Knows\", bob)\n        edge.save()\n\n    # Test\n    result = database.query(\"sql\", \"\"\"\n        SELECT expand(out('Knows'))\n        FROM User\n        WHERE name = 'Alice'\n    \"\"\")\n\n    friends = list(result)\n    assert len(friends) == 1\n    assert friends[0].get(\"name\") == \"Bob\"\n</code></pre>"},{"location":"development/architecture/#build-system","title":"Build System","text":""},{"location":"development/architecture/#package-build","title":"Package Build","text":"<pre><code># pyproject.toml configuration\n[build-system]\nrequires = [\"setuptools&gt;=45\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"arcadedb-embedded\"\nversion = \"0.1.0\"\ndependencies = [\"JPype1&gt;=1.4.0\", \"numpy&gt;=1.20.0\"]\n</code></pre>"},{"location":"development/architecture/#jar-management","title":"JAR Management","text":"<pre><code># setup_jars.py - Download and package JARs\n\nimport requests\nimport os\n\ndef download_arcadedb_jars(version, variant=\"full\"):\n    \"\"\"Download ArcadeDB distribution JARs.\"\"\"\n\n    base_url = f\"https://repo1.maven.org/maven2/com/arcadedata/\"\n\n    # Core JAR\n    jar_url = f\"{base_url}arcadedb/{version}/arcadedb-{version}.jar\"\n    download_jar(jar_url, f\"arcadedb-{version}.jar\")\n\n    # Variant-specific JARs\n    if variant == \"full\":\n        # Download Gremlin, GraphQL, etc.\n        pass\n\n# Called during package build\n</code></pre>"},{"location":"development/architecture/#see-also","title":"See Also","text":"<ul> <li>Core API Reference - Database and record APIs</li> <li>Troubleshooting - Common issues and solutions</li> <li>JPype Documentation - JPype library docs</li> <li>ArcadeDB Java API - Underlying Java API</li> </ul>"},{"location":"development/contributing/","title":"Contributing to ArcadeDB Python Bindings","text":"<p>Thank you for your interest in contributing to ArcadeDB Python bindings! This guide will help you get started with development.</p>"},{"location":"development/contributing/#quick-start","title":"Quick Start","text":"<pre><code># Clone the repository\ngit clone https://github.com/humemai/arcadedb.git\ncd arcadedb/bindings/python\n\n# Build all distributions (requires Docker)\n./build-all.sh all\n\n# Or build specific distribution\n./build-all.sh headless\n\n# Install in development mode\npip install -e .\n\n# Run tests\npytest tests/\n</code></pre>"},{"location":"development/contributing/#development-environment","title":"Development Environment","text":""},{"location":"development/contributing/#requirements","title":"Requirements","text":"<p>Required:</p> <ul> <li>Python 3.8+</li> <li>Java 11+ (JDK or JRE)</li> <li>Docker (for building distributions)</li> <li>Git</li> </ul> <p>Optional:</p> <ul> <li>pytest (testing)</li> <li>black (code formatting)</li> <li>mypy (type checking)</li> <li>mkdocs (documentation)</li> </ul>"},{"location":"development/contributing/#setup","title":"Setup","text":"<ol> <li>Clone Repository</li> </ol> <pre><code>git clone https://github.com/humemai/arcadedb.git\ncd arcadedb/bindings/python\n</code></pre> <ol> <li>Create Virtual Environment</li> </ol> <pre><code># Create venv\npython -m venv venv\n\n# Activate\nsource venv/bin/activate  # Linux/macOS\n# or\nvenv\\Scripts\\activate     # Windows\n</code></pre> <ol> <li>Install Development Dependencies</li> </ol> <pre><code># Install package in editable mode\npip install -e \".[dev,vector]\"\n\n# Or manually install dependencies\npip install pytest pytest-cov black isort mypy numpy\n</code></pre> <ol> <li>Verify Setup</li> </ol> <pre><code># Check Python\npython --version  # Should be 3.8+\n\n# Check Java\njava -version     # Should be 11+\n\n# Run quick test\npython -c \"import arcadedb_embedded; print('\u2705 Setup successful!')\"\n</code></pre>"},{"location":"development/contributing/#project-structure","title":"Project Structure","text":"<pre><code>arcadedb/bindings/python/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 arcadedb_embedded/        # Main package\n\u2502       \u251c\u2500\u2500 __init__.py            # Package initialization\n\u2502       \u251c\u2500\u2500 core.py                # Database, DatabaseFactory\n\u2502       \u251c\u2500\u2500 server.py              # ArcadeDBServer\n\u2502       \u251c\u2500\u2500 importer.py            # Data import utilities\n\u2502       \u251c\u2500\u2500 vector.py              # Vector search support\n\u2502       \u251c\u2500\u2500 results.py             # Query result handling\n\u2502       \u251c\u2500\u2500 transactions.py        # Transaction management\n\u2502       \u251c\u2500\u2500 exceptions.py          # Exception classes\n\u2502       \u251c\u2500\u2500 jvm.py                 # JVM startup logic\n\u2502       \u2514\u2500\u2500 jars/                  # JAR files (downloaded)\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py                # pytest fixtures\n\u2502   \u251c\u2500\u2500 test_core.py               # Core tests\n\u2502   \u251c\u2500\u2500 test_server.py             # Server tests\n\u2502   \u251c\u2500\u2500 test_importer.py           # Importer tests\n\u2502   \u251c\u2500\u2500 test_gremlin.py            # Gremlin tests (full only)\n\u2502   \u251c\u2500\u2500 test_concurrency.py        # Concurrency tests\n\u2502   \u2514\u2500\u2500 test_server_patterns.py    # Server pattern tests\n\u251c\u2500\u2500 docs/                          # MkDocs documentation\n\u2502   \u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 guide/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 development/\n\u251c\u2500\u2500 examples/                      # Example scripts\n\u2502   \u2514\u2500\u2500 basic.py\n\u251c\u2500\u2500 pyproject.toml                 # Package configuration\n\u251c\u2500\u2500 setup_jars.py                  # JAR download script\n\u251c\u2500\u2500 extract_version.py             # Version extraction\n\u251c\u2500\u2500 write_version.py               # Version writing\n\u251c\u2500\u2500 build-all.sh                   # Build script\n\u251c\u2500\u2500 Dockerfile.build               # Build container\n\u251c\u2500\u2500 docker-compose.yml             # Docker services\n\u2514\u2500\u2500 mkdocs.yml                     # Documentation config\n</code></pre>"},{"location":"development/contributing/#building-from-source","title":"Building from Source","text":""},{"location":"development/contributing/#docker-build-recommended","title":"Docker Build (Recommended)","text":"<pre><code># Build all distributions\n./build-all.sh all\n\n# Build specific distribution\n./build-all.sh headless   # ~94 MB, SQL/Cypher only\n./build-all.sh minimal    # ~97 MB, adds Studio UI\n./build-all.sh full       # ~158 MB, adds Gremlin/GraphQL\n\n# Output: dist/*.whl\n</code></pre> <p>What the build does:</p> <ol> <li>Extracts ArcadeDB version from parent <code>pom.xml</code></li> <li>Downloads appropriate JAR files for distribution</li> <li>Packages Python code with JARs</li> <li>Runs tests in isolated Docker environment</li> <li>Creates wheel file in <code>dist/</code></li> </ol>"},{"location":"development/contributing/#local-build","title":"Local Build","text":"<pre><code># Download JARs for headless distribution\npython setup_jars.py headless\n\n# Build wheel\npython -m build\n\n# Install locally\npip install dist/*.whl\n</code></pre>"},{"location":"development/contributing/#development-install","title":"Development Install","text":"<pre><code># Install in editable mode (no wheel needed)\npip install -e .\n\n# Changes to Python code take effect immediately\n# No reinstall needed\n</code></pre>"},{"location":"development/contributing/#running-tests","title":"Running Tests","text":""},{"location":"development/contributing/#all-tests","title":"All Tests","text":"<pre><code># Run all tests\npytest\n\n# With coverage\npytest --cov=arcadedb_embedded --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"development/contributing/#specific-test-files","title":"Specific Test Files","text":"<pre><code># Core functionality\npytest tests/test_core.py\n\n# Server mode\npytest tests/test_server.py\n\n# Importer\npytest tests/test_importer.py\n\n# Gremlin (requires full distribution)\npytest tests/test_gremlin.py -m gremlin\n</code></pre>"},{"location":"development/contributing/#test-markers","title":"Test Markers","text":"<pre><code># Skip server tests\npytest -m \"not server\"\n\n# Only Gremlin tests\npytest -m gremlin\n\n# Skip Gremlin tests\npytest -m \"not gremlin\"\n</code></pre>"},{"location":"development/contributing/#writing-tests","title":"Writing Tests","text":"<pre><code># tests/test_example.py\nimport pytest\nimport arcadedb_embedded as arcadedb\n\ndef test_create_database(tmp_path):\n    \"\"\"Test database creation.\"\"\"\n    db_path = tmp_path / \"test.db\"\n\n    # Create database\n    db = arcadedb.create_database(str(db_path))\n\n    try:\n        # Test operations\n        with db.transaction():\n            db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n\n        # Verify\n        result = db.query(\"sql\", \"SELECT FROM schema:types WHERE name = 'User'\")\n        assert result.has_next()\n    finally:\n        db.close()\n\ndef test_transaction_rollback(tmp_path):\n    \"\"\"Test transaction rollback.\"\"\"\n    db_path = tmp_path / \"test.db\"\n    db = arcadedb.create_database(str(db_path))\n\n    try:\n        with db.transaction():\n            db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n\n        # Should rollback\n        with pytest.raises(Exception):\n            with db.transaction():\n                db.command(\"sql\", \"INSERT INTO User SET name = 'Alice'\")\n                raise Exception(\"Force rollback\")\n\n        # Verify rollback\n        result = db.query(\"sql\", \"SELECT FROM User\")\n        assert not result.has_next()\n    finally:\n        db.close()\n</code></pre>"},{"location":"development/contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"development/contributing/#python-style","title":"Python Style","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 100 characters (not 79)</li> <li>Use double quotes for strings</li> <li>Use trailing commas in multi-line structures</li> </ul> <pre><code># Good\ndef create_user(db, name: str, email: str) -&gt; dict:\n    \"\"\"\n    Create a new user vertex.\n\n    Args:\n        db: Database instance\n        name: User's full name\n        email: User's email address\n\n    Returns:\n        User vertex as dict\n    \"\"\"\n    with db.transaction():\n        user = db.new_vertex(\"User\")\n        user.set(\"name\", name)\n        user.set(\"email\", email)\n        user.save()\n\n    return {\n        \"name\": name,\n        \"email\": email,\n    }\n\n# Bad\ndef create_user(db,name,email):\n    user=db.new_vertex('User')  # No spaces, single quotes\n    user.set('name',name)\n    return user\n</code></pre>"},{"location":"development/contributing/#formatting-tools","title":"Formatting Tools","text":"<pre><code># Format with black\nblack src/ tests/\n\n# Sort imports\nisort src/ tests/\n\n# Type checking\nmypy src/\n</code></pre>"},{"location":"development/contributing/#type-hints","title":"Type Hints","text":"<p>Use type hints for all public APIs:</p> <pre><code>from typing import Optional, List, Dict, Any\n\ndef query_users(\n    db: Database,\n    filters: Optional[Dict[str, Any]] = None,\n    limit: int = 100\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Query users with optional filters.\"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"development/contributing/#docstrings","title":"Docstrings","text":"<p>Use Google-style docstrings:</p> <pre><code>def import_csv(\n    db: Database,\n    file_path: str,\n    type_name: str,\n    batch_size: int = 1000\n) -&gt; int:\n    \"\"\"\n    Import CSV file into database.\n\n    Args:\n        db: Database instance\n        file_path: Path to CSV file\n        type_name: Vertex or document type name\n        batch_size: Records per transaction (default: 1000)\n\n    Returns:\n        Number of records imported\n\n    Raises:\n        FileNotFoundError: If CSV file doesn't exist\n        ArcadeDBError: If import fails\n\n    Example:\n        &gt;&gt;&gt; db = arcadedb.open_database(\"./mydb\")\n        &gt;&gt;&gt; count = import_csv(db, \"users.csv\", \"User\", batch_size=5000)\n        &gt;&gt;&gt; print(f\"Imported {count} users\")\n    \"\"\"\n    # Implementation\n    pass\n</code></pre>"},{"location":"development/contributing/#error-handling","title":"Error Handling","text":"<p>Always provide clear error messages:</p> <pre><code># Good\ntry:\n    db = arcadedb.open_database(path)\nexcept Exception as e:\n    raise ArcadeDBError(\n        f\"Failed to open database at '{path}': {e}\"\n    ) from e\n\n# Bad\ntry:\n    db = arcadedb.open_database(path)\nexcept:\n    raise Exception(\"Error\")  # Not informative!\n</code></pre>"},{"location":"development/contributing/#naming-conventions","title":"Naming Conventions","text":"<pre><code># Classes: PascalCase\nclass DatabaseFactory:\n    pass\n\nclass VectorIndex:\n    pass\n\n# Functions/methods: snake_case\ndef create_database(path: str) -&gt; Database:\n    pass\n\ndef get_importer(self) -&gt; Importer:\n    pass\n\n# Constants: UPPER_SNAKE_CASE\nDEFAULT_BATCH_SIZE = 1000\nMAX_RETRIES = 3\n\n# Private: leading underscore\ndef _internal_helper():\n    pass\n\nclass Database:\n    def _check_not_closed(self):\n        pass\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Install mkdocs\npip install mkdocs mkdocs-material\n\n# Serve locally (hot reload)\nmkdocs serve\n\n# Build static site\nmkdocs build\n\n# Output: site/\n</code></pre>"},{"location":"development/contributing/#writing-documentation","title":"Writing Documentation","text":"<p>Documentation uses Markdown with MkDocs Material theme:</p> <pre><code># Page Title\n\nBrief introduction to the topic.\n\n## Section\n\nContent here with examples.\n\n### Code Examples\n\n\\```python\nimport arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./mydb\")\n\\```\n\n### Admonitions\n\n!!! note \"Important Note\"\n    This is important information.\n\n!!! warning \"Warning\"\n    Be careful with this!\n\n!!! tip \"Pro Tip\"\n    This will make your life easier.\n\n### Links\n\n- [Internal link](../api/database.md)\n- [External link](https://arcadedb.com)\n</code></pre>"},{"location":"development/contributing/#api-documentation","title":"API Documentation","text":"<p>Keep API reference in sync with code:</p> <pre><code># src/arcadedb_embedded/core.py\nclass Database:\n    def query(self, language: str, command: str, params: Optional[dict] = None) -&gt; ResultSet:\n        \"\"\"\n        Execute a query and return results.\n\n        Args:\n            language: Query language (sql, cypher, gremlin, etc.)\n            command: Query command string\n            params: Optional query parameters\n\n        Returns:\n            ResultSet: Iterable query results\n\n        Raises:\n            ArcadeDBError: If query execution fails\n\n        Example:\n            &gt;&gt;&gt; result = db.query(\"sql\", \"SELECT FROM User WHERE age &gt; :min_age\", {\"min_age\": 18})\n            &gt;&gt;&gt; for user in result:\n            ...     print(user.get(\"name\"))\n        \"\"\"\n</code></pre> <p>Corresponding documentation in <code>docs/api/database.md</code>:</p> <pre><code>### query\n\n\\```python\ndb.query(language: str, command: str, params: Optional[dict] = None) -&gt; ResultSet\n\\```\n\nExecute a query and return results.\n\n**Parameters:**\n\n- `language` (str): Query language (sql, cypher, gremlin, mongodb, graphql)\n- `command` (str): Query command string\n- `params` (Optional[dict]): Query parameters for parameterized queries\n\n**Returns:**\n\n- `ResultSet`: Iterable query results\n\n**Raises:**\n\n- `ArcadeDBError`: If query execution fails\n\n**Example:**\n\n\\```python\n# Basic query\nresult = db.query(\"sql\", \"SELECT FROM User\")\nfor user in result:\n    print(user.get(\"name\"))\n\n# Parameterized query\nresult = db.query(\"sql\", \n    \"SELECT FROM User WHERE age &gt; :min_age\",\n    {\"min_age\": 18}\n)\n\\```\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork on GitHub first\ngit clone https://github.com/YOUR_USERNAME/arcadedb.git\ncd arcadedb/bindings/python\n\n# Add upstream\ngit remote add upstream https://github.com/humemai/arcadedb.git\n</code></pre>"},{"location":"development/contributing/#2-create-branch","title":"2. Create Branch","text":"<pre><code># Update main\ngit checkout main\ngit pull upstream main\n\n# Create feature branch\ngit checkout -b feature/my-new-feature\n\n# Or bug fix branch\ngit checkout -b fix/issue-123\n</code></pre>"},{"location":"development/contributing/#3-make-changes","title":"3. Make Changes","text":"<pre><code># Edit files\nvim src/arcadedb_embedded/core.py\n\n# Add tests\nvim tests/test_core.py\n\n# Update documentation\nvim docs/api/database.md\n</code></pre>"},{"location":"development/contributing/#4-test-changes","title":"4. Test Changes","text":"<pre><code># Run tests\npytest\n\n# Format code\nblack src/ tests/\nisort src/ tests/\n\n# Type check\nmypy src/\n\n# Build documentation\nmkdocs build\n</code></pre>"},{"location":"development/contributing/#5-commit-changes","title":"5. Commit Changes","text":"<pre><code># Stage changes\ngit add src/ tests/ docs/\n\n# Commit with clear message\ngit commit -m \"Add vector search distance function parameter\n\n- Added distance_function parameter to create_vector_index()\n- Supports cosine, euclidean, and inner_product\n- Added tests for all distance functions\n- Updated API documentation\n\nFixes #123\"\n</code></pre> <p>Commit Message Guidelines:</p> <ul> <li>First line: Brief summary (50 chars max)</li> <li>Blank line</li> <li>Detailed description</li> <li>Reference issues: <code>Fixes #123</code> or <code>Closes #456</code></li> </ul>"},{"location":"development/contributing/#6-push-and-create-pr","title":"6. Push and Create PR","text":"<pre><code># Push to your fork\ngit push origin feature/my-new-feature\n\n# Go to GitHub and create Pull Request\n</code></pre>"},{"location":"development/contributing/#7-pr-template","title":"7. PR Template","text":"<pre><code>## Description\nBrief description of changes.\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Performance improvement\n- [ ] Code refactoring\n\n## Testing\n- [ ] All tests pass\n- [ ] Added new tests for changes\n- [ ] Updated documentation\n- [ ] Tested manually\n\n## Checklist\n- [ ] Code follows project style guide\n- [ ] Self-review completed\n- [ ] Comments added for complex code\n- [ ] Documentation updated\n- [ ] No breaking changes (or documented)\n\n## Related Issues\nFixes #123\nCloses #456\n</code></pre>"},{"location":"development/contributing/#release-process","title":"Release Process","text":""},{"location":"development/contributing/#version-numbering","title":"Version Numbering","text":"<p>We follow ArcadeDB core version:</p> <ul> <li>Version extracted from parent <code>pom.xml</code></li> <li>Format: <code>MAJOR.MINOR.PATCH</code></li> <li>Example: <code>24.11.1</code></li> </ul>"},{"location":"development/contributing/#creating-a-release","title":"Creating a Release","text":"<ol> <li>Update Version</li> </ol> <pre><code># Version automatically extracted during build\npython extract_version.py\n</code></pre> <ol> <li>Build Distributions</li> </ol> <pre><code># Build all distributions\n./build-all.sh all\n\n# Verify wheels\nls -lh dist/\n</code></pre> <ol> <li>Test Installations</li> </ol> <pre><code># Test each wheel\npip install dist/arcadedb_embedded_headless-*.whl\npython -c \"import arcadedb_embedded; print('\u2705 Headless OK')\"\n\npip install dist/arcadedb_embedded_minimal-*.whl\npython -c \"import arcadedb_embedded; print('\u2705 Minimal OK')\"\n\npip install dist/arcadedb_embedded_full-*.whl\npython -c \"import arcadedb_embedded; print('\u2705 Full OK')\"\n</code></pre> <ol> <li>Publish to PyPI</li> </ol> <pre><code># Install twine\npip install twine\n\n# Upload to Test PyPI first\ntwine upload --repository testpypi dist/*\n\n# Test install from Test PyPI\npip install --index-url https://test.pypi.org/simple/ arcadedb-embedded-headless\n\n# Upload to production PyPI\ntwine upload dist/*\n</code></pre>"},{"location":"development/contributing/#common-tasks","title":"Common Tasks","text":""},{"location":"development/contributing/#adding-a-new-feature","title":"Adding a New Feature","text":"<ol> <li>Create feature branch</li> <li>Implement feature in <code>src/arcadedb_embedded/</code></li> <li>Add tests in <code>tests/</code></li> <li>Update documentation in <code>docs/</code></li> <li>Add example in <code>examples/</code> (if applicable)</li> <li>Submit PR</li> </ol>"},{"location":"development/contributing/#fixing-a-bug","title":"Fixing a Bug","text":"<ol> <li>Write failing test that reproduces bug</li> <li>Fix bug in source code</li> <li>Verify test now passes</li> <li>Update documentation if needed</li> <li>Submit PR with test + fix</li> </ol>"},{"location":"development/contributing/#adding-documentation","title":"Adding Documentation","text":"<ol> <li>Create/update Markdown files in <code>docs/</code></li> <li>Add to <code>mkdocs.yml</code> navigation</li> <li>Test locally: <code>mkdocs serve</code></li> <li>Submit PR</li> </ol>"},{"location":"development/contributing/#updating-dependencies","title":"Updating Dependencies","text":"<pre><code># Update JPype\npip install --upgrade jpype1\n\n# Update dev dependencies\npip install --upgrade pytest black mypy\n\n# Update in pyproject.toml\n[project]\ndependencies = [\n    \"jpype1&gt;=1.5.0\",  # Update version\n]\n</code></pre>"},{"location":"development/contributing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/contributing/#jvm-errors","title":"JVM Errors","text":"<pre><code># Check Java version\njava -version  # Must be 11+\n\n# Set JAVA_HOME\nexport JAVA_HOME=/path/to/jdk-11\n</code></pre>"},{"location":"development/contributing/#build-errors","title":"Build Errors","text":"<pre><code># Clean build artifacts\nrm -rf dist/ build/ *.egg-info\n\n# Remove cached JARs\nrm -rf src/arcadedb_embedded/jars/\n\n# Rebuild\n./build-all.sh headless\n</code></pre>"},{"location":"development/contributing/#test-failures","title":"Test Failures","text":"<pre><code># Run specific test with verbose output\npytest tests/test_core.py::test_create_database -vv\n\n# Run with debugging\npytest --pdb tests/test_core.py\n\n# Check test coverage\npytest --cov=arcadedb_embedded --cov-report=term-missing\n</code></pre>"},{"location":"development/contributing/#docker-issues","title":"Docker Issues","text":"<pre><code># Clean Docker cache\ndocker system prune -a\n\n# Rebuild without cache\ndocker build --no-cache -f Dockerfile.build ../..\n</code></pre>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: https://docs.arcadedb.com</li> <li>GitHub Issues: https://github.com/humemai/arcadedb/issues</li> <li>Discord: https://discord.gg/arcadedb</li> <li>Email: info@arcadedata.com</li> </ul>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers</li> <li>Accept constructive criticism</li> <li>Focus on what's best for the community</li> <li>Show empathy towards others</li> </ul>"},{"location":"development/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache License 2.0.</p>"},{"location":"development/contributing/#see-also","title":"See Also","text":"<ul> <li>Architecture - System architecture</li> <li>Troubleshooting - Common issues</li> <li>API Reference - API documentation</li> </ul>"},{"location":"development/documentation/","title":"Documentation Development","text":"<p>This guide explains how to work with the MkDocs Material documentation for ArcadeDB Python bindings.</p>"},{"location":"development/documentation/#documentation-structure","title":"Documentation Structure","text":"<pre><code>bindings/python/\n\u251c\u2500\u2500 docs/              # Documentation source\n\u2502   \u251c\u2500\u2500 index.md       # Homepage\n\u2502   \u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 guide/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 development/\n\u251c\u2500\u2500 mkdocs.yml         # MkDocs configuration\n\u2514\u2500\u2500 site/              # Built documentation (gitignored)\n</code></pre>"},{"location":"development/documentation/#local-development","title":"Local Development","text":""},{"location":"development/documentation/#preview-documentation","title":"Preview Documentation","text":"<p>Run a local development server with live reload:</p> <pre><code>cd bindings/python\nmkdocs serve\n</code></pre> <p>Then open: http://127.0.0.1:8000/arcadedb/</p> <p>Any changes to <code>.md</code> files will automatically refresh in your browser!</p>"},{"location":"development/documentation/#build-documentation","title":"Build Documentation","text":"<p>Build the static site to verify there are no errors:</p> <pre><code>mkdocs build --strict\n</code></pre> <p>The built site will be in <code>site/</code> directory.</p>"},{"location":"development/documentation/#check-for-issues","title":"Check for Issues","text":"<pre><code># Check for broken links\nmkdocs build --strict\n\n# Validate configuration\nmkdocs --version\n</code></pre>"},{"location":"development/documentation/#versioned-documentation","title":"Versioned Documentation","text":"<p>Documentation is versioned using mike and automatically deployed when you create release tags.</p>"},{"location":"development/documentation/#how-it-works","title":"How It Works","text":"<ol> <li>Create a GitHub Release with tag like <code>python-X.Y.Z</code></li> <li>GitHub Actions automatically:</li> <li>Builds documentation with MkDocs</li> <li>Deploys version <code>X.Y.Z</code> to GitHub Pages</li> <li>Sets it as the <code>latest</code> version</li> <li> <p>Updates version selector</p> </li> <li> <p>Users can view:</p> </li> <li>Latest stable docs: https://humemai.github.io/arcadedb/</li> <li>Specific version: https://humemai.github.io/arcadedb/X.Y.Z/</li> <li>Version selector in top-right corner</li> </ol>"},{"location":"development/documentation/#deployment-workflow","title":"Deployment Workflow","text":"<p>Automatic deployment (recommended):</p> <pre><code># 1. Make documentation changes on python-embedded branch\n# 2. Build and test wheels\n./build-all.sh headless\npytest\n\n# 3. Commit and push changes\ngit add .\ngit commit -m \"Release version X.Y.Z\"\ngit push origin python-embedded\n\n# 4. Create GitHub Release (creates tag automatically)\ngh release create python-X.Y.Z \\\n  --title \"Python Bindings vX.Y.Z\" \\\n  --notes \"Release notes\"\n\n# \u2705 Docs automatically deploy to:\n# https://humemai.github.io/arcadedb/X.Y.Z/ (versioned)\n# https://humemai.github.io/arcadedb/ (redirects to latest)\n</code></pre> <p>Manual deployment (for testing):</p> <p>You can manually trigger deployment from GitHub Actions:</p> <ol> <li>Go to Actions \u2192 Deploy MkDocs to GitHub Pages</li> <li>Click Run workflow</li> <li>Choose:</li> <li>Version: <code>dev</code> (or any version name)</li> <li>Set as latest: <code>false</code> (to keep as separate version)</li> </ol> <p>This creates a test deployment without affecting the stable docs.</p>"},{"location":"development/documentation/#version-management","title":"Version Management","text":"<p>List all deployed versions:</p> <pre><code>cd bindings/python\nmike list\n</code></pre> <p>Delete a version (requires push access):</p> <pre><code># Replace X.Y.Z with version to delete\nmike delete X.Y.Z --push\n</code></pre> <p>Set a different version as default:</p> <pre><code># Replace X.Y.Z with version to set as default\nmike set-default X.Y.Z --push\n</code></pre>"},{"location":"development/documentation/#version-alignment","title":"Version Alignment","text":"<p>Documentation versions match PyPI package versions:</p> Release Tag Docs Version PyPI Packages <code>python-X.Y.Z</code> <code>X.Y.Z</code> <code>arcadedb-embedded-*==X.Y.Z</code> Example: <code>v25.9.1-python</code> <code>25.9.1</code> <code>arcadedb-embedded-*==25.9.1</code> <p>This ensures users always see documentation matching their installed package version.</p>"},{"location":"development/documentation/#writing-documentation","title":"Writing Documentation","text":""},{"location":"development/documentation/#style-guide","title":"Style Guide","text":"<p>Tone:</p> <ul> <li>Friendly and approachable</li> <li>Use \"you\" to address the reader</li> <li>Keep sentences concise</li> <li>Use active voice</li> </ul> <p>Code Examples:</p> <ul> <li>Show complete, runnable examples</li> <li>Include imports and setup</li> <li>Add comments for complex logic</li> <li>Use realistic variable names</li> </ul> <p>Organization:</p> <ul> <li>Start with simple concepts</li> <li>Build to more complex topics</li> <li>Use clear headings</li> <li>Add navigation hints</li> </ul>"},{"location":"development/documentation/#markdown-features","title":"Markdown Features","text":""},{"location":"development/documentation/#admonitions-callouts","title":"Admonitions (Callouts)","text":"<pre><code>!!! note \"Title (optional)\"\n    This is a note with a custom title.\n\n!!! tip\n    This is a helpful tip.\n\n!!! warning\n    This is a warning.\n\n!!! danger\n    This is a critical warning.\n\n!!! info\n    This is informational.\n\n!!! success\n    This indicates success.\n</code></pre>"},{"location":"development/documentation/#code-blocks-with-tabs","title":"Code Blocks with Tabs","text":"<pre><code>=== \"Python\"\n\n    ```python\n    import arcadedb_embedded as arcadedb\n    ```\n\n=== \"SQL\"\n\n    ```sql\n    SELECT * FROM User;\n    ```\n</code></pre>"},{"location":"development/documentation/#code-block-highlighting","title":"Code Block Highlighting","text":"<pre><code># Line highlighting\n```python hl_lines=\"2 3\"\nimport arcadedb_embedded as arcadedb\ndb = arcadedb.create_database(\"./mydb\")  # (1)!\ndb.close()\n</code></pre> <ol> <li>Creates a new database in the current directory <pre><code>\\```\n\n#### Tables\n\n```markdown\n| Feature | Headless | Minimal | Full |\n|---------|----------|---------|------|\n| SQL | \u2705 Yes | \u2705 Yes | \u2705 Yes |\n| Gremlin | \u274c No | \u274c No | \u2705 Yes |\n</code></pre></li> </ol>"},{"location":"development/documentation/#internal-links","title":"Internal Links","text":"<pre><code>See [Installation Guide](../getting-started/installation.md) for details.\n\nLink to a specific section: [Testing](testing.md#quick-start)\n</code></pre>"},{"location":"development/documentation/#external-links","title":"External Links","text":"<pre><code>Check the [official ArcadeDB docs](https://docs.arcadedb.com) for more.\n</code></pre>"},{"location":"development/documentation/#api-documentation","title":"API Documentation","text":"<p>When documenting API methods, use this structure:</p> <pre><code>## method_name()\n\nBrief one-line description.\n\n**Signature:**\n```python\nmethod_name(param1: type, param2: type = default) -&gt; ReturnType\n\\```\n\n**Parameters:**\n\n- `param1` (type): Description of param1\n- `param2` (type, optional): Description of param2. Defaults to `default`.\n\n**Returns:**\n\n- `ReturnType`: Description of return value\n\n**Raises:**\n\n- `ExceptionType`: When this exception occurs\n\n**Example:**\n```python\nresult = obj.method_name(\"value\", param2=True)\n\\```\n\n**See Also:**\n\n- [Related Method](related.md)\n\\```\n\n## Testing Documentation\n\n### Verify All Links Work\n\n```bash\n# Build with strict mode (fails on warnings)\nmkdocs build --strict\n</code></pre>"},{"location":"development/documentation/#check-mobile-responsiveness","title":"Check Mobile Responsiveness","text":"<p>The Material theme is mobile-responsive by default. Test by:</p> <ol> <li>Run <code>mkdocs serve</code></li> <li>Open in browser</li> <li>Use browser DevTools responsive mode (F12 \u2192 Toggle device toolbar)</li> <li>Test navigation, search, code blocks on mobile sizes</li> </ol>"},{"location":"development/documentation/#test-search","title":"Test Search","text":"<ol> <li>Run <code>mkdocs serve</code></li> <li>Click search icon (or press <code>/</code>)</li> <li>Search for key terms</li> <li>Verify results are relevant</li> </ol>"},{"location":"development/documentation/#continuous-integration","title":"Continuous Integration","text":"<p>Documentation is automatically validated on every push via GitHub Actions:</p> <ul> <li>Build check: Ensures documentation builds without errors</li> <li>Version deployment: Deploys on tagged releases</li> <li>Link validation: Checks for broken links (TODO)</li> </ul>"},{"location":"development/documentation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/documentation/#config-file-not-found","title":"\"Config file not found\"","text":"<p>Make sure you're in <code>bindings/python/</code> directory:</p> <pre><code>cd bindings/python\nmkdocs serve\n</code></pre>"},{"location":"development/documentation/#module-not-found-error","title":"\"Module not found\" error","text":"<p>Install dependencies:</p> <pre><code>pip install mkdocs-material mkdocs-git-revision-date-localized-plugin\n</code></pre>"},{"location":"development/documentation/#changes-not-appearing","title":"Changes not appearing","text":"<ol> <li>Check file is saved</li> <li>Check terminal for build errors</li> <li>Hard refresh browser (Ctrl+Shift+R)</li> <li>Restart <code>mkdocs serve</code></li> </ol>"},{"location":"development/documentation/#version-selector-not-showing","title":"Version selector not showing","text":"<p>The version selector appears after deploying at least 2 versions with mike:</p> <pre><code># Example: Deploy two versions\nmike deploy X.Y.Z latest\nmike deploy dev\n</code></pre>"},{"location":"development/documentation/#next-steps","title":"Next Steps","text":"<ul> <li>Contributing Guide - How to contribute</li> <li>Testing Guide - Running tests</li> <li>MkDocs Material Reference - Full documentation</li> <li>mike Documentation - Versioning tool</li> </ul>"},{"location":"development/release/","title":"Release Workflow","text":"<p>Complete workflow for releasing ArcadeDB Python bindings to PyPI with versioned documentation.</p>"},{"location":"development/release/#prerequisites","title":"Prerequisites","text":"<ul> <li>Push access to the repository</li> <li>PyPI environments configured in GitHub (pypi-headless, pypi-minimal, pypi-full)</li> <li>Trusted publisher setup on PyPI (automatic authentication)</li> </ul>"},{"location":"development/release/#release-checklist","title":"Release Checklist","text":""},{"location":"development/release/#1-prepare-release","title":"1. Prepare Release","text":"<p>On <code>python-embedded</code> branch:</p> <ul> <li> Version is already set in <code>pom.xml</code> (e.g., <code>X.Y.Z-SNAPSHOT</code>)</li> <li> Run full test suite across all distributions</li> <li> Update <code>CHANGELOG.md</code> or prepare release notes</li> <li> Update documentation if needed</li> <li> Commit all changes</li> </ul> <pre><code>cd bindings/python\n\n# Build all distributions\n./build-all.sh headless\n./build-all.sh minimal\n./build-all.sh full\n\n# Test each distribution\npip install dist/arcadedb_embedded_headless-*.whl\npytest  # 34 passed, 7 skipped\n\npip install --force-reinstall dist/arcadedb_embedded_minimal-*.whl\npytest  # 38 passed, 3 skipped\n\npip install --force-reinstall dist/arcadedb_embedded_full-*.whl\npytest  # 41 passed, 0 skipped\n</code></pre> <p>Note: Version is automatically extracted from <code>pom.xml</code> by <code>extract_version.py</code> during build. The <code>-SNAPSHOT</code> suffix is converted to <code>.dev0</code> for PEP 440 compliance.</p>"},{"location":"development/release/#2-create-github-release","title":"2. Create GitHub Release","text":"<p>Instead of pushing tags manually, create a GitHub Release which automatically creates the tag and triggers deployments.</p> <p>Option A: Using GitHub Web UI (Recommended)</p> <ol> <li>Go to Releases</li> <li>Click Draft a new release</li> <li> <p>Click Choose a tag dropdown</p> </li> <li> <p>Click Choose a tag \u2192 Type <code>vX.Y.Z-python</code> \u2192 Create new tag</p> </li> <li>Target: <code>python-embedded</code></li> <li>Release title: <code>Python release vX.Y.Z</code></li> <li>Description/Release notes:</li> </ol> <pre><code>## What's New\n\n- Feature: Description\n- Fix: Description\n- Docs: Description\n\n## Installation\n\npip install arcadedb-embedded-headless\n\n## Documentation\n\nhttps://humemai.github.io/arcadedb/\n\n## Test Results\n\n- Headless: 34/41 passed (7 skipped)\n- Minimal: 38/41 passed (3 skipped)\n- Full: 41/41 passed\n</code></pre> <ol> <li>Click Publish release (or Save as draft to test first)</li> </ol> <p>Option B: Using GitHub CLI</p> <pre><code># Commit final changes\ngit add .\ngit commit -m \"Release Python bindings vX.Y.Z\"\ngit push origin python-embedded\n\n# Create annotated tag\ngit tag -a vX.Y.Z-python -m \"Python release vX.Y.Z\"\ngit push origin vX.Y.Z-python\n\n# Create release from tag\ngh release create vX.Y.Z-python \\\n  --target python-embedded \\\n  --title \"Python release vX.Y.Z\" \\\n  --notes \"## What's New\n\n- Feature: Description\n- Fix: Description\n</code></pre>"},{"location":"development/release/#installation","title":"Installation","text":"<pre><code>pip install arcadedb-embedded-headless\n</code></pre>"},{"location":"development/release/#documentation","title":"Documentation","text":"<p>https://humemai.github.io/arcadedb/</p>"},{"location":"development/release/#test-results","title":"Test Results","text":"<ul> <li>Headless: 34/41 passed</li> <li>Minimal: 38/41 passed  </li> <li>Full: 41/41 passed\"</li> </ul> <p>What happens automatically:</p> <ul> <li>\u2705 Git tag <code>vX.Y.Z-python</code> is created (annotated tag)</li> <li>\u2705 PyPI workflow builds and uploads all 3 distributions</li> <li>\u2705 Docs workflow deploys versioned documentation</li> </ul>"},{"location":"development/release/#3-monitor-github-actions","title":"3. Monitor GitHub Actions","text":"<p>Two workflows trigger automatically when you publish the release:</p> <p>PyPI Deployment (<code>.github/workflows/release-python-packages.yml</code>):</p> <ol> <li>Builds all 3 distributions in parallel (using Docker)</li> <li>Publishes to PyPI:</li> <li><code>arcadedb-embedded-headless</code></li> <li><code>arcadedb-embedded-minimal</code></li> <li><code>arcadedb-embedded</code> (full)</li> </ol> <p>Documentation Deployment (<code>.github/workflows/deploy-python-docs.yml</code>):</p> <ol> <li>Extracts version from release tag (e.g., <code>vX.Y.Z-python</code> \u2192 <code>X.Y.Z</code>)</li> <li>Builds documentation with MkDocs + mike</li> <li>Deploys to GitHub Pages with version number</li> <li>Sets as <code>latest</code> version</li> <li>Updates version selector dropdown</li> </ol> <p>Check progress:</p> <ul> <li>Go to GitHub \u2192 Actions tab</li> <li>Monitor both workflows</li> <li>Check for any failures</li> <li>Typical duration: 10-15 minutes total</li> </ul>"},{"location":"development/release/#4-verify-deployment","title":"4. Verify Deployment","text":"<p>PyPI Packages:</p> <pre><code># Check packages are live (replace VERSION with your version)\npip index versions arcadedb-embedded-headless\n\n# Test installation\npip install arcadedb-embedded-headless\npython -c \"import arcadedb_embedded as arcadedb; print(arcadedb.__version__)\"\n</code></pre> <p>Documentation:</p> <p>Visit: - Latest: https://humemai.github.io/arcadedb/ - Versioned: https://humemai.github.io/arcadedb/VERSION/ (replace VERSION)</p> <p>Check: - [ ] Version selector shows your version as <code>(latest)</code> - [ ] All pages load correctly - [ ] Search works - [ ] Code examples render properly - [ ] Links work (internal and external)</p>"},{"location":"development/release/#5-post-release","title":"5. Post-Release","text":"<p>Update Development Version:</p> <pre><code># Bump version in pom.xml for next development cycle\n# e.g., X.Y.Z-SNAPSHOT \u2192 X.Y.Z+1-SNAPSHOT (or whatever next version is)\n\n# Edit pom.xml, change &lt;version&gt; in parent POM\nvim pom.xml\n\ngit add pom.xml\ngit commit -m \"Bump version to next development version\"\ngit push origin python-embedded\n</code></pre> <p>Announce Release:</p> <ul> <li>Update project README if needed</li> <li>Notify users/community</li> <li>Update any integration guides</li> <li>Optionally add release to CHANGELOG.md</li> </ul>"},{"location":"development/release/#version-numbering","title":"Version Numbering","text":"<p>Python bindings follow the ArcadeDB main project version from <code>pom.xml</code>:</p> <ul> <li>Format: <code>MAJOR.MINOR.PATCH</code></li> <li>POM version: <code>X.Y.Z-SNAPSHOT</code> (development)</li> <li>Git tag: <code>vX.Y.Z-python</code> (follows git best practices with <code>v</code> prefix)</li> <li>Release tag: <code>vX.Y.Z-python</code> (GitHub Release)</li> <li>PyPI version: <code>X.Y.Z</code> (extracted automatically, no <code>v</code> prefix)</li> <li>Docs version: <code>X.Y.Z</code> (extracted from tag, no <code>v</code> prefix)</li> </ul> <p>How version is determined:</p> <ol> <li>Set in <code>pom.xml</code> root: <code>&lt;version&gt;X.Y.Z-SNAPSHOT&lt;/version&gt;</code></li> <li><code>extract_version.py</code> converts: <code>X.Y.Z-SNAPSHOT</code> \u2192 <code>X.Y.Z.dev0</code> (PEP 440)</li> <li>Create annotated tag: <code>git tag -a vX.Y.Z-python -m \"Python release vX.Y.Z\"</code></li> <li>GitHub Release tag: <code>vX.Y.Z-python</code> (with <code>v</code> prefix)</li> <li>Workflows extract: <code>vX.Y.Z-python</code> \u2192 <code>X.Y.Z</code> (strip prefix/suffix)</li> <li>Used everywhere: PyPI (<code>X.Y.Z</code>), docs (<code>/X.Y.Z/</code>)</li> </ol> <p>When to bump:</p> <ul> <li>MAJOR: Breaking API changes</li> <li>MINOR: New features, non-breaking</li> <li>PATCH: Bug fixes only</li> </ul> <p>Note: Version is only in ONE place (<code>pom.xml</code>) - everything else extracts it automatically!</p>"},{"location":"development/release/#hotfix-release","title":"Hotfix Release","text":"<p>For urgent bug fixes on a released version:</p> <pre><code># 1. Create hotfix branch from tag\ngit checkout -b hotfix/X.Y.Z+1 vX.Y.Z-python\n\n# 2. Make fixes, update version in pom.xml\nvim pom.xml  # Change to X.Y.Z+1-SNAPSHOT\n\n# 3. Test thoroughly\ncd bindings/python\n./build-all.sh full &amp;&amp; pytest\n\n# 4. Commit and create hotfix release\ngit commit -am \"Hotfix: description\"\ngit push origin hotfix/X.Y.Z+1\n\n# 5. Create annotated tag\ngit tag -a vX.Y.Z+1-python -m \"Python hotfix release vX.Y.Z+1\"\ngit push origin vX.Y.Z+1-python\n\n# 6. Create GitHub Release\ngh release create vX.Y.Z+1-python \\\n  --target hotfix/X.Y.Z+1 \\\n  --title \"Python hotfix release vX.Y.Z+1\" \\\n  --notes \"Hotfix for critical bug in X.Y.Z\"\n\n# 7. Merge back to python-embedded\ngit checkout python-embedded\ngit merge hotfix/X.Y.Z+1\ngit push origin python-embedded\n</code></pre>"},{"location":"development/release/#rolling-back-a-release","title":"Rolling Back a Release","text":"<p>If you need to roll back a broken release:</p> <p>PyPI (cannot delete, but can yank):</p> <pre><code># Install twine\npip install twine\n\n# Yank the release (makes it unavailable for new installs)\ntwine yank arcadedb-embedded-headless 25.9.1\n</code></pre> <p>Documentation (can delete version):</p> <pre><code>cd bindings/python\n\n# Install mike\npip install mike\n\n# Delete version from docs\nmike delete 25.9.1 --push\n\n# Set previous version as latest\nmike set-default 25.9.0 --push\n</code></pre> <p>GitHub Release:</p> <ol> <li>Go to Releases</li> <li>Edit the release</li> <li>Check \"Set as a pre-release\"</li> <li>Or delete the release entirely</li> </ol>"},{"location":"development/release/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/release/#pypi-upload-fails","title":"PyPI upload fails","text":"<p>Size limit exceeded:</p> <ul> <li>Full distribution might hit PyPI limits (~158 MB)</li> <li>Request size increase: https://pypi.org/help/#file-size-limit</li> <li>Or distribute via GitHub releases only</li> </ul> <p>Authentication error:</p> <ul> <li>Check GitHub environment secrets</li> <li>Verify trusted publisher configuration</li> <li>Check PyPI API tokens</li> </ul>"},{"location":"development/release/#documentation-deployment-fails","title":"Documentation deployment fails","text":"<p>mike command error:</p> <ul> <li>Ensure <code>git config</code> is set in workflow</li> <li>Check branch permissions</li> <li>Verify <code>gh-pages</code> branch exists</li> </ul> <p>Version not appearing:</p> <ul> <li>Check GitHub Actions logs</li> <li>Verify tag format: <code>python-*</code></li> <li>Manually run: <code>mike list</code> to see deployed versions</li> </ul> <p>Broken links:</p> <ul> <li>Run <code>mkdocs build --strict</code> locally first</li> <li>Check all internal links use correct paths</li> <li>Verify external URLs are accessible</li> </ul>"},{"location":"development/release/#build-failures","title":"Build failures","text":"<p>Docker build error:</p> <ul> <li>Check Docker daemon is running</li> <li>Verify Dockerfile.build syntax</li> <li>Check Maven dependencies are available</li> </ul> <p>Test failures:</p> <ul> <li>Run specific test: <code>pytest tests/test_core.py::test_name -v</code></li> <li>Check logs in <code>bindings/python/log/</code></li> <li>Verify Java JDK 11+ is available</li> </ul>"},{"location":"development/release/#automation-improvements","title":"Automation Improvements","text":"<p>Future enhancements:</p> <ul> <li> Automated changelog generation from commits</li> <li> Automated version bump on merge</li> <li> Integration tests before PyPI upload</li> <li> Automated link checking in docs</li> <li> Release notes template</li> <li> Slack/Discord notifications on release</li> </ul>"},{"location":"development/release/#see-also","title":"See Also","text":"<ul> <li>Documentation Development - Working with MkDocs</li> <li>Testing Guide - Running test suite</li> <li>Contributing Guide - Development workflow</li> <li>GitHub Actions Docs</li> <li>PyPI Publishing Guide</li> </ul>"},{"location":"development/testing/","title":"Testing Guide","text":"<p>Comprehensive testing documentation for ArcadeDB Python bindings.</p> <p>Test Coverage</p> <p>41 tests across 6 test files, 100% passing</p> <ul> <li>Headless: 34 passed, 7 skipped</li> <li>Minimal: 38 passed, 3 skipped  </li> <li>Full: 41 passed, 0 skipped</li> </ul>"},{"location":"development/testing/#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> Overview</p> <p>Quick start, statistics, and how to run tests</p> </li> <li> <p> Core Tests</p> <p>CRUD, transactions, queries, graph operations (13 tests)</p> </li> <li> <p> Server Tests</p> <p>HTTP API, Studio, configuration (6 tests)</p> </li> <li> <p> Concurrency Tests</p> <p>File locking, thread safety, multi-process (4 tests)</p> </li> <li> <p> Server Patterns</p> <p>Embedded + HTTP best practices (4 tests)</p> </li> <li> <p> Data Import Tests</p> <p>CSV, JSON, JSONL, Neo4j import (13 tests)</p> </li> <li> <p> Gremlin Tests</p> <p>Graph traversal language (1 test, full only)</p> </li> <li> <p> Best Practices</p> <p>Summary of recommended patterns and practices</p> </li> </ul>"},{"location":"development/testing/#quick-start","title":"Quick Start","text":""},{"location":"development/testing/#installation","title":"Installation","text":"<pre><code># Install test dependencies\npip install pytest pytest-cov\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run specific category\npytest tests/test_core.py -v\npytest tests/test_concurrency.py -v\n\n# Run with coverage\npytest --cov=arcadedb_embedded --cov-report=html\n</code></pre>"},{"location":"development/testing/#test-coverage-summary","title":"Test Coverage Summary","text":"Category What's Tested Core Operations CRUD, transactions, queries, graph operations, vector search Server Mode HTTP API, Studio UI, configuration, multiple databases Concurrency File locking, thread safety, multi-process limitations Server Patterns Embedded+HTTP combinations, lock management Data Import CSV, JSON, JSONL, Neo4j exports with type inference Query Languages SQL, Cypher (when available), Gremlin (full only) Advanced Features Unicode support, schema introspection, large datasets"},{"location":"development/testing/#key-concepts","title":"Key Concepts","text":""},{"location":"development/testing/#concurrency-model","title":"Concurrency Model","text":"<p>Can multiple Python instances access the same database?</p> <ul> <li>\u274c Multiple processes cannot (file lock prevents it)</li> <li>\u2705 Multiple threads can (thread-safe within same process)</li> <li>\u2705 Use server mode for true multi-process access</li> </ul> <p>See Concurrency Tests for details.</p>"},{"location":"development/testing/#server-access-patterns","title":"Server Access Patterns","text":"<p>Two ways to combine embedded + HTTP access:</p> <ol> <li>Pattern 1: Embedded First \u2192 Server (requires manual <code>close()</code>)</li> <li>Pattern 2: Server First \u2192 Create (recommended, simpler)</li> </ol> <p>See Server Patterns for detailed comparison.</p>"},{"location":"development/testing/#performance-insight","title":"Performance Insight","text":"<p>No HTTP Overhead</p> <p>Embedded access through server is just as fast as standalone embedded mode!</p> <p>It's a direct JVM call, not HTTP. Same Python process = zero network overhead.</p>"},{"location":"development/testing/#common-testing-workflows","title":"Common Testing Workflows","text":""},{"location":"development/testing/#development","title":"Development","text":"<pre><code># Run tests matching keyword\npytest -k \"transaction\" -v\npytest -k \"import\" -v\n\n# Stop on first failure\npytest -x\n\n# Drop into debugger on failure\npytest --pdb\n</code></pre>"},{"location":"development/testing/#distribution-specific","title":"Distribution-Specific","text":"<pre><code># Some tests are skipped based on distribution\npytest -v\n# ==================== 38 passed, 3 skipped ====================\n\n# Show skipped test reasons\npytest -v -rs\n</code></pre>"},{"location":"development/testing/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_core.py              # Core operations (13 tests)\n\u251c\u2500\u2500 test_server.py            # Server mode (6 tests)\n\u251c\u2500\u2500 test_concurrency.py       # Concurrency (4 tests)\n\u251c\u2500\u2500 test_server_patterns.py   # Patterns (4 tests)\n\u251c\u2500\u2500 test_importer.py          # Import (13 tests)\n\u251c\u2500\u2500 test_gremlin.py           # Gremlin (1 test)\n\u2514\u2500\u2500 conftest.py               # Shared fixtures\n</code></pre>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<p>New to testing? Start with Overview</p> <p>Working with databases? See Core Tests</p> <p>Need multi-process access? Read Concurrency Tests</p> <p>Setting up a server? Check Server Patterns</p> <p>Importing data? See Data Import Tests</p> <p>Want best practices? Read Best Practices Summary</p>"},{"location":"development/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues, solutions, and debugging techniques for ArcadeDB Python bindings.</p>"},{"location":"development/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"development/troubleshooting/#java-not-found","title":"Java Not Found","text":"<p>Symptom: <pre><code>Error: Java Runtime Environment (JRE) not found\n</code></pre></p> <p>Solution:</p> <p>Ubuntu/Debian: <pre><code>sudo apt-get update\nsudo apt-get install default-jre-headless\n</code></pre></p> <p>macOS: <pre><code>brew install openjdk\n</code></pre></p> <p>Windows: Download and install from java.com</p> <p>Verify: <pre><code>java -version\n</code></pre></p>"},{"location":"development/troubleshooting/#wrong-package-installed","title":"Wrong Package Installed","text":"<p>Symptom: <pre><code>import arcadedb_embedded\n# Missing features or import errors\n</code></pre></p> <p>Solution:</p> <p>Uninstall all variants first: <pre><code>pip uninstall -y arcadedb-embedded arcadedb-embedded-headless arcadedb-embedded-minimal\n</code></pre></p> <p>Then install the one you need: <pre><code># Smallest (~94MB, no Gremlin/GraphQL)\npip install arcadedb-embedded-headless\n\n# Full features (~158MB, includes everything)\npip install arcadedb-embedded\n</code></pre></p>"},{"location":"development/troubleshooting/#jpype-installation-fails","title":"JPype Installation Fails","text":"<p>Symptom: <pre><code>ERROR: Failed building wheel for JPype1\n</code></pre></p> <p>Solution:</p> <p>Install build dependencies first:</p> <p>Ubuntu/Debian: <pre><code>sudo apt-get install python3-dev build-essential\npip install JPype1\n</code></pre></p> <p>macOS: <pre><code>xcode-select --install\npip install JPype1\n</code></pre></p> <p>Windows: Install Visual Studio Build Tools, then: <pre><code>pip install JPype1\n</code></pre></p>"},{"location":"development/troubleshooting/#runtime-errors","title":"Runtime Errors","text":""},{"location":"development/troubleshooting/#jvm-already-started","title":"JVM Already Started","text":"<p>Symptom: <pre><code>jpype._core.JVMNotRunning: Unable to start JVM - already started\n</code></pre></p> <p>Cause: Attempting to configure JVM after it's already started.</p> <p>Solution:</p> <p>Configure JVM options before first import: <pre><code>import jpype\n\n# Configure BEFORE importing arcadedb_embedded\njpype.addClassPath(\"/path/to/extra.jar\")\n\n# Now import\nimport arcadedb_embedded as arcadedb\n</code></pre></p> <p>Alternative: Use separate processes for different JVM configurations: <pre><code>import multiprocessing as mp\n\ndef with_custom_jvm(jar_path):\n    import jpype\n    jpype.addClassPath(jar_path)\n\n    import arcadedb_embedded as arcadedb\n    # Use arcadedb here\n\nif __name__ == \"__main__\":\n    p = mp.Process(target=with_custom_jvm, args=(\"/path/to/jar\",))\n    p.start()\n    p.join()\n</code></pre></p>"},{"location":"development/troubleshooting/#database-already-exists","title":"Database Already Exists","text":"<p>Symptom: <pre><code>arcadedb.create_database(\"./mydb\")\n# ArcadeDBError: Database already exists\n</code></pre></p> <p>Solution:</p> <p>Use <code>open_database()</code> instead: <pre><code>import os\nimport arcadedb_embedded as arcadedb\n\nif os.path.exists(\"./mydb\"):\n    db = arcadedb.open_database(\"./mydb\")\nelse:\n    db = arcadedb.create_database(\"./mydb\")\n</code></pre></p> <p>Or delete existing database: <pre><code>import shutil\n\n# Remove existing database\nif os.path.exists(\"./mydb\"):\n    shutil.rmtree(\"./mydb\")\n\n# Create fresh database\ndb = arcadedb.create_database(\"./mydb\")\n</code></pre></p>"},{"location":"development/troubleshooting/#database-locked","title":"Database Locked","text":"<p>Symptom: <pre><code>ArcadeDBError: Database is locked by another process\n</code></pre></p> <p>Cause: Another process has the database open.</p> <p>Solution:</p> <ol> <li> <p>Close other connections: <pre><code># Ensure previous database is closed\ndb.close()\n</code></pre></p> </li> <li> <p>Check for orphaned processes: <pre><code># Linux/macOS\nps aux | grep python\nkill &lt;PID&gt;\n\n# Windows\ntasklist | findstr python\ntaskkill /PID &lt;PID&gt;\n</code></pre></p> </li> <li> <p>Remove lock file (last resort): <pre><code># Only if you're sure no process is using the database\nrm ./mydb/.lock\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#transaction-already-active","title":"Transaction Already Active","text":"<p>Symptom: <pre><code>with db.transaction():\n    with db.transaction():  # Nested!\n        pass\n# ArcadeDBError: Transaction already active\n</code></pre></p> <p>Cause: Nested transactions not supported.</p> <p>Solution:</p> <p>Don't nest transactions: <pre><code># Bad\nwith db.transaction():\n    some_operation()\n    with db.transaction():  # \u2717 Error\n        another_operation()\n\n# Good\nwith db.transaction():\n    some_operation()\n    another_operation()\n</code></pre></p> <p>Or use separate transaction blocks: <pre><code>with db.transaction():\n    some_operation()\n\n# First transaction committed\n\nwith db.transaction():\n    another_operation()\n</code></pre></p>"},{"location":"development/troubleshooting/#query-syntax-error","title":"Query Syntax Error","text":"<p>Symptom: <pre><code>db.query(\"sql\", \"SELECT * FROM User WHERE name = Alice\")\n# ArcadeDBError: Syntax error near 'Alice'\n</code></pre></p> <p>Cause: String not properly quoted.</p> <p>Solution:</p> <p>Use parameters (RECOMMENDED): <pre><code>db.query(\"sql\", \n    \"SELECT FROM User WHERE name = :name\",\n    {\"name\": \"Alice\"}\n)\n</code></pre></p> <p>Or quote strings in SQL: <pre><code>db.query(\"sql\", \"SELECT FROM User WHERE name = 'Alice'\")\n#                                              \u2191    \u2191 quotes\n</code></pre></p>"},{"location":"development/troubleshooting/#type-conversion-error","title":"Type Conversion Error","text":"<p>Symptom: <pre><code>vertex.set(\"embedding\", numpy_array)\n# TypeError: Cannot convert numpy.ndarray to Java type\n</code></pre></p> <p>Cause: NumPy arrays need explicit conversion.</p> <p>Solution:</p> <p>Use conversion utilities: <pre><code>from arcadedb_embedded import to_java_float_array\nimport numpy as np\n\nembedding = np.array([1.0, 2.0, 3.0], dtype=np.float32)\nvertex.set(\"embedding\", to_java_float_array(embedding))\n</code></pre></p>"},{"location":"development/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"development/troubleshooting/#slow-queries","title":"Slow Queries","text":"<p>Symptom: Queries take seconds or minutes.</p> <p>Diagnosis:</p> <p>Use EXPLAIN to analyze: <pre><code>result = db.query(\"sql\", \"EXPLAIN SELECT FROM User WHERE email = 'alice@example.com'\")\nfor row in result:\n    print(row.to_dict())\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Create indexes: <pre><code>with db.transaction():\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n</code></pre></p> </li> <li> <p>Use LIMIT: <pre><code># Bad: Load everything\nresult = db.query(\"sql\", \"SELECT FROM User\")\n\n# Good: Limit results\nresult = db.query(\"sql\", \"SELECT FROM User LIMIT 100\")\n</code></pre></p> </li> <li> <p>Project only needed fields: <pre><code># Bad: Load all properties\nresult = db.query(\"sql\", \"SELECT FROM User\")\n\n# Good: Only needed fields\nresult = db.query(\"sql\", \"SELECT name, email FROM User\")\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#slow-imports","title":"Slow Imports","text":"<p>Symptom: Importing data is very slow.</p> <p>Solutions:</p> <ol> <li> <p>Increase batch size: <pre><code>importer = db.get_importer()\nimporter.batch_size = 10000  # Default is 1000\n</code></pre></p> </li> <li> <p>Drop indexes during import: <pre><code># Drop indexes\nwith db.transaction():\n    db.command(\"sql\", \"DROP INDEX User.email\")\n\n# Import data\nimporter.import_csv(\"users.csv\", \"User\")\n\n# Recreate indexes\nwith db.transaction():\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n</code></pre></p> </li> <li> <p>Use transactions efficiently: <pre><code># Bad: Many small transactions\nfor record in records:\n    with db.transaction():\n        vertex = db.new_vertex(\"Data\")\n        vertex.set(\"data\", record)\n        vertex.save()\n\n# Good: Batch in larger transactions\nbatch_size = 10000\nfor i in range(0, len(records), batch_size):\n    with db.transaction():\n        for record in records[i:i+batch_size]:\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"data\", record)\n            vertex.save()\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptom: Process memory grows continuously.</p> <p>Diagnosis:</p> <p>Monitor memory: <pre><code>import psutil\nimport os\n\nprocess = psutil.Process(os.getpid())\nprint(f\"Memory: {process.memory_info().rss / 1024 / 1024:.1f} MB\")\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Stream large ResultSets: <pre><code># Bad: Load all results\nresult = db.query(\"sql\", \"SELECT FROM LargeTable\")\nall_results = list(result)  # Loads everything!\n\n# Good: Process streaming\nresult = db.query(\"sql\", \"SELECT FROM LargeTable\")\nfor row in result:\n    process(row)\n    # Only one row in memory\n</code></pre></p> </li> <li> <p>Close ResultSets: <pre><code>result = db.query(\"sql\", \"SELECT FROM User\")\nfor row in result:\n    if some_condition(row):\n        break\n# ResultSet automatically closed when iterator exhausted\n</code></pre></p> </li> <li> <p>Force garbage collection: <pre><code>import gc\n\nfor batch in large_dataset:\n    process_batch(batch)\n    gc.collect()  # Trigger GC\n</code></pre></p> </li> <li> <p>Smaller transactions: <pre><code># Bad: Huge transaction\nwith db.transaction():\n    for i in range(1000000):\n        vertex = db.new_vertex(\"Data\")\n        vertex.save()\n\n# Good: Batch transactions\nbatch_size = 10000\nfor i in range(0, 1000000, batch_size):\n    with db.transaction():\n        for j in range(batch_size):\n            vertex = db.new_vertex(\"Data\")\n            vertex.save()\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#server-mode-issues","title":"Server Mode Issues","text":""},{"location":"development/troubleshooting/#server-wont-start","title":"Server Won't Start","text":"<p>Symptom: <pre><code>server = arcadedb.create_server(\"./databases\")\nserver.start()\n# ArcadeDBError: Unable to start server\n</code></pre></p> <p>Solutions:</p> <ol> <li>Check port availability: <pre><code># Linux/macOS\nlsof -i :2480\n\n# Windows\nnetstat -ano | findstr :2480\n</code></pre></li> </ol> <p>Use different port: <pre><code>server = arcadedb.create_server(\n    root_path=\"./databases\",\n    http_port=8080  # Different port\n)\n</code></pre></p> <ol> <li> <p>Check permissions: <pre><code>ls -la ./databases\n# Ensure write permissions\nchmod -R 755 ./databases\n</code></pre></p> </li> <li> <p>Check logs: <pre><code># Enable logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\nserver = arcadedb.create_server(\"./databases\")\nserver.start()\n# Check log output\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#cant-connect-to-server","title":"Can't Connect to Server","text":"<p>Symptom: Server running but can't connect via HTTP.</p> <p>Solutions:</p> <ol> <li> <p>Verify server is running: <pre><code>if server.is_started():\n    print(\"Server is running\")\n    print(f\"URL: http://localhost:{server.http_port}\")\n</code></pre></p> </li> <li> <p>Check firewall: <pre><code># Linux\nsudo ufw allow 2480\n\n# macOS\n# System Preferences &gt; Security &amp; Privacy &gt; Firewall\n</code></pre></p> </li> <li> <p>Test with curl: <pre><code>curl http://localhost:2480/api/v1/server\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#vector-search-issues","title":"Vector Search Issues","text":""},{"location":"development/troubleshooting/#vector-dimension-mismatch","title":"Vector Dimension Mismatch","text":"<p>Symptom: <pre><code>index.add_vertex(vertex)\n# ArcadeDBError: Vector dimension mismatch\n</code></pre></p> <p>Cause: Embedding dimension doesn't match index dimension.</p> <p>Solution:</p> <p>Verify dimensions match: <pre><code>from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Check model dimension\ntest_embedding = model.encode(\"test\")\nprint(f\"Model dimension: {len(test_embedding)}\")  # 384\n\n# Create index with matching dimension\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384  # Must match!\n)\n</code></pre></p>"},{"location":"development/troubleshooting/#poor-search-results","title":"Poor Search Results","text":"<p>Symptom: Vector search returns irrelevant results.</p> <p>Solutions:</p> <ol> <li> <p>Try different distance function: <pre><code># Cosine (default, usually best for text)\nindex = db.create_vector_index(\n    vertex_type=\"Doc\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    distance_function=\"cosine\"\n)\n\n# Euclidean (sometimes better for images)\nindex = db.create_vector_index(\n    vertex_type=\"Image\",\n    vector_property=\"features\",\n    dimensions=512,\n    distance_function=\"euclidean\"\n)\n</code></pre></p> </li> <li> <p>Tune HNSW parameters: <pre><code># Better recall, slower\nindex = db.create_vector_index(\n    vertex_type=\"Doc\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    m=32,              # More connections\n    ef=256,            # Larger search candidates\n    ef_construction=256\n)\n</code></pre></p> </li> <li> <p>Improve embeddings: <pre><code># Combine title and content\ntext = f\"{doc['title']}. {doc['content']}\"\nembedding = model.encode(text)\n\n# vs. just content\nembedding = model.encode(doc['content'])  # May be less effective\n</code></pre></p> </li> </ol>"},{"location":"development/troubleshooting/#debugging","title":"Debugging","text":""},{"location":"development/troubleshooting/#enable-logging","title":"Enable Logging","text":"<p>Python logging: <pre><code>import logging\n\n# Basic logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# File logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    filename='arcadedb.log',\n    filemode='w',\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nimport arcadedb_embedded as arcadedb\n# Now all operations will be logged\n</code></pre></p> <p>Java logging: <pre><code>import jpype\n\n# Enable Java logging before importing arcadedb\njpype.startJVM(\n    classpath=[...],\n    \"-Djava.util.logging.config.file=logging.properties\"\n)\n</code></pre></p> <p>logging.properties: <pre><code>.level=INFO\nhandlers=java.util.logging.ConsoleHandler\njava.util.logging.ConsoleHandler.level=ALL\ncom.arcadedata.level=DEBUG\n</code></pre></p>"},{"location":"development/troubleshooting/#inspect-java-objects","title":"Inspect Java Objects","text":"<pre><code># Get Java class name\njava_obj = vertex._java_vertex\nprint(java_obj.getClass().getName())\n\n# List methods\nfor method in java_obj.getClass().getMethods():\n    print(method.getName())\n\n# Get property value (raw Java)\nvalue = java_obj.get(\"property_name\")\nprint(f\"Type: {type(value)}, Value: {value}\")\n</code></pre>"},{"location":"development/troubleshooting/#transaction-debugging","title":"Transaction Debugging","text":"<pre><code>class DebugTransaction:\n    \"\"\"Debug wrapper for transactions.\"\"\"\n\n    def __init__(self, db):\n        self.db = db\n        self.transaction = None\n\n    def __enter__(self):\n        print(\"Starting transaction\")\n        self.transaction = self.db.transaction()\n        return self.transaction.__enter__()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type:\n            print(f\"Transaction failed: {exc_type.__name__}: {exc_val}\")\n        else:\n            print(\"Transaction committed\")\n        return self.transaction.__exit__(exc_type, exc_val, exc_tb)\n\n# Usage\nwith DebugTransaction(db):\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", \"Alice\")\n    vertex.save()\n</code></pre>"},{"location":"development/troubleshooting/#query-debugging","title":"Query Debugging","text":"<pre><code>def debug_query(db, language, query, params=None):\n    \"\"\"Execute query with debugging.\"\"\"\n    print(f\"Query: {query}\")\n    if params:\n        print(f\"Params: {params}\")\n\n    try:\n        result = db.query(language, query, params)\n        rows = list(result)\n        print(f\"Results: {len(rows)} rows\")\n        return rows\n    except Exception as e:\n        print(f\"Error: {e}\")\n        raise\n\n# Usage\nresults = debug_query(db, \"sql\", \"SELECT FROM User WHERE name = :name\", {\"name\": \"Alice\"})\n</code></pre>"},{"location":"development/troubleshooting/#common-error-messages","title":"Common Error Messages","text":""},{"location":"development/troubleshooting/#property-not-found","title":"\"Property not found\"","text":"<p>Meaning: Trying to get property that doesn't exist.</p> <p>Solution: <pre><code># Check if property exists\nif vertex.has_property(\"name\"):\n    name = vertex.get(\"name\")\nelse:\n    name = \"Unknown\"\n\n# Or use default\nname = vertex.get(\"name\") or \"Unknown\"\n</code></pre></p>"},{"location":"development/troubleshooting/#type-not-found","title":"\"Type not found\"","text":"<p>Meaning: Vertex/Edge type doesn't exist.</p> <p>Solution: <pre><code># Create type first\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n\n# Then create vertex\nwith db.transaction():\n    vertex = db.new_vertex(\"User\")\n</code></pre></p>"},{"location":"development/troubleshooting/#index-already-exists","title":"\"Index already exists\"","text":"<p>Meaning: Trying to create duplicate index.</p> <p>Solution: <pre><code># Drop existing index\nwith db.transaction():\n    try:\n        db.command(\"sql\", \"DROP INDEX User.email\")\n    except:\n        pass  # Index doesn't exist\n\n    # Create new index\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n</code></pre></p>"},{"location":"development/troubleshooting/#unique-constraint-violation","title":"\"Unique constraint violation\"","text":"<p>Meaning: Trying to insert duplicate value for unique property.</p> <p>Solution: <pre><code># Check if exists first\nresult = db.query(\"sql\", \"SELECT FROM User WHERE email = :email\", {\"email\": \"alice@example.com\"})\n\nif result.has_next():\n    vertex = result.next()\n    # Update existing\n    vertex.set(\"name\", \"Alice\")\n    vertex.save()\nelse:\n    # Create new\n    with db.transaction():\n        vertex = db.new_vertex(\"User\")\n        vertex.set(\"email\", \"alice@example.com\")\n        vertex.set(\"name\", \"Alice\")\n        vertex.save()\n</code></pre></p>"},{"location":"development/troubleshooting/#getting-help","title":"Getting Help","text":"<ol> <li>Check Documentation:</li> <li>API Reference</li> <li>Guides</li> <li> <p>Examples</p> </li> <li> <p>Search Issues:</p> </li> <li>GitHub Issues</li> <li> <p>ArcadeDB Documentation</p> </li> <li> <p>Ask Community:</p> </li> <li>Discord</li> <li> <p>GitHub Discussions</p> </li> <li> <p>Report Bug:    Include:</p> </li> <li>Python version (<code>python --version</code>)</li> <li>Package version (<code>pip show arcadedb-embedded</code>)</li> <li>Minimal reproducible example</li> <li>Full error message with stack trace</li> <li>Operating system</li> </ol>"},{"location":"development/troubleshooting/#see-also","title":"See Also","text":"<ul> <li>Architecture - System architecture and design</li> <li>Database API - Core database operations</li> <li>Exceptions API - Error handling reference</li> </ul>"},{"location":"development/testing/best-practices/","title":"Testing Best Practices","text":"<p>Summary of best practices learned from the ArcadeDB Python test suite.</p>"},{"location":"development/testing/best-practices/#database-lifecycle","title":"Database Lifecycle","text":""},{"location":"development/testing/best-practices/#use-context-managers","title":"\u2705 Use Context Managers","text":"<pre><code># Good: Automatic cleanup\nwith arcadedb.create_database(\"./mydb\") as db:\n    db.query(\"sql\", \"SELECT ...\")\n# Database automatically closed\n</code></pre> <pre><code># Also good for servers\nwith arcadedb.create_server(root_path=\"./databases\") as server:\n    server.start()\n    db = server.create_database(\"mydb\")\n    # ... work ...\n# Server automatically stopped\n</code></pre>"},{"location":"development/testing/best-practices/#close-when-done","title":"\u2705 Close When Done","text":"<pre><code># If not using context manager, explicit close\ndb = arcadedb.create_database(\"./mydb\")\ntry:\n    # ... work ...\nfinally:\n    db.close()  # Always close to release lock\n</code></pre>"},{"location":"development/testing/best-practices/#transactions","title":"Transactions","text":""},{"location":"development/testing/best-practices/#always-use-transactions-for-writes","title":"\u2705 Always Use Transactions for Writes","text":"<pre><code># Good: Wrapped in transaction\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n    db.command(\"sql\", \"UPDATE Person SET age = 30 WHERE name = 'Alice'\")\n# Auto-commit on success, auto-rollback on exception\n</code></pre>"},{"location":"development/testing/best-practices/#dont-write-without-transactions","title":"\u274c Don't Write Without Transactions","text":"<pre><code># Bad: No transaction\ndb.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")  # May fail\n</code></pre>"},{"location":"development/testing/best-practices/#concurrency","title":"Concurrency","text":""},{"location":"development/testing/best-practices/#use-threads-for-parallelism","title":"\u2705 Use Threads for Parallelism","text":"<pre><code># Good: Share database instance across threads\ndb = arcadedb.create_database(\"./mydb\")\n\ndef worker():\n    result = db.query(\"sql\", \"SELECT FROM Data\")\n    # Process...\n\nthreads = [Thread(target=worker) for _ in range(10)]\n</code></pre>"},{"location":"development/testing/best-practices/#use-server-mode-for-multi-process","title":"\u2705 Use Server Mode for Multi-Process","text":"<pre><code># Good: Server mode for multiple processes\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Python process: embedded access\ndb = server.get_database(\"mydb\")\n\n# Other processes: HTTP API\n# http://localhost:2480/api/v1/query/mydb\n</code></pre>"},{"location":"development/testing/best-practices/#dont-try-concurrent-process-access","title":"\u274c Don't Try Concurrent Process Access","text":"<pre><code># Bad: Two processes, same database\n# process1.py\ndb1 = arcadedb.create_database(\"./mydb\")  # Locks\n\n# process2.py (simultaneously)\ndb2 = arcadedb.open_database(\"./mydb\")    # \u274c LockException!\n</code></pre>"},{"location":"development/testing/best-practices/#server-patterns","title":"Server Patterns","text":""},{"location":"development/testing/best-practices/#prefer-pattern-2-server-first","title":"\u2705 Prefer Pattern 2 (Server First)","text":"<pre><code># Recommended: Start server first\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.create_database(\"mydb\")\n\n# Use embedded access (fast!)\n# HTTP also available for other processes\n</code></pre>"},{"location":"development/testing/best-practices/#pattern-1-requires-close","title":"\u26a0\ufe0f Pattern 1 Requires close()","text":"<pre><code># If using Pattern 1, MUST close\ndb = arcadedb.create_database(\"./mydb\")\n# ... populate ...\ndb.close()  # \u26a0\ufe0f Critical!\n\n# Then start server\nserver = arcadedb.create_server(...)\n</code></pre>"},{"location":"development/testing/best-practices/#data-import","title":"Data Import","text":""},{"location":"development/testing/best-practices/#use-jsonl-for-large-files","title":"\u2705 Use JSONL for Large Files","text":"<pre><code># Good: Streams line-by-line\narcadedb.import_jsonl(\n    db,\n    \"large_file.jsonl\",\n    type_name=\"Data\"\n)\n</code></pre>"},{"location":"development/testing/best-practices/#adjust-batch-size-for-performance","title":"\u2705 Adjust Batch Size for Performance","text":"<pre><code># Large files: bigger batches\narcadedb.import_csv(\n    db,\n    \"huge.csv\",\n    type_name=\"Data\",\n    commit_every=10000  # Larger batches\n)\n</code></pre>"},{"location":"development/testing/best-practices/#define-schema-before-import","title":"\u2705 Define Schema Before Import","text":"<pre><code># Good: Schema first for better performance\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\ndb.command(\"sql\", \"CREATE PROPERTY Person.age INTEGER\")\ndb.command(\"sql\", \"CREATE INDEX ON Person(name)\")\n\n# Then import\narcadedb.import_csv(db, \"people.csv\", type_name=\"Person\")\n</code></pre>"},{"location":"development/testing/best-practices/#query-handling","title":"Query Handling","text":""},{"location":"development/testing/best-practices/#iterate-results-efficiently","title":"\u2705 Iterate Results Efficiently","text":"<pre><code># Good: Iterate directly\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nfor person in result:\n    process(person.get_property(\"name\"))\n</code></pre>"},{"location":"development/testing/best-practices/#convert-to-list-when-needed","title":"\u2705 Convert to List When Needed","text":"<pre><code># Good when you need all results\nresult = db.query(\"sql\", \"SELECT FROM Person\")\npeople = list(result)\nprint(f\"Found {len(people)} people\")\n</code></pre>"},{"location":"development/testing/best-practices/#error-handling","title":"Error Handling","text":""},{"location":"development/testing/best-practices/#catch-arcadedberror","title":"\u2705 Catch ArcadeDBError","text":"<pre><code>from arcadedb_embedded.exceptions import ArcadeDBError\n\ntry:\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\nexcept ArcadeDBError as e:\n    print(f\"Database error: {e}\")\n    # Handle error\n</code></pre>"},{"location":"development/testing/best-practices/#transactions-auto-rollback","title":"\u2705 Transactions Auto-Rollback","text":"<pre><code># Good: Exception triggers rollback\ntry:\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n        raise Exception(\"Something went wrong\")\nexcept Exception:\n    pass\n\n# Transaction was automatically rolled back\n</code></pre>"},{"location":"development/testing/best-practices/#testing","title":"Testing","text":""},{"location":"development/testing/best-practices/#clean-up-test-databases","title":"\u2705 Clean Up Test Databases","text":"<pre><code>import tempfile\nimport shutil\n\n# Good: Use temp directory\ntemp_dir = tempfile.mkdtemp()\ntry:\n    db = arcadedb.create_database(f\"{temp_dir}/test_db\")\n    # ... tests ...\n    db.close()\nfinally:\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"development/testing/best-practices/#use-fixtures-for-setupteardown","title":"\u2705 Use Fixtures for Setup/Teardown","text":"<pre><code>import pytest\n\n@pytest.fixture\ndef db():\n    temp_dir = tempfile.mkdtemp()\n    database = arcadedb.create_database(f\"{temp_dir}/test_db\")\n    yield database\n    database.close()\n    shutil.rmtree(temp_dir)\n\ndef test_something(db):\n    # db is ready to use\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Test\")\n</code></pre>"},{"location":"development/testing/best-practices/#performance","title":"Performance","text":""},{"location":"development/testing/best-practices/#batch-operations-in-transactions","title":"\u2705 Batch Operations in Transactions","text":"<pre><code># Good: One transaction for many operations\nwith db.transaction():\n    for i in range(1000):\n        db.command(\"sql\", f\"INSERT INTO Data SET value = {i}\")\n</code></pre>"},{"location":"development/testing/best-practices/#dont-use-transaction-per-operation","title":"\u274c Don't Use Transaction Per Operation","text":"<pre><code># Bad: 1000 separate transactions\nfor i in range(1000):\n    with db.transaction():\n        db.command(\"sql\", f\"INSERT INTO Data SET value = {i}\")\n</code></pre>"},{"location":"development/testing/best-practices/#server-managed-embedded-fast","title":"\u2705 Server-Managed Embedded = Fast","text":"<pre><code># Fast: No HTTP overhead, direct JVM call\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.create_database(\"mydb\")\n\n# This is as fast as standalone embedded!\nresult = db.query(\"sql\", \"SELECT FROM Data\")\n</code></pre>"},{"location":"development/testing/best-practices/#summary-checklist","title":"Summary Checklist","text":"<ul> <li> Use context managers for automatic cleanup</li> <li> Wrap writes in transactions</li> <li> Use threads (not processes) for parallelism</li> <li> Use server mode for multi-process access</li> <li> Prefer Pattern 2 (server first) for new projects</li> <li> Use JSONL for large file imports</li> <li> Define schema before importing data</li> <li> Batch operations in transactions</li> <li> Clean up test databases</li> <li> Catch ArcadeDBError exceptions</li> <li> Close databases to release locks</li> </ul>"},{"location":"development/testing/best-practices/#related-documentation","title":"Related Documentation","text":"<ul> <li>Core Tests</li> <li>Concurrency Tests</li> <li>Server Patterns</li> <li>Import Tests</li> <li>User Guide</li> </ul>"},{"location":"development/testing/overview/","title":"Testing Overview","text":"<p>The ArcadeDB Python bindings have a comprehensive test suite covering all major functionality.</p>"},{"location":"development/testing/overview/#quick-statistics","title":"Quick Statistics","text":"<p>Test Results by Distribution</p> <ul> <li>Headless: \u2705 34 passed, 7 skipped (Cypher, Gremlin, Server tests)</li> <li>Minimal: \u2705 38 passed, 3 skipped (Cypher, Gremlin tests)</li> <li>Full: \u2705 41 passed, 0 skipped (all features available)</li> </ul> <p>Total: 41 tests across 6 test files, 100% passing</p>"},{"location":"development/testing/overview/#whats-tested","title":"What's Tested","text":"<p>The test suite covers:</p> <ul> <li>\u2705 Core database operations - CRUD, transactions, queries</li> <li>\u2705 Server mode - HTTP API, multi-client access</li> <li>\u2705 Concurrency patterns - File locking, thread safety, multi-process</li> <li>\u2705 Graph operations - Vertices, edges, traversals</li> <li>\u2705 Query languages - SQL, Cypher, Gremlin</li> <li>\u2705 Vector search - HNSW indexes, similarity search</li> <li>\u2705 Data import - CSV, JSON, JSONL, Neo4j exports</li> <li>\u2705 Unicode support - International characters, emoji</li> <li>\u2705 Schema introspection - Querying database metadata</li> <li>\u2705 Type conversions - Python/Java type mapping</li> <li>\u2705 Large datasets - Handling 1000+ records efficiently</li> </ul>"},{"location":"development/testing/overview/#quick-start","title":"Quick Start","text":""},{"location":"development/testing/overview/#install-test-dependencies","title":"Install Test Dependencies","text":"<pre><code>pip install pytest pytest-cov\n</code></pre>"},{"location":"development/testing/overview/#run-all-tests","title":"Run All Tests","text":"<pre><code># From the bindings/python directory\npytest\n\n# With verbose output\npytest -v\n\n# With coverage report\npytest --cov=arcadedb_embedded --cov-report=html\n</code></pre>"},{"location":"development/testing/overview/#run-specific-tests","title":"Run Specific Tests","text":"<pre><code># Run a specific test file\npytest tests/test_core.py\n\n# Run a specific test function\npytest tests/test_core.py::test_database_creation\n\n# Run tests matching a keyword\npytest -k \"transaction\"\npytest -k \"server\"\npytest -k \"concurrency\"\n\n# Run with output (see print statements)\npytest -v -s\n</code></pre>"},{"location":"development/testing/overview/#test-files-overview","title":"Test Files Overview","text":"Test File Tests Description <code>test_core.py</code> 13 Core database operations, CRUD, transactions, queries <code>test_server.py</code> 6 Server mode, HTTP API, configuration <code>test_concurrency.py</code> 4 File locking, thread safety, multi-process behavior <code>test_server_patterns.py</code> 4 Best practices for embedded + server mode <code>test_importer.py</code> 13 CSV, JSON, JSONL, Neo4j import <code>test_gremlin.py</code> 1 Gremlin query language (if available)"},{"location":"development/testing/overview/#common-testing-workflows","title":"Common Testing Workflows","text":""},{"location":"development/testing/overview/#development-workflow","title":"Development Workflow","text":"<pre><code># Watch mode - rerun tests on file changes\npytest --watch\n\n# Run only failed tests from last run\npytest --lf\n\n# Run tests in parallel (faster)\npytest -n auto\n</code></pre>"},{"location":"development/testing/overview/#debugging-tests","title":"Debugging Tests","text":"<pre><code># Stop on first failure\npytest -x\n\n# Drop into debugger on failure\npytest --pdb\n\n# Show local variables on failure\npytest -l\n\n# Verbose with full output\npytest -vv -s\n</code></pre>"},{"location":"development/testing/overview/#distribution-specific-testing","title":"Distribution-Specific Testing","text":"<p>Some tests are automatically skipped based on your distribution:</p> <pre><code>@pytest.mark.server\ndef test_server_feature():\n    # Skipped in headless distribution\n    pass\n\n@pytest.mark.gremlin\ndef test_gremlin_query():\n    # Skipped in minimal and headless distributions\n    pass\n</code></pre>"},{"location":"development/testing/overview/#test-markers","title":"Test Markers","text":"<p>Tests are organized with pytest markers:</p> <pre><code># Run only server tests\npytest -m server\n\n# Run only Gremlin tests\npytest -m gremlin\n\n# Run all except slow tests\npytest -m \"not slow\"\n</code></pre>"},{"location":"development/testing/overview/#expected-output","title":"Expected Output","text":"<p>When all tests pass, you should see:</p> <pre><code>======================== 41 passed in 9.67s =========================\n</code></pre> <p>With some distributions, you may see skipped tests:</p> <pre><code>================== 38 passed, 3 skipped in 8.50s ===================\n</code></pre> <p>This is normal! Tests are skipped when features aren't available in your distribution.</p>"},{"location":"development/testing/overview/#next-steps","title":"Next Steps","text":"<ul> <li>New to testing? Start with Core Tests</li> <li>Using server mode? See Server Tests and Server Patterns</li> <li>Confused about concurrency? Read Concurrency Tests</li> <li>Importing data? Check Data Import Tests</li> <li>Using Gremlin? See Gremlin Tests</li> </ul>"},{"location":"development/testing/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>API Reference - Database API documentation</li> <li>User Guide - Database usage guide</li> <li>Contributing - How to contribute tests</li> </ul>"},{"location":"development/testing/test-concurrency/","title":"Concurrency Tests","text":"<p>The <code>test_concurrency.py</code> file contains 4 tests that explain ArcadeDB's concurrency model and file locking behavior.</p> <p>View source code</p>"},{"location":"development/testing/test-concurrency/#overview","title":"Overview","text":"<p>The Key Question</p> <p>\"Can multiple Python instances access the same database?\"</p> <p>Short Answer:</p> <ul> <li>\u274c Multiple processes cannot (file lock prevents it)</li> <li>\u2705 Multiple threads can (thread-safe within same process)</li> <li>\u2705 Use server mode for true multi-process access</li> </ul> <p>These tests demonstrate:</p> <ul> <li>File locking mechanism (OS-level locks)</li> <li>Thread safety within a single process</li> <li>Sequential access patterns (open \u2192 close \u2192 reopen)</li> <li>Multi-process limitations and solutions</li> </ul>"},{"location":"development/testing/test-concurrency/#why-this-matters","title":"Why This Matters","text":"<p>Understanding ArcadeDB's concurrency model is critical for:</p> <ul> <li>Deployment architecture: Knowing when to use embedded vs server mode</li> <li>Multi-process applications: Understanding limitations and workarounds</li> <li>Thread safety: Confidently using threads with shared database access</li> <li>Performance optimization: Choosing the right access pattern</li> </ul>"},{"location":"development/testing/test-concurrency/#test-cases","title":"Test Cases","text":""},{"location":"development/testing/test-concurrency/#1-file-lock-mechanism","title":"1. File Lock Mechanism","text":"<p>Test: <code>test_file_lock_mechanism</code></p> <p>Demonstrates that ArcadeDB uses OS-level file locks to prevent concurrent access from multiple processes.</p> <pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded.exceptions import ArcadeDBError\n\n# Process 1: Create and hold lock\ndb1 = arcadedb.create_database(\"./test_db\")\n\n# Process 2: Try to open same database (this would be in another Python process)\ntry:\n    db2 = arcadedb.open_database(\"./test_db\")\n    # This will fail with LockException\nexcept ArcadeDBError as e:\n    print(f\"Expected error: {e}\")\n    # Error message contains: \"LockException\" or \"already locked\"\n\ndb1.close()\n</code></pre> <p>What happens:</p> <ol> <li>First database open acquires an OS-level file lock</li> <li>Second attempt to open fails immediately</li> <li>Lock is released when database is closed</li> <li>Java throws <code>LockException</code>, wrapped as <code>ArcadeDBError</code> in Python</li> </ol> <p>Why it exists:</p> <ul> <li>Prevents database corruption from concurrent writes</li> <li>Ensures data consistency</li> <li>Standard practice for embedded databases (SQLite does the same)</li> </ul> <p>Multi-Process Access</p> <p>You cannot open the same database from multiple Python processes simultaneously.</p> <pre><code># \u274c This WILL NOT work\n# process_1.py\ndb = arcadedb.create_database(\"./mydb\")  # Locks the database\n\n# process_2.py (running simultaneously)\ndb = arcadedb.open_database(\"./mydb\")    # FAILS with LockException!\n</code></pre> <p>Solution: Use server mode for multi-process access.</p>"},{"location":"development/testing/test-concurrency/#2-thread-safe-operations","title":"2. Thread-Safe Operations","text":"<p>Test: <code>test_thread_safe_operations</code></p> <p>Demonstrates that multiple threads can safely access the same database instance.</p> <pre><code>import threading\nimport arcadedb_embedded as arcadedb\n\n# Create database\ndb = arcadedb.create_database(\"./test_db\")\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Counter\")\n\n# Insert initial record\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Counter SET value = 0\")\n\ndef increment_counter(thread_id, iterations):\n    \"\"\"Each thread increments the counter\"\"\"\n    for i in range(iterations):\n        with db.transaction():\n            # Read current value\n            result = db.query(\"sql\", \"SELECT FROM Counter\")\n            current = list(result)[0].get_property(\"value\")\n\n            # Increment\n            db.command(\"sql\", f\"UPDATE Counter SET value = {current + 1}\")\n\n# Create multiple threads\nthreads = []\nnum_threads = 5\niterations_per_thread = 10\n\nfor i in range(num_threads):\n    thread = threading.Thread(\n        target=increment_counter,\n        args=(i, iterations_per_thread)\n    )\n    threads.append(thread)\n    thread.start()\n\n# Wait for all threads to complete\nfor thread in threads:\n    thread.join()\n\n# Verify final count\nresult = db.query(\"sql\", \"SELECT FROM Counter\")\nfinal_value = list(result)[0].get_property(\"value\")\n\n# Should be num_threads * iterations_per_thread\nassert final_value == 50\n\ndb.close()\n</code></pre> <p>What it tests:</p> <ul> <li>Multiple threads accessing the same <code>Database</code> instance</li> <li>Concurrent read/write operations</li> <li>Transaction isolation between threads</li> <li>No race conditions or data corruption</li> </ul> <p>Key insight:</p> <p>\u2705 ArcadeDB is thread-safe! Multiple threads in the same process can safely share a database instance.</p> <p>Thread Safety</p> <p>The Java ArcadeDB engine handles internal synchronization, so you can confidently use the same database object across multiple threads.</p> <pre><code># \u2705 This WORKS perfectly\ndb = arcadedb.create_database(\"./mydb\")\n\ndef worker():\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO MyType SET data = 'value'\")\n\n# Multiple threads share the same db instance\nthreads = [Thread(target=worker) for _ in range(10)]\nfor t in threads:\n    t.start()\n</code></pre> <p>Best practice:</p> <p>Use a single database instance shared across threads:</p> <pre><code># Good: Share one database instance\ndb = arcadedb.create_database(\"./mydb\")\n\ndef thread_worker():\n    result = db.query(\"sql\", \"SELECT FROM MyType\")\n    # Process results...\n\nthreads = [Thread(target=thread_worker) for _ in range(10)]\n</code></pre> <p>Don't create separate database instances per thread (unnecessary overhead):</p> <pre><code># Avoid: Don't do this\ndef thread_worker():\n    db = arcadedb.open_database(\"./mydb\")  # \u274c Creates separate instance\n    result = db.query(\"sql\", \"SELECT FROM MyType\")\n    db.close()\n</code></pre>"},{"location":"development/testing/test-concurrency/#3-sequential-access-pattern","title":"3. Sequential Access Pattern","text":"<p>Test: <code>test_sequential_access</code></p> <p>Demonstrates that a database can be closed and reopened sequentially.</p> <pre><code>import arcadedb_embedded as arcadedb\n\n# First: Create and populate\ndb1 = arcadedb.create_database(\"./test_db\")\ndb1.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\nwith db1.transaction():\n    db1.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n\n# Close to release file lock\ndb1.close()\n\n# Second: Reopen and verify data persisted\ndb2 = arcadedb.open_database(\"./test_db\")\n\nresult = db2.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\nperson = list(result)[0]\n\nassert person.get_property(\"name\") == \"Alice\"\nassert person.get_property(\"age\") == 30\n\ndb2.close()\n</code></pre> <p>What it tests:</p> <ul> <li>Database persistence across close/reopen cycles</li> <li>File lock release on <code>close()</code></li> <li>Data integrity after reopening</li> <li>Proper resource cleanup</li> </ul> <p>Common pattern:</p> <p>This is useful for:</p> <ol> <li>Batch processing: Open \u2192 process \u2192 close \u2192 repeat</li> <li>Migration to server: Create &amp; populate \u2192 close \u2192 move to server directory</li> <li>Temporary exclusive access: Open \u2192 do work \u2192 close (release lock)</li> </ol> <p>Important:</p> <pre><code># Pattern: Create \u2192 Use \u2192 Close \u2192 Reopen\ndb = arcadedb.create_database(\"./mydb\")\n# ... do work ...\ndb.close()  # \u26a0\ufe0f Must close to release lock\n\n# Now someone else (or same process) can open it\ndb2 = arcadedb.open_database(\"./mydb\")  # \u2705 Works!\n</code></pre>"},{"location":"development/testing/test-concurrency/#4-multi-process-limitations","title":"4. Multi-Process Limitations","text":"<p>Test: <code>test_multiprocess_limitation</code></p> <p>Explicitly demonstrates why multiple processes cannot access the same database directly, and shows the solution.</p> <pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded.exceptions import ArcadeDBError\nimport subprocess\nimport sys\n\n# Create test database\ndb = arcadedb.create_database(\"./test_db\")\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Data\")\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Data SET value = 'test'\")\ndb.close()\n\n# Attempt to access from subprocess\nscript = \"\"\"\nimport arcadedb_embedded as arcadedb\ntry:\n    db = arcadedb.open_database(\"./test_db\")\n    print(\"SUCCESS\")\n    db.close()\nexcept Exception as e:\n    print(f\"FAILED: {e}\")\n\"\"\"\n\n# This subprocess will fail if main process holds lock\nresult = subprocess.run(\n    [sys.executable, \"-c\", script],\n    capture_output=True,\n    text=True\n)\n\nprint(\"Subprocess output:\", result.stdout)\n</code></pre> <p>Why this fails:</p> <pre><code>Process 1 (main):     db1 = open(\"./mydb\")  \ud83d\udd12 Lock acquired\n                      |\n                      | (both processes running)\n                      |\nProcess 2 (subprocess): db2 = open(\"./mydb\")  \u274c LockException!\n</code></pre> <p>The solution: Server Mode</p> <pre><code># Solution: Use server mode for multi-process access\n\n# Main process: Start server\nimport arcadedb_embedded as arcadedb\n\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Create database through server\ndb = server.create_database(\"mydb\")\n\n# Now you have TWO ways to access:\n\n# 1. Embedded access (same process) - Fast, no HTTP\ndb.query(\"sql\", \"SELECT FROM MyType\")\n\n# 2. HTTP access (other processes) - Via HTTP API\nimport requests\nresponse = requests.post(\n    'http://localhost:2480/api/v1/query/mydb',\n    json={\n        'language': 'sql',\n        'command': 'SELECT FROM MyType'\n    },\n    auth=('root', 'your_password')\n)\n</code></pre> <p>Key insight:</p> <p>Multi-Process Architecture</p> <p>For multi-process applications:</p> <ol> <li>Start ArcadeDB server in one process</li> <li>Access via HTTP from other processes</li> <li>Or: Use embedded access in server process + HTTP for others</li> </ol> <p>See Server Patterns for detailed guide.</p>"},{"location":"development/testing/test-concurrency/#summary-table","title":"Summary Table","text":"Scenario Supported? Notes Multiple threads, same process \u2705 Yes Thread-safe, share database instance Sequential: open \u2192 close \u2192 reopen \u2705 Yes Must close to release lock Multiple processes, embedded mode \u274c No File lock prevents concurrent access Multiple processes, server mode \u2705 Yes Use HTTP API for additional processes Server-managed embedded + HTTP \u2705 Yes Best of both worlds"},{"location":"development/testing/test-concurrency/#running-these-tests","title":"Running These Tests","text":"<pre><code># Run all concurrency tests\npytest tests/test_concurrency.py -v\n\n# Run specific test\npytest tests/test_concurrency.py::test_file_lock_mechanism -v\npytest tests/test_concurrency.py::test_thread_safe_operations -v\n\n# Run with output to see details\npytest tests/test_concurrency.py -v -s\n</code></pre>"},{"location":"development/testing/test-concurrency/#best-practices","title":"Best Practices","text":""},{"location":"development/testing/test-concurrency/#do-use-threads-for-parallelism","title":"\u2705 DO: Use Threads for Parallelism","text":"<pre><code>db = arcadedb.create_database(\"./mydb\")\n\ndef worker(worker_id):\n    with db.transaction():\n        db.command(\"sql\", f\"INSERT INTO Data SET worker = {worker_id}\")\n\nthreads = [Thread(target=worker, args=(i,)) for i in range(10)]\nfor t in threads:\n    t.start()\nfor t in threads:\n    t.join()\n\ndb.close()\n</code></pre>"},{"location":"development/testing/test-concurrency/#do-use-server-mode-for-multi-process","title":"\u2705 DO: Use Server Mode for Multi-Process","text":"<pre><code># Process 1: Start server\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.create_database(\"mydb\")\n\n# Process 2+: Use HTTP API\n# (See Server Patterns documentation)\n</code></pre>"},{"location":"development/testing/test-concurrency/#do-close-between-sequential-opens","title":"\u2705 DO: Close Between Sequential Opens","text":"<pre><code># Process 1\ndb = arcadedb.create_database(\"./mydb\")\n# ... work ...\ndb.close()  # Release lock\n\n# Process 2 (later, or different script)\ndb = arcadedb.open_database(\"./mydb\")  # Works!\n</code></pre>"},{"location":"development/testing/test-concurrency/#dont-try-concurrent-process-access","title":"\u274c DON'T: Try Concurrent Process Access","text":"<pre><code># \u274c This will fail\n# script1.py\ndb1 = arcadedb.create_database(\"./mydb\")\n# keeps running...\n\n# script2.py (simultaneously)\ndb2 = arcadedb.open_database(\"./mydb\")  # LockException!\n</code></pre>"},{"location":"development/testing/test-concurrency/#dont-create-multiple-db-instances-in-threads","title":"\u274c DON'T: Create Multiple DB Instances in Threads","text":"<pre><code># \u274c Inefficient - creates unnecessary instances\ndef worker():\n    db = arcadedb.open_database(\"./mydb\")  # Separate instance\n    # ... work ...\n    db.close()\n\n# \u2705 Better - share one instance\ndb = arcadedb.open_database(\"./mydb\")\n\ndef worker():\n    # Use shared db instance\n    result = db.query(\"sql\", \"SELECT ...\")\n</code></pre>"},{"location":"development/testing/test-concurrency/#related-documentation","title":"Related Documentation","text":"<ul> <li>Server Tests - Server mode basics</li> <li>Server Patterns - Combining embedded + HTTP access</li> <li>Concurrency Guide - User guide for concurrency</li> <li>Database API - Database class reference</li> <li>Server API - Server class reference</li> </ul>"},{"location":"development/testing/test-concurrency/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/testing/test-concurrency/#database-is-locked-error","title":"\"Database is locked\" Error","text":"<pre><code># Error: LockException: database ./mydb is already locked\n</code></pre> <p>Cause: Another process (or unclosed instance) holds the file lock.</p> <p>Solutions:</p> <ol> <li>Close the other database instance: <code>db.close()</code></li> <li>Check for zombie processes holding locks</li> <li>Use server mode for multi-process access</li> <li>Restart if lock file is orphaned</li> </ol>"},{"location":"development/testing/test-concurrency/#thread-safety-concerns","title":"Thread Safety Concerns","text":"<p>Q: Is it safe to share a database instance across threads?</p> <p>A: Yes! ArcadeDB handles internal synchronization. You can safely share a <code>Database</code> instance across multiple threads.</p> <p>Q: Do I need to synchronize access to the database?</p> <p>A: No, unless you need application-level coordination (e.g., ensuring specific order of operations). The database itself is thread-safe.</p>"},{"location":"development/testing/test-concurrency/#performance-with-threads","title":"Performance with Threads","text":"<p>Q: Should I use one database instance or multiple?</p> <p>A: Use one shared instance. Creating multiple instances adds overhead with no benefit since they'll all access the same underlying database through Java.</p>"},{"location":"development/testing/test-concurrency/#further-reading","title":"Further Reading","text":"<ul> <li>Wikipedia: File Locking - Background on OS-level locks</li> <li>SQLite Locking - Similar approach in SQLite</li> <li>Java Synchronization - How ArcadeDB handles thread safety internally</li> </ul>"},{"location":"development/testing/test-core/","title":"Core Database Tests","text":"<p>The <code>test_core.py</code> file contains 13 tests covering fundamental database operations.</p> <p>View source code</p>"},{"location":"development/testing/test-core/#overview","title":"Overview","text":"<p>These tests validate:</p> <ul> <li>\u2705 Database creation and opening</li> <li>\u2705 CRUD operations (Create, Read, Update, Delete)</li> <li>\u2705 Transaction management</li> <li>\u2705 Graph operations (vertices, edges, traversals)</li> <li>\u2705 Query result handling</li> <li>\u2705 Error handling</li> <li>\u2705 Cypher queries (when available)</li> <li>\u2705 Vector search with HNSW indexes</li> <li>\u2705 Unicode support (international characters, emoji)</li> <li>\u2705 Schema introspection</li> <li>\u2705 Large result sets (1000+ records)</li> <li>\u2705 Type conversions (Python \u2194 Java)</li> <li>\u2705 Complex graph traversals</li> </ul>"},{"location":"development/testing/test-core/#test-cases","title":"Test Cases","text":""},{"location":"development/testing/test-core/#1-database-creation","title":"1. Database Creation","text":"<p>Test: <code>test_database_creation</code></p> <p>Validates that databases can be created with proper initialization.</p> <pre><code>import arcadedb_embedded as arcadedb\n\n# Create a new database\ndb = arcadedb.create_database(\"./test_db\")\n\n# Database should be accessible\nassert db is not None\n\n# Clean up\ndb.close()\n</code></pre> <p>What it tests: - Database creation with default settings - Database object initialization - Proper cleanup</p>"},{"location":"development/testing/test-core/#2-database-opening","title":"2. Database Opening","text":"<p>Test: <code>test_database_open</code></p> <p>Tests opening existing databases.</p> <pre><code># Create database first\ndb1 = arcadedb.create_database(\"./test_db\")\ndb1.close()\n\n# Open existing database\ndb2 = arcadedb.open_database(\"./test_db\")\nassert db2 is not None\ndb2.close()\n</code></pre> <p>What it tests: - Opening pre-existing databases - Database persistence - Multiple open/close cycles</p>"},{"location":"development/testing/test-core/#3-context-manager-usage","title":"3. Context Manager Usage","text":"<p>Test: <code>test_context_manager</code></p> <p>Validates the <code>with</code> statement for automatic cleanup.</p> <pre><code># Database automatically closed when exiting context\nwith arcadedb.create_database(\"./test_db\") as db:\n    result = db.query(\"sql\", \"SELECT 1 as num\")\n    assert list(result)[0].get_property(\"num\") == 1\n\n# Database is automatically closed here\n</code></pre> <p>What it tests: - Context manager protocol (<code>__enter__</code>, <code>__exit__</code>) - Automatic resource cleanup - Exception handling in context</p>"},{"location":"development/testing/test-core/#4-crud-operations","title":"4. CRUD Operations","text":"<p>Test: <code>test_crud_operations</code></p> <p>Comprehensive test of Create, Read, Update, Delete operations.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    # Create schema\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\n    # Create (Insert)\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n\n    # Read (Query)\n    result = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\n    person = list(result)[0]\n    assert person.get_property(\"name\") == \"Alice\"\n    assert person.get_property(\"age\") == 30\n\n    # Update\n    with db.transaction():\n        db.command(\"sql\", \"UPDATE Person SET age = 31 WHERE name = 'Alice'\")\n\n    result = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\n    person = list(result)[0]\n    assert person.get_property(\"age\") == 31\n\n    # Delete\n    with db.transaction():\n        db.command(\"sql\", \"DELETE FROM Person WHERE name = 'Alice'\")\n\n    result = db.query(\"sql\", \"SELECT FROM Person\")\n    assert len(list(result)) == 0\n</code></pre> <p>What it tests: - Document type creation - Insert operations - Query and result iteration - Update operations - Delete operations - Transaction boundaries</p>"},{"location":"development/testing/test-core/#5-transaction-management","title":"5. Transaction Management","text":"<p>Test: <code>test_transactions</code></p> <p>Tests ACID transaction behavior.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Product\")\n\n    # Successful transaction\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Product SET name = 'Widget', price = 10\")\n\n    # Changes are committed\n    result = db.query(\"sql\", \"SELECT FROM Product\")\n    assert len(list(result)) == 1\n\n    # Failed transaction (exception causes rollback)\n    try:\n        with db.transaction():\n            db.command(\"sql\", \"INSERT INTO Product SET name = 'Gadget', price = 20\")\n            raise Exception(\"Simulated error\")\n    except Exception:\n        pass\n\n    # Second insert was rolled back\n    result = db.query(\"sql\", \"SELECT FROM Product\")\n    assert len(list(result)) == 1  # Still only 1 record\n</code></pre> <p>What it tests: - Transaction context manager - Automatic commit on success - Automatic rollback on exception - Data consistency</p>"},{"location":"development/testing/test-core/#6-graph-operations","title":"6. Graph Operations","text":"<p>Test: <code>test_graph_operations</code></p> <p>Tests vertex and edge creation.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    # Create vertex types\n    db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n    db.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n\n    with db.transaction():\n        # Create vertices\n        db.command(\"sql\", \"CREATE VERTEX Person SET name = 'Alice'\")\n        db.command(\"sql\", \"CREATE VERTEX Person SET name = 'Bob'\")\n\n        # Create edge between them\n        db.command(\"sql\", \"\"\"\n            CREATE EDGE Knows \n            FROM (SELECT FROM Person WHERE name = 'Alice')\n            TO (SELECT FROM Person WHERE name = 'Bob')\n            SET since = 2020\n        \"\"\")\n\n    # Query graph\n    result = db.query(\"sql\", \"\"\"\n        SELECT name, out('Knows').name as friends \n        FROM Person WHERE name = 'Alice'\n    \"\"\")\n\n    alice = list(result)[0]\n    assert alice.get_property(\"name\") == \"Alice\"\n    assert \"Bob\" in str(alice.get_property(\"friends\"))\n</code></pre> <p>What it tests: - Vertex type creation - Edge type creation - Vertex creation - Edge creation with properties - Graph traversal queries</p>"},{"location":"development/testing/test-core/#7-query-result-handling","title":"7. Query Result Handling","text":"<p>Test: <code>test_result_set</code></p> <p>Tests ResultSet and Result wrapper classes.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Item\")\n\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Item SET id = 1, value = 'first'\")\n        db.command(\"sql\", \"INSERT INTO Item SET id = 2, value = 'second'\")\n        db.command(\"sql\", \"INSERT INTO Item SET id = 3, value = 'third'\")\n\n    # Query returns ResultSet\n    result_set = db.query(\"sql\", \"SELECT FROM Item ORDER BY id\")\n\n    # Iterate over results\n    items = []\n    for result in result_set:\n        items.append({\n            'id': result.get_property('id'),\n            'value': result.get_property('value')\n        })\n\n    assert len(items) == 3\n    assert items[0]['value'] == 'first'\n    assert items[1]['value'] == 'second'\n    assert items[2]['value'] == 'third'\n</code></pre> <p>What it tests: - ResultSet iteration - Result property access - Multiple result handling - Order preservation</p>"},{"location":"development/testing/test-core/#8-cypher-queries","title":"8. Cypher Queries","text":"<p>Test: <code>test_cypher_queries</code></p> <p>Tests Neo4j Cypher query language support (when available).</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n    db.command(\"sql\", \"CREATE EDGE TYPE KNOWS\")\n\n    with db.transaction():\n        # Use Cypher to create nodes and relationships\n        db.command(\"cypher\", \"\"\"\n            CREATE (a:Person {name: 'Alice', age: 30})\n            CREATE (b:Person {name: 'Bob', age: 25})\n            CREATE (a)-[:KNOWS {since: 2020}]-&gt;(b)\n        \"\"\")\n\n    # Query with Cypher\n    result = db.query(\"cypher\", \"MATCH (p:Person) RETURN p.name as name, p.age as age\")\n\n    people = [(r.get_property(\"name\"), r.get_property(\"age\")) for r in result]\n    assert len(people) == 2\n</code></pre> <p>Distribution Support</p> <p>Cypher support requires specific Java modules. This test is skipped in minimal distribution.</p> <p>What it tests: - Cypher CREATE statements - Cypher MATCH queries - Property access in Cypher results - Cypher syntax compatibility</p>"},{"location":"development/testing/test-core/#9-vector-search","title":"9. Vector Search","text":"<p>Test: <code>test_vector_search</code></p> <p>Tests HNSW vector indexing and similarity search.</p> <pre><code>import arcadedb_embedded as arcadedb\n\nwith arcadedb.create_database(\"./test_db\") as db:\n    # Create document type with vector property\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding EMBEDDING DOUBLE[3]\")\n\n    # Create HNSW index\n    db.command(\"sql\", \"\"\"\n        CREATE HNSW INDEX Document.embedding \n        ON Document(embedding) \n        WITH m=16, ef=128, efConstruction=128\n    \"\"\")\n\n    # Insert vectors\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Document SET name = 'doc1', embedding = [1.0, 0.0, 0.0]\")\n        db.command(\"sql\", \"INSERT INTO Document SET name = 'doc2', embedding = [0.9, 0.1, 0.0]\")\n        db.command(\"sql\", \"INSERT INTO Document SET name = 'doc3', embedding = [0.0, 1.0, 0.0]\")\n\n    # Similarity search\n    result = db.query(\"sql\", \"\"\"\n        SELECT name, cosine_similarity(embedding, [1.0, 0.0, 0.0]) as similarity\n        FROM Document\n        ORDER BY similarity DESC\n        LIMIT 2\n    \"\"\")\n\n    docs = list(result)\n    assert docs[0].get_property(\"name\") == \"doc1\"  # Closest match\n    assert docs[1].get_property(\"name\") == \"doc2\"  # Second closest\n</code></pre> <p>What it tests: - EMBEDDING property type creation - HNSW index creation with parameters - Vector insertion - Cosine similarity search - Result ranking by similarity</p>"},{"location":"development/testing/test-core/#10-unicode-support","title":"10. Unicode Support","text":"<p>Test: <code>test_unicode_support</code></p> <p>Tests international characters and emoji.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Message\")\n\n    with db.transaction():\n        # Spanish\n        db.command(\"sql\", \"INSERT INTO Message SET text = 'Hola, \u00bfc\u00f3mo est\u00e1s?'\")\n\n        # Chinese\n        db.command(\"sql\", \"INSERT INTO Message SET text = '\u4f60\u597d\u4e16\u754c'\")\n\n        # Japanese\n        db.command(\"sql\", \"INSERT INTO Message SET text = '\u3053\u3093\u306b\u3061\u306f'\")\n\n        # Arabic\n        db.command(\"sql\", \"INSERT INTO Message SET text = '\u0645\u0631\u062d\u0628\u0627 \u0628\u0627\u0644\u0639\u0627\u0644\u0645'\")\n\n        # Emoji\n        db.command(\"sql\", \"INSERT INTO Message SET text = '\ud83c\udfae ArcadeDB \ud83d\ude80'\")\n\n    result = db.query(\"sql\", \"SELECT FROM Message\")\n    texts = [r.get_property(\"text\") for r in result]\n\n    assert \"\u00bfc\u00f3mo est\u00e1s?\" in texts[0]\n    assert \"\u4f60\u597d\u4e16\u754c\" in texts[1]\n    assert \"\u3053\u3093\u306b\u3061\u306f\" in texts[2]\n    assert \"\u0645\u0631\u062d\u0628\u0627\" in texts[3]\n    assert \"\ud83c\udfae\" in texts[4] and \"\ud83d\ude80\" in texts[4]\n</code></pre> <p>What it tests: - UTF-8 encoding/decoding - Non-ASCII character storage - Emoji support - International character sets</p>"},{"location":"development/testing/test-core/#11-schema-introspection","title":"11. Schema Introspection","text":"<p>Test: <code>test_schema_queries</code></p> <p>Tests querying database metadata.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    # Create schema\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n    db.command(\"sql\", \"CREATE VERTEX TYPE Company\")\n    db.command(\"sql\", \"CREATE EDGE TYPE WorksAt\")\n\n    # Query schema\n    types_result = db.query(\"sql\", \"SELECT FROM schema:types\")\n    type_names = [r.get_property(\"name\") for r in types_result]\n\n    assert \"Person\" in type_names\n    assert \"Company\" in type_names\n    assert \"WorksAt\" in type_names\n\n    # Get properties of a type\n    props_result = db.query(\"sql\", \"SELECT FROM schema:type:Person\")\n    person_type = list(props_result)[0]\n\n    assert person_type.get_property(\"name\") == \"Person\"\n</code></pre> <p>What it tests: - Schema metadata queries - Type listing - Type introspection - Schema system tables</p>"},{"location":"development/testing/test-core/#12-large-result-sets","title":"12. Large Result Sets","text":"<p>Test: <code>test_large_result_sets</code></p> <p>Tests handling 1000+ records efficiently.</p> <pre><code>with arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Record\")\n\n    # Insert 1000 records\n    with db.transaction():\n        for i in range(1000):\n            db.command(\"sql\", f\"INSERT INTO Record SET id = {i}, value = 'record_{i}'\")\n\n    # Query all records\n    result = db.query(\"sql\", \"SELECT FROM Record ORDER BY id\")\n\n    # Iterate efficiently\n    count = 0\n    for record in result:\n        assert record.get_property(\"id\") == count\n        count += 1\n\n    assert count == 1000\n</code></pre> <p>What it tests: - Bulk inserts in transactions - Large result set iteration - Memory efficiency - Result ordering at scale</p>"},{"location":"development/testing/test-core/#13-type-conversions","title":"13. Type Conversions","text":"<p>Test: <code>test_type_conversions</code></p> <p>Tests Python \u2194 Java type mapping.</p> <pre><code>from datetime import datetime\n\nwith arcadedb.create_database(\"./test_db\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE TypeTest\")\n\n    with db.transaction():\n        db.command(\"sql\", \"\"\"\n            INSERT INTO TypeTest SET \n                str_val = 'text',\n                int_val = 42,\n                float_val = 3.14,\n                bool_val = true,\n                null_val = null,\n                date_val = date('2025-10-21')\n        \"\"\")\n\n    result = db.query(\"sql\", \"SELECT FROM TypeTest\")\n    record = list(result)[0]\n\n    # Verify types\n    assert isinstance(record.get_property(\"str_val\"), str)\n    assert isinstance(record.get_property(\"int_val\"), int)\n    assert isinstance(record.get_property(\"float_val\"), float)\n    assert isinstance(record.get_property(\"bool_val\"), bool)\n    assert record.get_property(\"null_val\") is None\n\n    # Values match\n    assert record.get_property(\"str_val\") == \"text\"\n    assert record.get_property(\"int_val\") == 42\n    assert record.get_property(\"float_val\") == 3.14\n    assert record.get_property(\"bool_val\") is True\n</code></pre> <p>What it tests: - String conversion - Integer conversion - Float conversion - Boolean conversion - Null handling - Date/time handling - Type preservation across JVM boundary</p>"},{"location":"development/testing/test-core/#running-these-tests","title":"Running These Tests","text":"<pre><code># Run all core tests\npytest tests/test_core.py -v\n\n# Run specific test\npytest tests/test_core.py::test_database_creation -v\n\n# Run with output\npytest tests/test_core.py -v -s\n\n# Run only graph-related tests\npytest tests/test_core.py -k \"graph\" -v\n\n# Run only vector-related tests\npytest tests/test_core.py -k \"vector\" -v\n</code></pre>"},{"location":"development/testing/test-core/#key-concepts","title":"Key Concepts","text":""},{"location":"development/testing/test-core/#database-lifecycle","title":"Database Lifecycle","text":"<ol> <li>Create: <code>arcadedb.create_database(path)</code></li> <li>Use: Run queries and commands</li> <li>Close: <code>db.close()</code> or use context manager</li> </ol>"},{"location":"development/testing/test-core/#transaction-pattern","title":"Transaction Pattern","text":"<p>Always use transactions for write operations:</p> <pre><code>with db.transaction():\n    db.command(\"sql\", \"INSERT INTO ...\")\n    db.command(\"sql\", \"UPDATE ...\")\n    # Automatically commits on success\n    # Automatically rolls back on exception\n</code></pre>"},{"location":"development/testing/test-core/#result-handling","title":"Result Handling","text":"<pre><code># Query returns ResultSet (iterable)\nresult_set = db.query(\"sql\", \"SELECT FROM MyType\")\n\n# Iterate to get Result objects\nfor result in result_set:\n    value = result.get_property(\"field_name\")\n    # Process value...\n\n# Or convert to list\nresults = list(result_set)\n</code></pre>"},{"location":"development/testing/test-core/#related-documentation","title":"Related Documentation","text":"<ul> <li>Database API Reference</li> <li>Transactions API Reference</li> <li>Results API Reference</li> <li>Database Guide</li> <li>Query Guide</li> <li>Transaction Guide</li> </ul>"},{"location":"development/testing/test-gremlin/","title":"Gremlin Tests","text":"<p>The <code>test_gremlin.py</code> file contains 1 test validating Gremlin query language support.</p> <p>View source code</p>"},{"location":"development/testing/test-gremlin/#overview","title":"Overview","text":"<p>Full Distribution Only</p> <p>Gremlin support requires the full distribution of ArcadeDB Python bindings.</p> <pre><code>pip install arcadedb-embedded  # Full distribution\n</code></pre> <p>This test is skipped in headless and minimal distributions.</p>"},{"location":"development/testing/test-gremlin/#what-is-gremlin","title":"What is Gremlin?","text":"<p>Apache Gremlin is a graph traversal language from Apache TinkerPop. It provides powerful graph querying capabilities.</p>"},{"location":"development/testing/test-gremlin/#test-case","title":"Test Case","text":""},{"location":"development/testing/test-gremlin/#basic-gremlin-query","title":"Basic Gremlin Query","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./test_db\")\n\n# Create graph schema\ndb.command(\"sql\", \"CREATE VERTEX TYPE Person\")\ndb.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n\n# Insert data with Gremlin\nwith db.transaction():\n    db.command(\"gremlin\", \"\"\"\n        g.addV('Person').property('name', 'Alice').property('age', 30)\n         .addV('Person').property('name', 'Bob').property('age', 25)\n         .next()\n    \"\"\")\n\n# Query with Gremlin\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().hasLabel('Person').values('name')\n\"\"\")\n\nnames = [r for r in result]\nassert 'Alice' in names\nassert 'Bob' in names\n\ndb.close()\n</code></pre>"},{"location":"development/testing/test-gremlin/#gremlin-examples","title":"Gremlin Examples","text":""},{"location":"development/testing/test-gremlin/#graph-traversal","title":"Graph Traversal","text":"<pre><code># Create vertices and edges\nwith db.transaction():\n    db.command(\"gremlin\", \"\"\"\n        alice = g.addV('Person').property('name', 'Alice').next()\n        bob = g.addV('Person').property('name', 'Bob').next()\n        charlie = g.addV('Person').property('name', 'Charlie').next()\n\n        g.addE('Knows').from(alice).to(bob).property('since', 2020).next()\n        g.addE('Knows').from(bob).to(charlie).property('since', 2021).next()\n    \"\"\")\n\n# Find friends of friends\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('name', 'Alice')\n     .out('Knows')\n     .out('Knows')\n     .values('name')\n\"\"\")\n\n# Should find Charlie (friend of friend)\nassert 'Charlie' in list(result)\n</code></pre>"},{"location":"development/testing/test-gremlin/#filtering-and-projection","title":"Filtering and Projection","text":"<pre><code># Find people older than 25\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().hasLabel('Person')\n     .has('age', gt(25))\n     .values('name')\n\"\"\")\n\nnames = list(result)\nassert 'Alice' in names  # age 30\nassert 'Bob' not in names  # age 25\n</code></pre>"},{"location":"development/testing/test-gremlin/#running-this-test","title":"Running This Test","text":"<pre><code># Run Gremlin test (requires full distribution)\npytest tests/test_gremlin.py -v\n\n# Will be skipped if Gremlin not available\npytest tests/test_gremlin.py -v\n# ======================== 1 skipped =========================\n</code></pre>"},{"location":"development/testing/test-gremlin/#gremlin-vs-sql","title":"Gremlin vs SQL","text":"Feature SQL Gremlin Style Declarative Imperative Focus Set operations Step-by-step traversal Learning curve Easier (if you know SQL) Steeper Graph traversal Limited Excellent Use case General queries Complex graph patterns"},{"location":"development/testing/test-gremlin/#example-comparison","title":"Example Comparison","text":"<p>SQL: <pre><code>SELECT name FROM Person WHERE age &gt; 25\n</code></pre></p> <p>Gremlin: <pre><code>g.V().hasLabel('Person').has('age', gt(25)).values('name')\n</code></pre></p> <p>SQL (graph traversal): <pre><code>SELECT name, out('Knows').name as friends FROM Person WHERE name = 'Alice'\n</code></pre></p> <p>Gremlin (graph traversal): <pre><code>g.V().has('name', 'Alice').out('Knows').values('name')\n</code></pre></p>"},{"location":"development/testing/test-gremlin/#when-to-use-gremlin","title":"When to Use Gremlin","text":"<p>Use Gremlin when:</p> <ul> <li>\u2705 Complex graph traversals (multi-hop, conditional paths)</li> <li>\u2705 Graph algorithms (PageRank, shortest path, etc.)</li> <li>\u2705 Pattern matching in graphs</li> <li>\u2705 You're already familiar with TinkerPop</li> </ul> <p>Use SQL when:</p> <ul> <li>\u2705 Simple CRUD operations</li> <li>\u2705 Set-based queries</li> <li>\u2705 Standard reporting</li> <li>\u2705 Your team knows SQL</li> </ul>"},{"location":"development/testing/test-gremlin/#related-documentation","title":"Related Documentation","text":"<ul> <li>Gremlin Guide</li> <li>Graph Operations Guide</li> <li>ArcadeDB Gremlin Docs</li> <li>Apache TinkerPop Docs</li> </ul>"},{"location":"development/testing/test-gremlin/#distribution-requirements","title":"Distribution Requirements","text":"<pre><code># Headless - \u274c No Gremlin\npip install arcadedb-embedded-headless\n\n# Minimal - \u274c No Gremlin\npip install arcadedb-embedded-minimal\n\n# Full - \u2705 Includes Gremlin\npip install arcadedb-embedded\n</code></pre>"},{"location":"development/testing/test-importer/","title":"Data Import Tests","text":"<p>The <code>test_importer.py</code> file contains 13 tests covering CSV, JSON, JSONL, and Neo4j data import.</p> <p>View source code</p>"},{"location":"development/testing/test-importer/#overview","title":"Overview","text":"<p>ArcadeDB Python bindings provide built-in importers for:</p> <ul> <li>\u2705 CSV - Import as documents, vertices, or edges</li> <li>\u2705 JSONL (JSON Lines) - Import as documents or vertices  </li> <li>\u2705 JSON - Import as documents (uses Java importer)</li> <li>\u2705 Neo4j - Import APOC export format (nodes and relationships)</li> </ul> <p>All importers support:</p> <ul> <li>Batch transaction commits (default: 1000 records)</li> <li>Type inference (CSV: string \u2192 int/float/bool/None)</li> <li>Error handling and statistics</li> <li>Memory-efficient streaming (JSONL)</li> </ul>"},{"location":"development/testing/test-importer/#import-capabilities-matrix","title":"Import Capabilities Matrix","text":"Format Documents Vertices Edges Type Inference Streaming CSV \u2705 \u2705 \u2705 \u2705 \u274c JSONL \u2705 \u2705 \u274c \u2705 (JSON types) \u2705 JSON \u2705 \u274c \u274c \u2705 (JSON types) \u274c Neo4j \u2705 \u2705 (nodes) \u2705 (rels) \u2705 \u274c"},{"location":"development/testing/test-importer/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"development/testing/test-importer/#csv-import","title":"CSV Import","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./mydb\")\n\n# Import as documents\narcadedb.import_csv(\n    db,\n    \"data.csv\",\n    type_name=\"Person\",\n    import_as=\"document\"  # or \"vertex\" or \"edge\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#jsonl-import","title":"JSONL Import","text":"<pre><code># Import JSONL (one JSON object per line)\narcadedb.import_jsonl(\n    db,\n    \"data.jsonl\",\n    type_name=\"Person\",\n    import_as=\"document\"  # or \"vertex\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#json-import","title":"JSON Import","text":"<pre><code># Import JSON array\narcadedb.import_json(\n    db,\n    \"data.json\",\n    type_name=\"Person\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#neo4j-import","title":"Neo4j Import","text":"<pre><code># Import Neo4j APOC export\narcadedb.import_neo4j(\n    db,\n    \"neo4j_export.jsonl\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#test-cases","title":"Test Cases","text":""},{"location":"development/testing/test-importer/#csv-import-tests-5-tests","title":"CSV Import Tests (5 tests)","text":""},{"location":"development/testing/test-importer/#1-csv-as-documents","title":"1. CSV as Documents","text":"<pre><code># Create CSV file\ncsv_content = \"\"\"name,age,city\nAlice,30,New York\nBob,25,Los Angeles\nCharlie,35,Chicago\"\"\"\n\n# Import\nstats = arcadedb.import_csv(\n    db,\n    \"people.csv\",\n    type_name=\"Person\",\n    import_as=\"document\"\n)\n\n# Verify\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nassert len(list(result)) == 3\n</code></pre>"},{"location":"development/testing/test-importer/#2-csv-as-vertices","title":"2. CSV as Vertices","text":"<pre><code>csv_content = \"\"\"name,age\nAlice,30\nBob,25\"\"\"\n\nstats = arcadedb.import_csv(\n    db,\n    \"people.csv\",\n    type_name=\"Person\",\n    import_as=\"vertex\"\n)\n\n# Verify vertices created\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nfor person in result:\n    assert hasattr(person, 'out')  # Vertices have out() method\n</code></pre>"},{"location":"development/testing/test-importer/#3-csv-as-edges","title":"3. CSV as Edges","text":"<pre><code># Requires pre-existing vertices with RIDs\ncsv_content = \"\"\"from_rid,to_rid,since\n#1:0,#1:1,2020\n#1:1,#1:2,2021\"\"\"\n\nstats = arcadedb.import_csv(\n    db,\n    \"relationships.csv\",\n    type_name=\"Knows\",\n    import_as=\"edge\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#4-csv-with-custom-delimiter","title":"4. CSV with Custom Delimiter","text":"<pre><code>csv_content = \"\"\"name|age|city\nAlice|30|NYC\"\"\"\n\nstats = arcadedb.import_csv(\n    db,\n    \"data.csv\",\n    type_name=\"Person\",\n    delimiter=\"|\"\n)\n</code></pre>"},{"location":"development/testing/test-importer/#5-csv-type-inference","title":"5. CSV Type Inference","text":"<pre><code>csv_content = \"\"\"name,age,active,score,notes\nAlice,30,true,98.5,\nBob,25,false,87.3,Some text\"\"\"\n\nstats = arcadedb.import_csv(db, \"data.csv\", type_name=\"Person\")\n\nresult = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\nalice = list(result)[0]\n\n# Types are inferred\nassert isinstance(alice.get_property(\"age\"), int)\nassert isinstance(alice.get_property(\"active\"), bool)\nassert isinstance(alice.get_property(\"score\"), float)\nassert alice.get_property(\"notes\") is None\n</code></pre> <p>Type inference rules:</p> <ul> <li><code>\"123\"</code> \u2192 <code>int</code></li> <li><code>\"3.14\"</code> \u2192 <code>float</code></li> <li><code>\"true\"/\"false\"</code> \u2192 <code>bool</code></li> <li><code>\"\"</code> (empty) \u2192 <code>None</code></li> <li>Everything else \u2192 <code>str</code></li> </ul>"},{"location":"development/testing/test-importer/#jsonl-import-tests-3-tests","title":"JSONL Import Tests (3 tests)","text":""},{"location":"development/testing/test-importer/#1-jsonl-as-documents","title":"1. JSONL as Documents","text":"<pre><code># JSONL format: one JSON object per line\njsonl_content = '''{\"name\": \"Alice\", \"age\": 30, \"city\": \"NYC\"}\n{\"name\": \"Bob\", \"age\": 25, \"city\": \"LA\"}\n{\"name\": \"Charlie\", \"age\": 35, \"city\": \"Chicago\"}'''\n\nstats = arcadedb.import_jsonl(\n    db,\n    \"people.jsonl\",\n    type_name=\"Person\",\n    import_as=\"document\"\n)\n\n# Verify\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nassert len(list(result)) == 3\n</code></pre>"},{"location":"development/testing/test-importer/#2-jsonl-as-vertices","title":"2. JSONL as Vertices","text":"<pre><code>jsonl_content = '''{\"name\": \"Alice\", \"age\": 30}\n{\"name\": \"Bob\", \"age\": 25}'''\n\nstats = arcadedb.import_jsonl(\n    db,\n    \"people.jsonl\",\n    type_name=\"Person\",\n    import_as=\"vertex\"\n)\n\n# Vertices are created\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nassert all(hasattr(r, 'out') for r in result)\n</code></pre>"},{"location":"development/testing/test-importer/#3-jsonl-streaming-large-files","title":"3. JSONL Streaming (Large Files)","text":"<p>Memory efficient - processes line by line:</p> <pre><code># Even with millions of lines, memory stays constant\nstats = arcadedb.import_jsonl(\n    db,\n    \"huge_file.jsonl\",  # Could be GBs\n    type_name=\"Data\",\n    commit_every=1000  # Commit every 1000 records\n)\n\nprint(f\"Imported {stats['records_imported']} records\")\nprint(f\"Time: {stats['duration_seconds']:.2f}s\")\n</code></pre>"},{"location":"development/testing/test-importer/#json-import-tests-2-tests","title":"JSON Import Tests (2 tests)","text":""},{"location":"development/testing/test-importer/#1-json-array-import","title":"1. JSON Array Import","text":"<pre><code># JSON array format\njson_content = '''[\n  {\"name\": \"Alice\", \"age\": 30},\n  {\"name\": \"Bob\", \"age\": 25},\n  {\"name\": \"Charlie\", \"age\": 35}\n]'''\n\nstats = arcadedb.import_json(\n    db,\n    \"people.json\",\n    type_name=\"Person\"\n)\n\n# Only creates documents (not vertices)\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nassert len(list(result)) == 3\n</code></pre>"},{"location":"development/testing/test-importer/#2-json-with-nested-objects","title":"2. JSON with Nested Objects","text":"<pre><code>json_content = '''[\n  {\n    \"name\": \"Alice\",\n    \"address\": {\n      \"city\": \"NYC\",\n      \"zip\": \"10001\"\n    },\n    \"hobbies\": [\"reading\", \"gaming\"]\n  }\n]'''\n\nstats = arcadedb.import_json(db, \"people.json\", type_name=\"Person\")\n\nresult = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\nalice = list(result)[0]\n\n# Nested structures preserved\naddress = alice.get_property(\"address\")\nassert address[\"city\"] == \"NYC\"\n</code></pre>"},{"location":"development/testing/test-importer/#neo4j-import-tests-3-tests","title":"Neo4j Import Tests (3 tests)","text":""},{"location":"development/testing/test-importer/#1-neo4j-nodes-vertices","title":"1. Neo4j Nodes (Vertices)","text":"<pre><code># Neo4j APOC export format\nneo4j_content = '''{\"type\":\"node\",\"id\":\"0\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Alice\",\"age\":30}}\n{\"type\":\"node\",\"id\":\"1\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Bob\",\"age\":25}}'''\n\nstats = arcadedb.import_neo4j(db, \"neo4j_export.jsonl\")\n\n# Creates vertices with Person type\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nassert len(list(result)) == 2\n</code></pre>"},{"location":"development/testing/test-importer/#2-neo4j-relationships-edges","title":"2. Neo4j Relationships (Edges)","text":"<pre><code># Nodes first\nneo4j_content = '''{\"type\":\"node\",\"id\":\"0\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Alice\"}}\n{\"type\":\"node\",\"id\":\"1\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Bob\"}}\n{\"type\":\"relationship\",\"id\":\"0\",\"label\":\"KNOWS\",\"start\":{\"id\":\"0\"},\"end\":{\"id\":\"1\"},\"properties\":{\"since\":2020}}'''\n\nstats = arcadedb.import_neo4j(db, \"neo4j_export.jsonl\")\n\n# Verify edge created\nresult = db.query(\"sql\", \"SELECT FROM KNOWS\")\nassert len(list(result)) == 1\n\nedge = list(result)[0]\nassert edge.get_property(\"since\") == 2020\n</code></pre>"},{"location":"development/testing/test-importer/#3-neo4j-full-graph","title":"3. Neo4j Full Graph","text":"<pre><code># Complete graph export\nneo4j_content = '''{\"type\":\"node\",\"id\":\"0\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Alice\"}}\n{\"type\":\"node\",\"id\":\"1\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Bob\"}}\n{\"type\":\"node\",\"id\":\"2\",\"labels\":[\"Person\"],\"properties\":{\"name\":\"Charlie\"}}\n{\"type\":\"relationship\",\"id\":\"0\",\"label\":\"KNOWS\",\"start\":{\"id\":\"0\"},\"end\":{\"id\":\"1\"},\"properties\":{}}\n{\"type\":\"relationship\",\"id\":\"1\",\"label\":\"KNOWS\",\"start\":{\"id\":\"1\"},\"end\":{\"id\":\"2\"},\"properties\":{}}'''\n\nstats = arcadedb.import_neo4j(db, \"graph.jsonl\")\n\nprint(f\"Nodes imported: {stats['nodes_imported']}\")\nprint(f\"Relationships imported: {stats['relationships_imported']}\")\n\n# Query graph\nresult = db.query(\"sql\", \"\"\"\n    SELECT name, out('KNOWS').name as friends\n    FROM Person WHERE name = 'Bob'\n\"\"\")\n</code></pre>"},{"location":"development/testing/test-importer/#import-options","title":"Import Options","text":""},{"location":"development/testing/test-importer/#common-options-all-importers","title":"Common Options (All Importers)","text":"<pre><code>stats = arcadedb.import_xxx(\n    db,\n    file_path,\n    type_name=\"MyType\",\n    commit_every=1000,  # Commit every N records (default: 1000)\n    **options\n)\n</code></pre>"},{"location":"development/testing/test-importer/#csv-options","title":"CSV Options","text":"<pre><code>stats = arcadedb.import_csv(\n    db,\n    \"data.csv\",\n    type_name=\"Person\",\n    import_as=\"document\",  # \"document\", \"vertex\", or \"edge\"\n    delimiter=\",\",          # Field delimiter (default: \",\")\n    quote_char='\"',         # Quote character (default: '\"')\n    header=True,            # Has header row (default: True)\n    commit_every=1000\n)\n</code></pre>"},{"location":"development/testing/test-importer/#jsonl-options","title":"JSONL Options","text":"<pre><code>stats = arcadedb.import_jsonl(\n    db,\n    \"data.jsonl\",\n    type_name=\"Person\",\n    import_as=\"document\",  # \"document\" or \"vertex\"\n    commit_every=1000\n)\n</code></pre>"},{"location":"development/testing/test-importer/#neo4j-options","title":"Neo4j Options","text":"<pre><code>stats = arcadedb.import_neo4j(\n    db,\n    \"neo4j_export.jsonl\",\n    commit_every=1000\n)\n</code></pre>"},{"location":"development/testing/test-importer/#import-statistics","title":"Import Statistics","text":"<p>All importers return statistics:</p> <pre><code>stats = arcadedb.import_csv(db, \"data.csv\", type_name=\"Person\")\n\nprint(stats)\n# {\n#     'records_imported': 1000,\n#     'duration_seconds': 1.23,\n#     'records_per_second': 813.0,\n#     'errors': 0\n# }\n</code></pre> <p>For Neo4j imports:</p> <pre><code>stats = arcadedb.import_neo4j(db, \"graph.jsonl\")\n\nprint(stats)\n# {\n#     'nodes_imported': 100,\n#     'relationships_imported': 250,\n#     'duration_seconds': 0.45,\n#     'errors': 0\n# }\n</code></pre>"},{"location":"development/testing/test-importer/#running-these-tests","title":"Running These Tests","text":"<pre><code># Run all import tests\npytest tests/test_importer.py -v\n\n# Run specific format tests\npytest tests/test_importer.py -k \"csv\" -v\npytest tests/test_importer.py -k \"jsonl\" -v\npytest tests/test_importer.py -k \"neo4j\" -v\n\n# Run with output\npytest tests/test_importer.py -v -s\n</code></pre>"},{"location":"development/testing/test-importer/#best-practices","title":"Best Practices","text":""},{"location":"development/testing/test-importer/#do-use-appropriate-batch-size","title":"\u2705 DO: Use Appropriate Batch Size","text":"<pre><code># Large files: increase batch size\narcadedb.import_csv(\n    db,\n    \"huge_file.csv\",\n    type_name=\"Data\",\n    commit_every=10000  # Fewer, larger transactions\n)\n\n# Small files: default is fine\narcadedb.import_csv(\n    db,\n    \"small_file.csv\",\n    type_name=\"Data\"\n    # commit_every=1000 (default)\n)\n</code></pre>"},{"location":"development/testing/test-importer/#do-use-jsonl-for-large-files","title":"\u2705 DO: Use JSONL for Large Files","text":"<pre><code># \u2705 Good: JSONL streams line-by-line\narcadedb.import_jsonl(db, \"10GB_file.jsonl\", type_name=\"Data\")\n\n# \u274c Bad: JSON loads entire file into memory\narcadedb.import_json(db, \"10GB_file.json\", type_name=\"Data\")\n</code></pre>"},{"location":"development/testing/test-importer/#do-create-types-before-importing","title":"\u2705 DO: Create Types Before Importing","text":"<pre><code># Define schema first for better performance\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\ndb.command(\"sql\", \"CREATE PROPERTY Person.age INTEGER\")\ndb.command(\"sql\", \"CREATE INDEX ON Person(name) UNIQUE\")\n\n# Then import\narcadedb.import_csv(db, \"people.csv\", type_name=\"Person\")\n</code></pre>"},{"location":"development/testing/test-importer/#do-handle-import-errors","title":"\u2705 DO: Handle Import Errors","text":"<pre><code>try:\n    stats = arcadedb.import_csv(db, \"data.csv\", type_name=\"Person\")\n    print(f\"Imported {stats['records_imported']} records\")\nexcept Exception as e:\n    print(f\"Import failed: {e}\")\n    # Handle error, rollback, etc.\n</code></pre>"},{"location":"development/testing/test-importer/#related-documentation","title":"Related Documentation","text":"<ul> <li>Importer API Reference</li> <li>Data Import Guide</li> <li>CSV Import Examples</li> <li>JSONL Import Examples</li> <li>Neo4j Migration Guide</li> </ul>"},{"location":"development/testing/test-server-patterns/","title":"Server Pattern Tests","text":"<p>The <code>test_server_patterns.py</code> file contains 4 tests demonstrating best practices for combining embedded and HTTP access.</p> <p>View source code</p>"},{"location":"development/testing/test-server-patterns/#overview","title":"Overview","text":"<p>These tests answer: \"What's the best way to use server mode?\"</p> <p>There are two patterns for using ArcadeDB server:</p> <ol> <li>Pattern 1: Embedded First \u2192 Server (Advanced, requires manual lock management)</li> <li>Pattern 2: Server First \u2192 Create (Recommended, simpler)</li> </ol> <p>Recommendation</p> <p>Use Pattern 2 for new projects. It's simpler, requires no lock management, and has no performance penalty.</p>"},{"location":"development/testing/test-server-patterns/#the-two-patterns","title":"The Two Patterns","text":""},{"location":"development/testing/test-server-patterns/#pattern-comparison","title":"Pattern Comparison","text":"Aspect Pattern 1: Embedded First Pattern 2: Server First \u2b50 Complexity More complex Simpler Lock Management Manual (<code>close()</code> required) Automatic Use Case Pre-populate, then expose Start fresh with server Steps Create \u2192 close \u2192 move \u2192 server Server \u2192 create \u2192 use Risk Lock conflicts if forget <code>close()</code> None Performance Same Same (no HTTP overhead)"},{"location":"development/testing/test-server-patterns/#test-cases","title":"Test Cases","text":""},{"location":"development/testing/test-server-patterns/#1-pattern-1-embedded-first-server","title":"1. Pattern 1: Embedded First \u2192 Server","text":"<p>Test: <code>test_embedded_first_then_server</code></p> <p>When to use:</p> <ul> <li>Pre-populating a database before exposing it</li> <li>Migrating existing embedded database to server mode</li> <li>Setup scripts that initialize schema/data</li> </ul> <p>Critical requirement: Must <code>close()</code> database before starting server!</p> <pre><code>import arcadedb_embedded as arcadedb\nimport shutil\nimport os\n\n# Step 1: Create database with embedded API\ndb = arcadedb.create_database(\"./temp_db\")\n\n# Step 2: Populate schema and data\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob', age = 25\")\n\n# Step 3: \u26a0\ufe0f CRITICAL - Must close to release file lock!\ndb.close()\n\n# Step 4: Move database to server's databases directory\nos.makedirs(\"./databases\", exist_ok=True)\nshutil.move(\"./temp_db\", \"./databases/mydb\")\n\n# Step 5: Start server\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Step 6: Access through server\ndb = server.get_database(\"mydb\")\n\n# Verify data is there\nresult = db.query(\"sql\", \"SELECT FROM Person\")\npeople = list(result)\nassert len(people) == 2\n\n# Clean up\nserver.stop()\n</code></pre> <p>Why <code>close()</code> is required:</p> <pre><code>Your Python process:\n  db = create_database(\"./temp_db\")  \ud83d\udd12 Lock acquired\n  # ... work ...\n  db.close()                         \ud83d\udd13 Lock released\n\n  server.start()\n  server.get_database(\"mydb\")        \ud83d\udd12 Server acquires lock \u2705\n\nWithout close():\n  db = create_database(\"./temp_db\")  \ud83d\udd12 Lock acquired\n  # ... work ...\n  # Forgot db.close()!              \ud83d\udd12 Still locked\n\n  server.start()\n  server.get_database(\"mydb\")        \u274c LockException!\n</code></pre> <p>Common Mistake</p> <p>Forgetting to call <code>db.close()</code> will cause the server to fail when trying to open the database.</p> <pre><code>db = arcadedb.create_database(\"./mydb\")\n# ... populate ...\n# \u274c Forgot db.close()!\n\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.get_database(\"mydb\")  # \u274c LockException!\n</code></pre>"},{"location":"development/testing/test-server-patterns/#2-pattern-2-server-first-create-recommended","title":"2. Pattern 2: Server First \u2192 Create (Recommended)","text":"<p>Test: <code>test_server_first_pattern_recommended</code></p> <p>When to use:</p> <ul> <li>Starting new projects</li> <li>Want simplest setup</li> <li>Need both embedded and HTTP from the start</li> </ul> <p>Why it's better:</p> <ul> <li>\u2705 No manual lock management</li> <li>\u2705 One database instance shared between embedded &amp; HTTP</li> <li>\u2705 Server coordinates all access</li> <li>\u2705 Simpler code, fewer steps</li> <li>\u2705 No performance penalty</li> </ul> <pre><code>import arcadedb_embedded as arcadedb\n\n# Step 1: Start server FIRST\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Step 2: Create database THROUGH server\ndb = server.create_database(\"mydb\")\n\n# Step 3: Use embedded access directly\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob', age = 25\")\n\n# Query with embedded access\nresult = db.query(\"sql\", \"SELECT FROM Person\")\npeople = list(result)\nassert len(people) == 2\n\n# Step 4: HTTP access also works immediately!\n# http://localhost:2480/api/v1/query/mydb\n\n# No close() needed - server manages the database\nserver.stop()\n</code></pre> <p>Key insight:</p> <p>No Performance Penalty</p> <p>Embedded access through server is just as fast as standalone embedded mode!</p> <ul> <li>It's a direct JVM call, not HTTP</li> <li>HTTP is only used for OTHER processes/clients</li> <li>Same Python process = direct method invocation</li> <li>Zero network overhead</li> </ul> <p>How it works:</p> <pre><code>Same Python Process:\n  server.start()                    Server manages DB lifecycle\n  db = server.create_database()    Returns reference to managed DB\n  db.query(...)                     Direct JVM call (fast!) \u26a1\n\nOther Process (e.g., curl):\n  POST http://localhost:2480/...    HTTP API call \ud83c\udf10\n</code></pre>"},{"location":"development/testing/test-server-patterns/#3-thread-safety-with-server","title":"3. Thread Safety with Server","text":"<p>Test: <code>test_server_thread_safety</code></p> <p>Demonstrates that multiple threads can safely access server-managed databases.</p> <pre><code>import arcadedb_embedded as arcadedb\nimport threading\n\n# Start server and create database\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.create_database(\"mydb\")\n\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Counter\")\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Counter SET value = 0\")\n\ndef increment_counter(thread_id, count):\n    \"\"\"Each thread increments the counter\"\"\"\n    for i in range(count):\n        with db.transaction():\n            result = db.query(\"sql\", \"SELECT FROM Counter\")\n            current = list(result)[0].get_property(\"value\")\n            db.command(\"sql\", f\"UPDATE Counter SET value = {current + 1}\")\n    print(f\"Thread {thread_id} completed\")\n\n# Create and run multiple threads\nthreads = []\nnum_threads = 5\nincrements_per_thread = 10\n\nfor i in range(num_threads):\n    t = threading.Thread(target=increment_counter, args=(i, increments_per_thread))\n    threads.append(t)\n    t.start()\n\n# Wait for all threads\nfor t in threads:\n    t.join()\n\n# Verify final count\nresult = db.query(\"sql\", \"SELECT FROM Counter\")\nfinal = list(result)[0].get_property(\"value\")\nassert final == num_threads * increments_per_thread\n\nserver.stop()\n</code></pre> <p>What it tests:</p> <ul> <li>Multiple threads accessing server-managed database</li> <li>Concurrent transactions</li> <li>No race conditions</li> <li>Server's internal synchronization</li> </ul>"},{"location":"development/testing/test-server-patterns/#4-performance-comparison","title":"4. Performance Comparison","text":"<p>Test: <code>test_embedded_vs_server_performance</code></p> <p>Proves that Pattern 2 embedded access has no performance penalty compared to standalone embedded mode.</p> <pre><code>import arcadedb_embedded as arcadedb\nimport time\n\n# Pattern 1: Standalone embedded\ndb1 = arcadedb.create_database(\"./standalone_db\")\ndb1.command(\"sql\", \"CREATE DOCUMENT TYPE Test\")\n\nstart = time.time()\nwith db1.transaction():\n    for i in range(1000):\n        db1.command(\"sql\", f\"INSERT INTO Test SET id = {i}\")\nstandalone_time = time.time() - start\n\ndb1.close()\n\n# Pattern 2: Server-managed embedded\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb2 = server.create_database(\"mydb\")\ndb2.command(\"sql\", \"CREATE DOCUMENT TYPE Test\")\n\nstart = time.time()\nwith db2.transaction():\n    for i in range(1000):\n        db2.command(\"sql\", f\"INSERT INTO Test SET id = {i}\")\nserver_time = time.time() - start\n\nserver.stop()\n\n# Times should be very similar (within 10% variance)\nprint(f\"Standalone: {standalone_time:.3f}s\")\nprint(f\"Server-managed: {server_time:.3f}s\")\nprint(f\"Difference: {abs(server_time - standalone_time) / standalone_time * 100:.1f}%\")\n\n# Server-managed should not be significantly slower\nassert server_time &lt; standalone_time * 1.2  # Max 20% variance\n</code></pre> <p>Results:</p> <p>Typical output: <pre><code>Standalone: 0.234s\nServer-managed: 0.241s\nDifference: 3.0%\n</code></pre></p> <p>Conclusion: Server-managed embedded access is just as fast as standalone!</p>"},{"location":"development/testing/test-server-patterns/#running-these-tests","title":"Running These Tests","text":"<pre><code># Run all server pattern tests\npytest tests/test_server_patterns.py -v\n\n# Run specific pattern test\npytest tests/test_server_patterns.py::test_server_first_pattern_recommended -v\n\n# Run with output to see timing\npytest tests/test_server_patterns.py::test_embedded_vs_server_performance -v -s\n</code></pre>"},{"location":"development/testing/test-server-patterns/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"development/testing/test-server-patterns/#do-use-pattern-2-server-first","title":"\u2705 DO: Use Pattern 2 (Server First)","text":"<pre><code># Recommended approach\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb = server.create_database(\"mydb\")\n\n# Use embedded access (fast!)\ndb.query(\"sql\", \"SELECT ...\")\n\n# HTTP also available for other processes\n# http://localhost:2480/api/v1/query/mydb\n</code></pre>"},{"location":"development/testing/test-server-patterns/#do-use-context-manager","title":"\u2705 DO: Use Context Manager","text":"<pre><code># Automatic start/stop\nwith arcadedb.create_server(root_path=\"./databases\") as server:\n    server.start()\n    db = server.create_database(\"mydb\")\n    # ... work ...\n# Server automatically stopped\n</code></pre>"},{"location":"development/testing/test-server-patterns/#do-if-using-pattern-1-remember-to-close","title":"\u26a0\ufe0f DO (if using Pattern 1): Remember to Close","text":"<pre><code># If you must use Pattern 1\ndb = arcadedb.create_database(\"./mydb\")\n# ... populate ...\ndb.close()  # \u26a0\ufe0f Don't forget this!\n\n# Then start server\nserver = arcadedb.create_server(...)\nserver.start()\n</code></pre>"},{"location":"development/testing/test-server-patterns/#dont-mix-patterns-incorrectly","title":"\u274c DON'T: Mix Patterns Incorrectly","text":"<pre><code># \u274c This will fail\ndb = arcadedb.create_database(\"./databases/mydb\")\n# Forgot db.close()!\n\nserver = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\ndb2 = server.get_database(\"mydb\")  # LockException!\n</code></pre>"},{"location":"development/testing/test-server-patterns/#decision-tree","title":"Decision Tree","text":"<pre><code>Need embedded + HTTP access?\n\u251c\u2500 Yes\n\u2502  \u251c\u2500 Starting fresh? \n\u2502  \u2502  \u2514\u2500 Use Pattern 2 \u2b50 (server first)\n\u2502  \u2514\u2500 Have existing DB?\n\u2502     \u2514\u2500 Use Pattern 1 (embedded first, remember close!)\n\u2514\u2500 No (embedded only)\n   \u2514\u2500 Use standalone embedded\n      \u2514\u2500 db = arcadedb.create_database(\"./mydb\")\n</code></pre>"},{"location":"development/testing/test-server-patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>Server Tests - Basic server functionality</li> <li>Concurrency Tests - Multi-process limitations</li> <li>Server API - Server class reference</li> <li>Server Guide - User guide for server mode</li> <li>Database API - Database class reference</li> </ul>"},{"location":"development/testing/test-server-patterns/#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"development/testing/test-server-patterns/#why-use-server-mode-at-all","title":"Why use server mode at all?","text":"<p>Benefits:</p> <ol> <li>HTTP API - Access from any language/tool</li> <li>Studio UI - Web interface for exploration</li> <li>Multi-process - Multiple applications can access via HTTP</li> <li>Management - Server lifecycle, monitoring, logs</li> </ol>"},{"location":"development/testing/test-server-patterns/#does-server-mode-slow-down-embedded-access","title":"Does server mode slow down embedded access?","text":"<p>No! Embedded access through server is a direct JVM call, not HTTP. Same performance as standalone.</p>"},{"location":"development/testing/test-server-patterns/#when-should-i-use-pattern-1-vs-pattern-2","title":"When should I use Pattern 1 vs Pattern 2?","text":"<ul> <li>Pattern 2: Starting fresh, want simplicity \u2192 Recommended \u2b50</li> <li>Pattern 1: Have existing embedded DB, need to expose it \u2192 Use with caution</li> </ul>"},{"location":"development/testing/test-server-patterns/#can-i-have-both-embedded-and-http-clients","title":"Can I have both embedded and HTTP clients?","text":"<p>Yes! That's the whole point of Pattern 2:</p> <ul> <li>Your Python app: Embedded access (fast)</li> <li>Other apps: HTTP API access</li> <li>Web users: Studio UI</li> </ul>"},{"location":"development/testing/test-server-patterns/#do-i-need-to-close-server-managed-databases","title":"Do I need to close server-managed databases?","text":"<p>No! Server manages the lifecycle. Just stop the server when done:</p> <pre><code>server = arcadedb.create_server(...)\nserver.start()\ndb = server.create_database(\"mydb\")\n# ... work ...\n# Don't close db!\nserver.stop()  # Server handles cleanup\n</code></pre>"},{"location":"development/testing/test-server/","title":"Server Tests","text":"<p>The <code>test_server.py</code> file contains 6 tests covering basic server functionality.</p> <p>View source code</p>"},{"location":"development/testing/test-server/#overview","title":"Overview","text":"<p>These tests validate:</p> <ul> <li>\u2705 Server creation and startup</li> <li>\u2705 Database operations through server</li> <li>\u2705 Custom configuration</li> <li>\u2705 Context manager usage</li> <li>\u2705 Multiple databases</li> <li>\u2705 Server info retrieval</li> </ul> <p>For advanced server patterns (embedded + HTTP), see Server Patterns.</p>"},{"location":"development/testing/test-server/#quick-example","title":"Quick Example","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create and start server\nserver = arcadedb.create_server(\n    root_path=\"./databases\",\n    root_password=\"mypassword\"\n)\nserver.start()\n\n# Create database\ndb = server.create_database(\"mydb\")\n\n# Use it\ndb.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n\n# Query\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nfor person in result:\n    print(person.get_property(\"name\"))\n\n# Stop server\nserver.stop()\n</code></pre>"},{"location":"development/testing/test-server/#test-cases","title":"Test Cases","text":""},{"location":"development/testing/test-server/#1-server-creation-and-startup","title":"1. Server Creation and Startup","text":"<pre><code>server = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\nassert server.is_running()\n\nserver.stop()\nassert not server.is_running()\n</code></pre>"},{"location":"development/testing/test-server/#2-context-manager","title":"2. Context Manager","text":"<pre><code>with arcadedb.create_server(root_path=\"./databases\") as server:\n    server.start()\n    # Server automatically stopped on exit\n</code></pre>"},{"location":"development/testing/test-server/#3-custom-configuration","title":"3. Custom Configuration","text":"<pre><code>server = arcadedb.create_server(\n    root_path=\"./databases\",\n    root_password=\"secure_password\",\n    config={\n        \"http_port\": 2480,\n        \"host\": \"0.0.0.0\",\n        \"mode\": \"development\"\n    }\n)\nserver.start()\n\nassert server.get_http_port() == 2480\n</code></pre>"},{"location":"development/testing/test-server/#4-multiple-databases","title":"4. Multiple Databases","text":"<pre><code>server = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Create multiple databases\ndb1 = server.create_database(\"db1\")\ndb2 = server.create_database(\"db2\")\n\n# Each is independent\ndb1.command(\"sql\", \"CREATE DOCUMENT TYPE TypeA\")\ndb2.command(\"sql\", \"CREATE DOCUMENT TYPE TypeB\")\n\n# Verify isolation\nresult1 = db1.query(\"sql\", \"SELECT FROM schema:types WHERE name = 'TypeA'\")\nassert len(list(result1)) == 1\n\nresult2 = db2.query(\"sql\", \"SELECT FROM schema:types WHERE name = 'TypeB'\")\nassert len(list(result2)) == 1\n\nserver.stop()\n</code></pre>"},{"location":"development/testing/test-server/#5-server-information","title":"5. Server Information","text":"<pre><code>server = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Get server info\nport = server.get_http_port()\nurl = server.get_studio_url()\n\nprint(f\"Server running on port: {port}\")\nprint(f\"Studio URL: {url}\")\n\nserver.stop()\n</code></pre>"},{"location":"development/testing/test-server/#6-database-listing","title":"6. Database Listing","text":"<pre><code>server = arcadedb.create_server(root_path=\"./databases\")\nserver.start()\n\n# Create databases\nserver.create_database(\"db1\")\nserver.create_database(\"db2\")\n\n# List databases\ndatabases = server.list_databases()\nassert \"db1\" in databases\nassert \"db2\" in databases\n\nserver.stop()\n</code></pre>"},{"location":"development/testing/test-server/#running-these-tests","title":"Running These Tests","text":"<pre><code># Run all server tests\npytest tests/test_server.py -v\n\n# Run specific test\npytest tests/test_server.py::test_server_creation -v\n</code></pre> <p>Distribution Support</p> <p>Server tests are skipped in the headless distribution (no server module).</p>"},{"location":"development/testing/test-server/#related-documentation","title":"Related Documentation","text":"<ul> <li>Server Patterns - Advanced patterns</li> <li>Server API Reference</li> <li>Server Guide</li> <li>Concurrency Tests - Multi-process access</li> </ul>"},{"location":"examples/basic/","title":"Basic Examples","text":"<p>This page demonstrates the fundamental operations with ArcadeDB Python bindings.</p>"},{"location":"examples/basic/#database-creation-and-basic-crud","title":"Database Creation and Basic CRUD","text":""},{"location":"examples/basic/#create-a-database","title":"Create a Database","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create new database\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    print(f\"Created database at: {db.get_database_path()}\")\n    # Database automatically closed when exiting context\n</code></pre>"},{"location":"examples/basic/#open-existing-database","title":"Open Existing Database","text":"<pre><code># Open existing database\nwith arcadedb.open_database(\"/tmp/mydb\") as db:\n    result = db.query(\"sql\", \"SELECT count(*) as total FROM Person\")\n    print(f\"Total records: {result[0].get_property('total')}\")\n</code></pre> <p>For more examples, see the Quick Start Guide.</p>"},{"location":"examples/import/","title":"Import Examples","text":"<p>Under Construction</p> <p>This page is being developed. Check back soon!</p>"},{"location":"examples/import/#coming-soon","title":"Coming Soon","text":"<ul> <li>CSV import examples</li> <li>JSON/JSONL import</li> <li>Neo4j migration</li> <li>Batch processing</li> </ul>"},{"location":"examples/server/","title":"Server Examples","text":"<p>Under Construction</p> <p>This page is being developed. Check back soon!</p>"},{"location":"examples/server/#coming-soon","title":"Coming Soon","text":"<ul> <li>Starting HTTP server</li> <li>Accessing Studio UI</li> <li>REST API usage</li> <li>Security configuration</li> </ul>"},{"location":"examples/vectors/","title":"Vector Search Examples","text":"<p>Under Construction</p> <p>This page is being developed. Check back soon!</p>"},{"location":"examples/vectors/#coming-soon","title":"Coming Soon","text":"<ul> <li>Creating vector indexes</li> <li>Storing embeddings</li> <li>Similarity search</li> <li>Real-world use cases</li> </ul>"},{"location":"getting-started/distributions/","title":"Distribution Comparison","text":"<p>All three ArcadeDB Python packages are embedded - they run the database directly in your Python process via JPype. The difference is which Java JARs are bundled.</p>"},{"location":"getting-started/distributions/#quick-comparison","title":"Quick Comparison","text":"Feature Headless Minimal Full Package Name <code>arcadedb-embedded-headless</code> <code>arcadedb-embedded-minimal</code> <code>arcadedb-embedded</code> Wheel Size ~94 MB ~97 MB ~158 MB Studio Web UI \u274c No \u2705 Yes \u2705 Yes SQL \u2705 Yes \u2705 Yes \u2705 Yes Cypher \u2705 Yes \u2705 Yes \u2705 Yes Gremlin \u274c No \u274c No \u2705 Yes GraphQL \u274c No \u274c No \u2705 Yes PostgreSQL Wire \u2705 Yes \u2705 Yes \u2705 Yes MongoDB Wire \u274c No \u274c No \u2705 Yes Redis Wire \u274c No \u274c No \u2705 Yes HTTP REST API \u2705 Yes \u2705 Yes \u2705 Yes Test Results 34/41 passed 38/41 passed 41/41 passed PyPI Status \u2705 Available \u2705 Available \u23f3 Coming Soon"},{"location":"getting-started/distributions/#headless-distribution","title":"Headless Distribution","text":"<p>Best for: Production applications, minimal dependencies</p> <pre><code>pip install arcadedb-embedded-headless\n</code></pre>"},{"location":"getting-started/distributions/#whats-included","title":"What's Included","text":"<ul> <li>Core Database: SQL and Cypher query engines</li> <li>PostgreSQL Wire Protocol: Connect with PostgreSQL clients</li> <li>HTTP REST API: Programmatic access via HTTP</li> <li>All Database Models: Graph, Document, Key/Value, Vector, Time Series</li> </ul>"},{"location":"getting-started/distributions/#whats-not-included","title":"What's NOT Included","text":"<ul> <li>\u274c Studio web UI (use code/API only)</li> <li>\u274c Gremlin query language</li> <li>\u274c GraphQL support</li> <li>\u274c MongoDB/Redis wire protocols</li> </ul>"},{"location":"getting-started/distributions/#test-results","title":"Test Results","text":"<p>34 out of 41 tests pass (7 tests skipped):</p> <ul> <li>\u2705 All core database operations work</li> <li>\u2705 SQL and Cypher queries work</li> <li>\u23ed\ufe0f Cypher tests skipped (Cypher engine not in headless)</li> <li>\u23ed\ufe0f Gremlin tests skipped (Gremlin not available)</li> <li>\u23ed\ufe0f Server tests skipped (HTTP server not included)</li> </ul>"},{"location":"getting-started/distributions/#use-cases","title":"Use Cases","text":"<ul> <li>Production Python applications</li> <li>Headless servers and containers</li> <li>Applications that don't need visual debugging</li> <li>Minimal dependency footprint</li> </ul>"},{"location":"getting-started/distributions/#example","title":"Example","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Direct database access - no UI needed\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE User\")\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO User SET name = 'Alice'\")\n\n    result = db.query(\"sql\", \"SELECT FROM User\")\n    print(f\"Users: {len(result)}\")\n</code></pre>"},{"location":"getting-started/distributions/#minimal-distribution","title":"Minimal Distribution","text":"<p>Best for: Development, learning, visual debugging</p> <pre><code>pip install arcadedb-embedded-minimal\n</code></pre>"},{"location":"getting-started/distributions/#whats-included_1","title":"What's Included","text":"<p>Everything in Headless plus:</p> <ul> <li>\u2705 Studio Web UI (~2 MB): Visual database explorer</li> <li>Query editor with syntax highlighting</li> <li>Schema visualization</li> <li>Data browsing and editing</li> <li>Graph visualization</li> </ul>"},{"location":"getting-started/distributions/#test-results_1","title":"Test Results","text":"<p>38 out of 41 tests pass (3 tests skipped):</p> <ul> <li>\u2705 All core database operations work</li> <li>\u2705 SQL and Cypher queries work</li> <li>\u2705 HTTP server and Studio UI work</li> <li>\u23ed\ufe0f Gremlin tests skipped (Gremlin not available)</li> </ul>"},{"location":"getting-started/distributions/#use-cases_1","title":"Use Cases","text":"<ul> <li>Development and testing</li> <li>Learning ArcadeDB features</li> <li>Visual database exploration</li> <li>Debugging queries and data</li> </ul>"},{"location":"getting-started/distributions/#accessing-studio-ui","title":"Accessing Studio UI","text":"<pre><code>from arcadedb_embedded import create_server\n\n# Start HTTP server with Studio UI\nserver = create_server(\"./databases\")\nserver.start()\n\n# Studio UI available at: http://localhost:2480\n# Create databases, run queries, visualize data\n\n# When done\nserver.stop()\n</code></pre> <p>Studio in Browser</p> <p>Once the server starts, open your browser to <code>http://localhost:2480</code> to access the Studio UI.</p>"},{"location":"getting-started/distributions/#full-distribution","title":"Full Distribution","text":"<p>Best for: Gremlin graphs, GraphQL APIs, MongoDB/Redis compatibility</p> <pre><code>pip install arcadedb-embedded\n</code></pre> <p>Coming Soon</p> <p>The full distribution is pending PyPI size limit approval. Will be available soon!</p>"},{"location":"getting-started/distributions/#whats-included_2","title":"What's Included","text":"<p>Everything in Minimal plus:</p> <ul> <li>\u2705 Gremlin (~60 MB): Apache TinkerPop graph traversal language</li> <li>\u2705 GraphQL (~4 MB): GraphQL query endpoint</li> <li>\u2705 MongoDB Wire Protocol: Connect with MongoDB clients</li> <li>\u2705 Redis Wire Protocol: Connect with Redis clients</li> </ul>"},{"location":"getting-started/distributions/#test-results_2","title":"Test Results","text":"<p>41 out of 41 tests pass (0 tests skipped):</p> <ul> <li>\u2705 All core database operations work</li> <li>\u2705 SQL, Cypher, and Gremlin queries work</li> <li>\u2705 HTTP server and Studio UI work</li> <li>\u2705 All features available</li> </ul>"},{"location":"getting-started/distributions/#use-cases_2","title":"Use Cases","text":"<ul> <li>Applications using Gremlin graph traversals</li> <li>GraphQL API integration</li> <li>MongoDB client compatibility</li> <li>Redis client compatibility</li> <li>Complete feature set</li> </ul>"},{"location":"getting-started/distributions/#gremlin-example","title":"Gremlin Example","text":"<pre><code>import arcadedb_embedded as arcadedb\n\nwith arcadedb.create_database(\"/tmp/graphdb\") as db:\n    # Create vertices and edges\n    db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n    db.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n\n    with db.transaction():\n        db.command(\"sql\", \"CREATE VERTEX Person SET name = 'Alice'\")\n        db.command(\"sql\", \"CREATE VERTEX Person SET name = 'Bob'\")\n        db.command(\"sql\", \"\"\"\n            CREATE EDGE Knows FROM \n                (SELECT FROM Person WHERE name = 'Alice') \n            TO \n                (SELECT FROM Person WHERE name = 'Bob')\n        \"\"\")\n\n    # Use Gremlin for graph traversals\n    result = db.query(\"gremlin\", \"g.V().has('name', 'Alice').out('Knows').values('name')\")\n    print(f\"Alice knows: {list(result)}\")  # ['Bob']\n</code></pre>"},{"location":"getting-started/distributions/#same-import-for-all","title":"Same Import for All","text":"<p>Regardless of distribution, the import is always:</p> <pre><code>import arcadedb_embedded as arcadedb\n</code></pre> <p>This means you can:</p> <ul> <li>Develop with Minimal (Studio UI for debugging)</li> <li>Deploy with Headless (smaller, production-ready)</li> <li>Upgrade to Full (when you need Gremlin/GraphQL)</li> </ul> <p>No code changes required!</p>"},{"location":"getting-started/distributions/#which-distribution-should-you-choose","title":"Which Distribution Should You Choose?","text":"<p>Start with Headless</p> <p>For most Python applications:</p> <ul> <li>Production-ready and tested</li> <li>Smallest size (~94 MB)</li> <li>All core features included</li> <li>Available now on PyPI</li> </ul> <p>Upgrade to Minimal for Development</p> <p>If you need visual debugging:</p> <ul> <li>Only ~3 MB larger</li> <li>Studio UI for exploration</li> <li>Great for learning</li> <li>Available now on PyPI</li> </ul> <p>Wait for Full if Needed</p> <p>Only if you specifically need:</p> <ul> <li>Gremlin graph traversals</li> <li>GraphQL endpoint</li> <li>MongoDB/Redis compatibility</li> <li>Coming soon to PyPI!</li> </ul>"},{"location":"getting-started/distributions/#size-breakdown","title":"Size Breakdown","text":""},{"location":"getting-started/distributions/#headless-94-mb","title":"Headless (~94 MB)","text":"<ul> <li>Core Database: ~60 MB</li> <li>SQL/Cypher Engines: ~15 MB</li> <li>PostgreSQL Wire: ~5 MB</li> <li>HTTP Server: ~10 MB</li> <li>Dependencies: ~4 MB</li> </ul>"},{"location":"getting-started/distributions/#minimal-97-mb","title":"Minimal (~97 MB)","text":"<ul> <li>Everything in Headless: ~94 MB</li> <li>Studio UI: ~3 MB</li> </ul>"},{"location":"getting-started/distributions/#full-158-mb","title":"Full (~158 MB)","text":"<ul> <li>Everything in Minimal: ~97 MB</li> <li>Gremlin (TinkerPop): ~60 MB</li> <li>GraphQL: ~4 MB</li> <li>MongoDB/Redis Wire: ~2 MB</li> </ul>"},{"location":"getting-started/distributions/#installation-tips","title":"Installation Tips","text":""},{"location":"getting-started/distributions/#switch-distributions","title":"Switch Distributions","text":"<p>Uninstall the current distribution first:</p> <pre><code># Uninstall any existing distribution\npip uninstall arcadedb-embedded arcadedb-embedded-headless arcadedb-embedded-minimal\n\n# Install the one you want\npip install arcadedb-embedded-headless\n</code></pre>"},{"location":"getting-started/distributions/#check-installed-distribution","title":"Check Installed Distribution","text":"<pre><code>import arcadedb_embedded as arcadedb\nprint(f\"Version: {arcadedb.__version__}\")\n\n# Check which JARs are available\nfrom arcadedb_embedded.jvm import get_jvm\njvm = get_jvm()\n# JVM will load JARs from your installed distribution\n</code></pre>"},{"location":"getting-started/distributions/#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide - Detailed install instructions</li> <li>Quick Start - Get started in 5 minutes</li> <li>Server Mode - Using the HTTP server with Studio UI</li> <li>Gremlin Guide - Graph traversals (Full distribution)</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#choose-your-distribution","title":"Choose Your Distribution","text":"<p>All three packages are embedded - they run ArcadeDB directly in your Python process. Choose based on which features you need:</p> Headless (Recommended)MinimalFull <p>Core database functionality - perfect for production</p> <pre><code>pip install arcadedb-embedded-headless\n</code></pre> <ul> <li>\u2705 Size: ~94MB</li> <li>\u2705 SQL, Cypher queries</li> <li>\u2705 PostgreSQL wire protocol</li> <li>\u2705 HTTP REST API</li> <li>\u274c No Studio UI</li> </ul> <p>Best for:</p> <ul> <li>Production applications</li> <li>Python applications where you don't need the web UI</li> <li>Minimal dependencies</li> </ul> <p>Adds Studio web UI for development</p> <pre><code>pip install arcadedb-embedded-minimal\n</code></pre> <ul> <li>\u2705 Size: ~97MB</li> <li>\u2705 Everything in Headless</li> <li>\u2705 Studio web UI for visual debugging</li> </ul> <p>Best for:</p> <ul> <li>Development and learning</li> <li>Visual database exploration</li> <li>Debugging with the Studio UI</li> </ul> <p>Adds Gremlin + GraphQL support</p> <pre><code>pip install arcadedb-embedded\n</code></pre> <p>Coming Soon</p> <p>Full distribution is pending PyPI size limit approval. Will be available soon!</p> <ul> <li>\u2705 Size: ~158MB</li> <li>\u2705 Everything in Minimal</li> <li>\u2705 Gremlin query language</li> <li>\u2705 GraphQL support</li> <li>\u2705 MongoDB &amp; Redis wire protocols</li> </ul> <p>Best for:</p> <ul> <li>Applications using Gremlin graph queries</li> <li>GraphQL integration</li> <li>MongoDB/Redis compatibility</li> </ul>"},{"location":"getting-started/installation/#same-import-for-all-distributions","title":"Same Import for All Distributions","text":"<p>Regardless of which distribution you install, the import is always:</p> <pre><code>import arcadedb_embedded as arcadedb\n</code></pre> <p>This means you can switch between distributions without changing your code!</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":""},{"location":"getting-started/installation/#java-runtime-environment-jre","title":"Java Runtime Environment (JRE)","text":"<p>Java Required</p> <p>You need Java Runtime Environment (JRE) 11+ installed. The wheels bundle all JAR files, but need a JVM to run them.</p> Ubuntu/DebianmacOSWindows <pre><code>sudo apt-get update\nsudo apt-get install default-jre-headless\n</code></pre> <p>Verify installation:</p> <pre><code>java -version\n# Should show: openjdk version \"11.0.x\" or higher\n</code></pre> <pre><code>brew install openjdk\n</code></pre> <p>Verify installation:</p> <pre><code>java -version\n# Should show: openjdk version \"11.0.x\" or higher\n</code></pre> <ol> <li>Download OpenJDK from Adoptium</li> <li>Run the installer (choose JRE, not full JDK)</li> <li>Verify installation in Command Prompt:</li> </ol> <pre><code>java -version\n</code></pre>"},{"location":"getting-started/installation/#python-version","title":"Python Version","text":"<ul> <li>Supported: Python 3.8, 3.9, 3.10, 3.11, 3.12</li> <li>Recommended: Python 3.10 or higher</li> </ul>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>All Python dependencies are automatically installed:</p> <ul> <li>JPype1 &gt;= 1.5.0 (Java-Python bridge)</li> <li>typing-extensions (for Python &lt; 3.10)</li> </ul>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify everything works:</p> <pre><code>import arcadedb_embedded as arcadedb\nprint(f\"ArcadeDB Python bindings version: {arcadedb.__version__}\")\n</code></pre> <p>Expected output (version will match what you installed):</p> <pre><code>ArcadeDB Python bindings version: X.Y.Z\n</code></pre>"},{"location":"getting-started/installation/#building-from-source","title":"Building from Source","text":"<p>If you want to build the wheels yourself:</p> <p>Docker Required</p> <p>Building requires Docker - it handles all dependencies (Java, Maven, Python build tools).</p> <pre><code>cd bindings/python/\n\n# Build all three distributions\n./build-all.sh\n\n# Or build specific distribution\n./build-all.sh headless    # ~94 MB\n./build-all.sh minimal     # ~97 MB\n./build-all.sh full        # ~158 MB\n</code></pre> <p>Built wheels will be in <code>dist/</code>:</p> <pre><code>dist/\n\u251c\u2500\u2500 arcadedb_embedded_headless-X.Y.Z-py3-none-any.whl\n\u251c\u2500\u2500 arcadedb_embedded_minimal-X.Y.Z-py3-none-any.whl\n\u2514\u2500\u2500 arcadedb_embedded_full-X.Y.Z-py3-none-any.whl\n</code></pre> <p>Install locally (version extracted from <code>pom.xml</code>):</p> <pre><code>pip install dist/arcadedb_embedded_headless-*.whl\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#java-not-found","title":"Java Not Found","text":"<p>If you get <code>Java runtime not found</code> error:</p> <ol> <li>Install JRE (see requirements above)</li> <li>Set <code>JAVA_HOME</code> environment variable:</li> </ol> <pre><code># Linux/macOS\nexport JAVA_HOME=/usr/lib/jvm/default-java\n\n# Windows\nset JAVA_HOME=C:\\Program Files\\Java\\jdk-11\n</code></pre>"},{"location":"getting-started/installation/#import-errors","title":"Import Errors","text":"<p>If <code>import arcadedb_embedded</code> fails:</p> <pre><code># Uninstall all distributions first\npip uninstall arcadedb-embedded arcadedb-embedded-headless arcadedb-embedded-minimal\n\n# Reinstall chosen distribution\npip install arcadedb-embedded-headless\n</code></pre>"},{"location":"getting-started/installation/#version-conflicts","title":"Version Conflicts","text":"<p>If you see version conflicts with JPype:</p> <pre><code># Upgrade JPype\npip install --upgrade JPype1\n\n# Reinstall ArcadeDB\npip install --force-reinstall arcadedb-embedded-headless\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Get started in 5 minutes</li> <li>Distribution Comparison - Detailed comparison</li> <li>User Guide - Learn all features</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get up and running with ArcadeDB Python bindings in 5 minutes!</p>"},{"location":"getting-started/quickstart/#installation","title":"Installation","text":"<p>First, install the headless distribution (recommended for getting started):</p> <pre><code>pip install arcadedb-embedded-headless\n</code></pre> <p>Java Required</p> <p>Make sure you have Java 11+ installed: <pre><code>java -version\n</code></pre> If not installed, see Installation Guide.</p>"},{"location":"getting-started/quickstart/#your-first-database","title":"Your First Database","text":""},{"location":"getting-started/quickstart/#1-create-a-database","title":"1. Create a Database","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create database (context manager for automatic cleanup)\nwith arcadedb.create_database(\"/tmp/quickstart\") as db:\n    print(f\"Created database at: {db.get_database_path()}\")\n</code></pre>"},{"location":"getting-started/quickstart/#2-create-schema","title":"2. Create Schema","text":"<pre><code>with arcadedb.create_database(\"/tmp/quickstart\") as db:\n    # Create a document type\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\n    # Create a property\n    db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY name STRING\")\n    db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY age INTEGER\")\n\n    print(\"Schema created!\")\n</code></pre>"},{"location":"getting-started/quickstart/#3-insert-data","title":"3. Insert Data","text":"<p>All writes must be in a transaction:</p> <pre><code>with arcadedb.create_database(\"/tmp/quickstart\") as db:\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n\n    # Use transaction for writes\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob', age = 25\")\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Charlie', age = 35\")\n\n    print(\"Inserted 3 records\")\n</code></pre> <p>Transactions</p> <p>Always use <code>with db.transaction():</code> for INSERT, UPDATE, DELETE operations.</p>"},{"location":"getting-started/quickstart/#4-query-data","title":"4. Query Data","text":"<pre><code>with arcadedb.create_database(\"/tmp/quickstart\") as db:\n    # Setup (abbreviated)\n    db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n    with db.transaction():\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice', age = 30\")\n        db.command(\"sql\", \"INSERT INTO Person SET name = 'Bob', age = 25\")\n\n    # Query data\n    result = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n\n    for record in result:\n        name = record.get_property('name')\n        age = record.get_property('age')\n        print(f\"Name: {name}, Age: {age}\")\n</code></pre> <p>Output: <pre><code>Name: Alice, Age: 30\n</code></pre></p>"},{"location":"getting-started/quickstart/#complete-example","title":"Complete Example","text":"<p>Here's a complete working example:</p> <pre><code>import arcadedb_embedded as arcadedb\n\ndef main():\n    # Create database\n    with arcadedb.create_database(\"/tmp/quickstart\") as db:\n        # Create schema\n        db.command(\"sql\", \"CREATE DOCUMENT TYPE Person\")\n        db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY name STRING\")\n        db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY age INTEGER\")\n        db.command(\"sql\", \"CREATE INDEX Person_name ON Person (name) NOTUNIQUE\")\n\n        # Insert data (in transaction)\n        with db.transaction():\n            db.command(\"sql\", \"\"\"\n                INSERT INTO Person SET \n                    name = 'Alice', \n                    age = 30,\n                    email = 'alice@example.com'\n            \"\"\")\n            db.command(\"sql\", \"\"\"\n                INSERT INTO Person SET \n                    name = 'Bob', \n                    age = 25,\n                    email = 'bob@example.com'\n            \"\"\")\n            db.command(\"sql\", \"\"\"\n                INSERT INTO Person SET \n                    name = 'Charlie', \n                    age = 35,\n                    email = 'charlie@example.com'\n            \"\"\")\n\n        print(\"\u2705 Inserted 3 records\")\n\n        # Query all\n        print(\"\\n\ud83d\udccb All people:\")\n        result = db.query(\"sql\", \"SELECT FROM Person ORDER BY age\")\n        for record in result:\n            print(f\"  - {record.get_property('name')}, age {record.get_property('age')}\")\n\n        # Query with filter\n        print(\"\\n\ud83d\udd0d People over 25:\")\n        result = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25 ORDER BY age\")\n        for record in result:\n            print(f\"  - {record.get_property('name')}, age {record.get_property('age')}\")\n\n        # Count\n        result = db.query(\"sql\", \"SELECT count(*) as total FROM Person\")\n        total = result[0].get_property('total')\n        print(f\"\\n\ud83d\udcca Total people: {total}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Output: <pre><code>\u2705 Inserted 3 records\n\n\ud83d\udccb All people:\n  - Bob, age 25\n  - Alice, age 30\n  - Charlie, age 35\n\n\ud83d\udd0d People over 25:\n  - Alice, age 30\n  - Charlie, age 35\n\n\ud83d\udcca Total people: 3\n</code></pre></p>"},{"location":"getting-started/quickstart/#key-concepts","title":"Key Concepts","text":""},{"location":"getting-started/quickstart/#context-managers","title":"Context Managers","text":"<p>Always use <code>with</code> statements for automatic cleanup:</p> <pre><code># \u2705 Good - automatic cleanup\nwith arcadedb.create_database(\"/tmp/mydb\") as db:\n    # Use database\n    pass\n# Database automatically closed\n\n# \u274c Avoid - manual cleanup required\ndb = arcadedb.create_database(\"/tmp/mydb\")\n# Use database\ndb.close()  # Easy to forget!\n</code></pre>"},{"location":"getting-started/quickstart/#transactions","title":"Transactions","text":"<p>All writes require a transaction:</p> <pre><code># \u2705 Good - in transaction\nwith db.transaction():\n    db.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n\n# \u274c Will fail - no transaction\ndb.command(\"sql\", \"INSERT INTO Person SET name = 'Alice'\")\n</code></pre> <p>Read-Only Operations</p> <p><code>db.query()</code> doesn't require a transaction - only <code>db.command()</code> for writes.</p>"},{"location":"getting-started/quickstart/#query-languages","title":"Query Languages","text":"<p>ArcadeDB supports multiple query languages:</p> SQLCypherMongoDBGremlin (Full only) <pre><code>result = db.query(\"sql\", \"SELECT FROM Person WHERE age &gt; 25\")\n</code></pre> <pre><code>result = db.query(\"cypher\", \"MATCH (p:Person) WHERE p.age &gt; 25 RETURN p\")\n</code></pre> <pre><code>result = db.query(\"mongo\", \"{ find: 'Person', filter: { age: { $gt: 25 } } }\")\n</code></pre> <pre><code># Only in arcadedb-embedded (full distribution)\nresult = db.query(\"gremlin\", \"g.V().has('Person', 'age', gt(25))\")\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've created your first database, explore more features:</p> <ul> <li> <p> Core Operations</p> <p>Learn about database management, queries, and transactions</p> </li> <li> <p> Vector Search</p> <p>Store and query embeddings with HNSW indexing</p> </li> <li> <p> Graph Operations</p> <p>Work with vertices, edges, and graph traversals</p> </li> <li> <p> Import Data</p> <p>Bulk import from CSV, JSON, JSONL, Neo4j</p> </li> </ul>"},{"location":"getting-started/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quickstart/#working-with-existing-database","title":"Working with Existing Database","text":"<pre><code># Open existing database\nwith arcadedb.open_database(\"/tmp/quickstart\") as db:\n    result = db.query(\"sql\", \"SELECT FROM Person\")\n    print(f\"Found {len(result)} records\")\n</code></pre>"},{"location":"getting-started/quickstart/#batch-inserts","title":"Batch Inserts","text":"<pre><code>with db.transaction():\n    for i in range(100):\n        db.command(\"sql\", f\"INSERT INTO Person SET name = 'User{i}', age = {20 + i}\")\n</code></pre>"},{"location":"getting-started/quickstart/#error-handling","title":"Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ntry:\n    with arcadedb.create_database(\"/tmp/mydb\") as db:\n        db.command(\"sql\", \"INVALID SQL\")\nexcept ArcadeDBError as e:\n    print(f\"Database error: {e}\")\n</code></pre>"},{"location":"getting-started/quickstart/#need-help","title":"Need Help?","text":"<ul> <li>Examples: Check Examples for more code samples</li> <li>API Reference: See Database API for all methods</li> <li>Troubleshooting: Visit Troubleshooting Guide</li> </ul>"},{"location":"guide/graphs/","title":"Graph Operations","text":"<p>ArcadeDB is a native multi-model database with first-class support for property graphs. This guide covers working with vertices, edges, and graph traversals using the Python bindings.</p>"},{"location":"guide/graphs/#overview","title":"Overview","text":"<p>ArcadeDB's graph model consists of:</p> <ul> <li>Vertices (Nodes): Entities in your graph with properties</li> <li>Edges (Relationships): Connections between vertices with optional properties  </li> <li>Types: Schema definitions for vertices and edges</li> </ul>"},{"location":"guide/graphs/#creating-graph-schema","title":"Creating Graph Schema","text":"<p>Before creating vertices and edges, define their types:</p> <pre><code>import arcadedb_embedded as arcadedb\n\nwith arcadedb.create_database(\"/tmp/social\") as db:\n    # Create vertex types\n    db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n    db.command(\"sql\", \"CREATE VERTEX TYPE Company\")\n\n    # Create edge types\n    db.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n    db.command(\"sql\", \"CREATE EDGE TYPE WorksFor\")\n\n    # Add properties to vertices\n    db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY name STRING\")\n    db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY age INTEGER\")\n    db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY email STRING\")\n\n    # Add properties to edges\n    db.command(\"sql\", \"ALTER TYPE Knows CREATE PROPERTY since DATE\")\n    db.command(\"sql\", \"ALTER TYPE WorksFor CREATE PROPERTY role STRING\")\n\n    print(\"\u2705 Graph schema created\")\n</code></pre>"},{"location":"guide/graphs/#creating-vertices","title":"Creating Vertices","text":""},{"location":"guide/graphs/#using-sql","title":"Using SQL","text":"<p>The simplest way to create vertices is with SQL:</p> <pre><code>with db.transaction():\n    # Create vertices with properties\n    db.command(\"sql\", \"\"\"\n        CREATE VERTEX Person \n        SET name = 'Alice', age = 30, email = 'alice@example.com'\n    \"\"\")\n\n    db.command(\"sql\", \"\"\"\n        CREATE VERTEX Person \n        SET name = 'Bob', age = 25, email = 'bob@example.com'\n    \"\"\")\n</code></pre>"},{"location":"guide/graphs/#using-the-api","title":"Using the API","text":"<p>You can also create vertices programmatically using the <code>new_vertex()</code> method:</p> <pre><code>with db.transaction():\n    # Create a vertex using the API\n    vertex = db.new_vertex(\"Person\")\n    vertex.set(\"name\", \"Charlie\")\n    vertex.set(\"age\", 35)\n    vertex.set(\"email\", \"charlie@example.com\")\n    vertex.save()\n\n    print(f\"\u2705 Created vertex with RID: {vertex.getIdentity()}\")\n</code></pre> <p>When to Use Each Approach</p> <ul> <li>SQL: Best for simple inserts, batch operations, and declarative code</li> <li>API: Best when you need programmatic control, access to the vertex object, or complex logic</li> </ul>"},{"location":"guide/graphs/#creating-edges","title":"Creating Edges","text":"<p>Important: In ArcadeDB, edges are created from vertices, not from the database directly. This is the proper graph model - edges represent connections between existing vertices.</p>"},{"location":"guide/graphs/#why-no-dbnew_edge-method","title":"Why No <code>db.new_edge()</code> Method?","text":"<p>Unlike <code>db.new_vertex()</code> and <code>db.new_document()</code>, there is no <code>db.new_edge()</code> method. This is by design in the Java API and reflected in Python:</p> <ul> <li>Edges conceptually belong to vertices - they represent relationships</li> <li>You must have both vertices before creating a connection</li> <li>Edges are created by calling <code>vertex.newEdge(edgeType, toVertex, properties)</code></li> </ul>"},{"location":"guide/graphs/#creating-edges-with-sql","title":"Creating Edges with SQL","text":"<p>The most straightforward way to create edges is with SQL:</p> <pre><code>with db.transaction():\n    # Create vertices first\n    db.command(\"sql\", \"\"\"\n        CREATE VERTEX Person SET name = 'Alice', id = 1\n    \"\"\")\n    db.command(\"sql\", \"\"\"\n        CREATE VERTEX Person SET name = 'Bob', id = 2\n    \"\"\")\n\n    # Create edge between them\n    db.command(\"sql\", \"\"\"\n        CREATE EDGE Knows \n        FROM (SELECT FROM Person WHERE id = 1)\n        TO (SELECT FROM Person WHERE id = 2)\n        SET since = date('2020-01-15')\n    \"\"\")\n</code></pre>"},{"location":"guide/graphs/#creating-edges-with-the-api","title":"Creating Edges with the API","text":"<p>To create edges programmatically, you must:</p> <ol> <li>Create or retrieve both vertices</li> <li>Call <code>newEdge()</code> on the source vertex</li> <li>Save the edge</li> </ol> <pre><code>with db.transaction():\n    # Create vertices\n    alice = db.new_vertex(\"Person\")\n    alice.set(\"name\", \"Alice\")\n    alice.set(\"id\", 1)\n    alice.save()\n\n    bob = db.new_vertex(\"Person\")\n    bob.set(\"name\", \"Bob\")\n    bob.set(\"id\", 2)\n    bob.save()\n\n    # Create edge FROM alice TO bob\n    # Note: Called on the vertex, not the database!\n    edge = alice.newEdge(\"Knows\", bob)\n    edge.set(\"since\", \"2020-01-15\")\n    edge.save()\n\n    print(f\"\u2705 Created edge: {alice.get('name')} -&gt; {bob.get('name')}\")\n</code></pre>"},{"location":"guide/graphs/#creating-edges-with-retrieved-vertices","title":"Creating Edges with Retrieved Vertices","text":"<p>Often you'll create edges between existing vertices:</p> <pre><code># Query for existing vertices\nresult_alice = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Alice'\")\nresult_bob = db.query(\"sql\", \"SELECT FROM Person WHERE name = 'Bob'\")\n\nif result_alice.has_next() and result_bob.has_next():\n    alice = result_alice.next()._java_result\n    bob = result_bob.next()._java_result\n\n    with db.transaction():\n        # Create edge between existing vertices\n        edge = alice.newEdge(\"Knows\", bob)\n        edge.set(\"since\", \"2020-01-15\")\n        edge.save()\n</code></pre> <p>Vertex Must Be Saved First</p> <p>Before creating an edge, both vertices must be saved (have a valid RID). Attempting to create an edge with unsaved vertices will raise an error: <pre><code>IllegalArgumentException: Current vertex is not persistent. Call save() first\n</code></pre></p>"},{"location":"guide/graphs/#creating-edges-with-cypher","title":"Creating Edges with Cypher","text":"<p>Cypher provides a clean syntax for creating edges:</p> <pre><code>with db.transaction():\n    # Create vertices and edge in one statement\n    db.command(\"cypher\", \"\"\"\n        CREATE (alice:Person {name: 'Alice', age: 30})\n        CREATE (bob:Person {name: 'Bob', age: 25})\n        CREATE (alice)-[:Knows {since: '2020-01-15'}]-&gt;(bob)\n    \"\"\")\n</code></pre> <p>Or connect existing vertices:</p> <pre><code>with db.transaction():\n    db.command(\"cypher\", \"\"\"\n        MATCH (alice:Person {name: 'Alice'})\n        MATCH (bob:Person {name: 'Bob'})\n        CREATE (alice)-[:Knows {since: '2020-01-15'}]-&gt;(bob)\n    \"\"\")\n</code></pre>"},{"location":"guide/graphs/#complete-example-social-network","title":"Complete Example: Social Network","text":"<p>Here's a complete example building a small social network:</p> <pre><code>import arcadedb_embedded as arcadedb\n\ndef create_social_network():\n    with arcadedb.create_database(\"/tmp/social_network\") as db:\n        # 1. Create schema\n        print(\"Creating schema...\")\n        db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n        db.command(\"sql\", \"CREATE EDGE TYPE Knows\")\n        db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY name STRING\")\n        db.command(\"sql\", \"ALTER TYPE Person CREATE PROPERTY age INTEGER\")\n        db.command(\"sql\", \"ALTER TYPE Knows CREATE PROPERTY since INTEGER\")\n\n        # 2. Create vertices and edges\n        print(\"Creating graph data...\")\n        with db.transaction():\n            # Create people\n            alice = db.new_vertex(\"Person\")\n            alice.set(\"name\", \"Alice\")\n            alice.set(\"age\", 30)\n            alice.save()\n\n            bob = db.new_vertex(\"Person\")\n            bob.set(\"name\", \"Bob\")\n            bob.set(\"age\", 25)\n            bob.save()\n\n            charlie = db.new_vertex(\"Person\")\n            charlie.set(\"name\", \"Charlie\")\n            charlie.set(\"age\", 35)\n            charlie.save()\n\n            # Create relationships\n            edge1 = alice.newEdge(\"Knows\", bob)\n            edge1.set(\"since\", 2020)\n            edge1.save()\n\n            edge2 = bob.newEdge(\"Knows\", charlie)\n            edge2.set(\"since\", 2019)\n            edge2.save()\n\n            edge3 = charlie.newEdge(\"Knows\", alice)\n            edge3.set(\"since\", 2021)\n            edge3.save()\n\n        print(\"\u2705 Graph created\\n\")\n\n        # 3. Query the graph\n        print(\"Finding Alice's friends:\")\n        result = db.query(\"cypher\", \"\"\"\n            MATCH (person:Person {name: 'Alice'})-[:Knows]-&gt;(friend)\n            RETURN friend.name AS name, friend.age AS age\n        \"\"\")\n\n        for record in result:\n            name = record.get_property('name')\n            age = record.get_property('age')\n            print(f\"  - {name}, age {age}\")\n\n        print(\"\\nFinding friends of friends:\")\n        result = db.query(\"cypher\", \"\"\"\n            MATCH (person:Person {name: 'Alice'})-[:Knows*2]-&gt;(fof)\n            WHERE fof.name &lt;&gt; 'Alice'\n            RETURN DISTINCT fof.name AS name\n        \"\"\")\n\n        for record in result:\n            print(f\"  - {record.get_property('name')}\")\n\nif __name__ == \"__main__\":\n    create_social_network()\n</code></pre>"},{"location":"guide/graphs/#best-practices","title":"Best Practices","text":""},{"location":"guide/graphs/#1-always-use-transactions-for-writes","title":"1. Always Use Transactions for Writes","text":"<pre><code># \u2705 Good - wrapped in transaction\nwith db.transaction():\n    vertex = db.new_vertex(\"Person\")\n    vertex.set(\"name\", \"Alice\")\n    vertex.save()\n\n# \u274c Bad - will fail\nvertex = db.new_vertex(\"Person\")  # Error: No transaction!\n</code></pre>"},{"location":"guide/graphs/#2-create-indexes-for-frequent-lookups","title":"2. Create Indexes for Frequent Lookups","text":"<pre><code># Index properties used in WHERE clauses\ndb.command(\"sql\", \"CREATE INDEX ON Person (name) NOTUNIQUE\")\ndb.command(\"sql\", \"CREATE INDEX ON Person (email) UNIQUE\")\n</code></pre>"},{"location":"guide/graphs/#3-use-cypher-for-complex-graph-queries","title":"3. Use Cypher for Complex Graph Queries","text":"<p>Cypher is more expressive and readable for graph operations than SQL.</p>"},{"location":"guide/graphs/#4-save-vertices-before-creating-edges","title":"4. Save Vertices Before Creating Edges","text":"<pre><code>with db.transaction():\n    v1 = db.new_vertex(\"Person\")\n    v1.set(\"name\", \"Alice\")\n    v1.save()  # \u2705 Must save first!\n\n    v2 = db.new_vertex(\"Person\")\n    v2.set(\"name\", \"Bob\")\n    v2.save()  # \u2705 Must save first!\n\n    # Now can create edge\n    edge = v1.newEdge(\"Knows\", v2)\n    edge.save()\n</code></pre>"},{"location":"guide/graphs/#next-steps","title":"Next Steps","text":"<ul> <li>Vector Search: Add vector embeddings to vertices for similarity search</li> <li>Data Import: Import graph data from CSV, JSON, or Neo4j</li> <li>Server Mode: Visualize your graph in Studio UI</li> </ul>"},{"location":"guide/import/","title":"Data Import Guide","text":"<p>This guide covers strategies, best practices, and patterns for importing data into ArcadeDB efficiently and reliably.</p>"},{"location":"guide/import/#overview","title":"Overview","text":"<p>ArcadeDB's Importer supports multiple data formats:</p> <ul> <li>CSV: Tabular data with headers</li> <li>JSON: Single JSON documents or arrays</li> <li>JSONL: Line-delimited JSON (streaming)</li> <li>Neo4j: Direct migration from Neo4j exports</li> </ul> <p>Key Features:</p> <ul> <li>Automatic type inference</li> <li>Batch processing for performance</li> <li>Relationship/edge mapping</li> <li>Schema validation</li> <li>Error handling and recovery</li> </ul>"},{"location":"guide/import/#quick-start","title":"Quick Start","text":""},{"location":"guide/import/#csv-import","title":"CSV Import","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.create_database(\"./mydb\")\nimporter = db.get_importer()\n\n# Import CSV file\nimporter.import_csv(\n    file_path=\"products.csv\",\n    vertex_type=\"Product\",\n    delimiter=\",\",\n    header=True\n)\n\nprint(\"Import complete!\")\n</code></pre>"},{"location":"guide/import/#json-import","title":"JSON Import","text":"<pre><code># Import JSON array\nimporter.import_json(\n    file_path=\"data.json\",\n    vertex_type=\"User\"\n)\n\n# Import JSONL (streaming)\nimporter.import_jsonl(\n    file_path=\"logs.jsonl\",\n    vertex_type=\"LogEntry\"\n)\n</code></pre>"},{"location":"guide/import/#neo4j-import","title":"Neo4j Import","text":"<pre><code># Migrate from Neo4j export\nimporter.import_neo4j(\n    file_path=\"neo4j_export.json\",\n    vertex_types=[\"User\", \"Product\"],\n    edge_types=[\"PURCHASED\", \"REVIEWED\"]\n)\n</code></pre>"},{"location":"guide/import/#format-selection","title":"Format Selection","text":""},{"location":"guide/import/#csv-tabular-data","title":"CSV - Tabular Data","text":"<p>Best For: - Spreadsheet data - Relational database exports - Time-series data - Simple structured data</p> <p>Advantages: - Simple format - Excel/LibreOffice compatible - Wide tool support - Human readable</p> <p>Disadvantages: - No nested structures - Limited type information - Relationships require separate files</p> <p>Example: <pre><code>id,name,email,age\n1,Alice,alice@example.com,30\n2,Bob,bob@example.com,25\n</code></pre></p>"},{"location":"guide/import/#json-complex-documents","title":"JSON - Complex Documents","text":"<p>Best For: - API responses - Document databases - Nested data structures - Complex objects</p> <p>Advantages: - Native type support - Nested structures - Arrays and objects - Standard format</p> <p>Disadvantages: - Larger file sizes - Must load entire file - Harder to edit manually</p> <p>Example: <pre><code>[\n  {\n    \"id\": 1,\n    \"name\": \"Alice\",\n    \"email\": \"alice@example.com\",\n    \"addresses\": [\n      {\"street\": \"123 Main St\", \"city\": \"NYC\"}\n    ]\n  }\n]\n</code></pre></p>"},{"location":"guide/import/#jsonl-streaming-data","title":"JSONL - Streaming Data","text":"<p>Best For: - Large datasets - Log files - Streaming data - Line-by-line processing</p> <p>Advantages: - Memory efficient - Streamable - Append-only logs - Easy to split/merge</p> <p>Disadvantages: - Less human readable - Must be valid JSON per line - No top-level array</p> <p>Example: <pre><code>{\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\"}\n{\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\"}\n</code></pre></p>"},{"location":"guide/import/#neo4j-graph-migration","title":"Neo4j - Graph Migration","text":"<p>Best For: - Neo4j to ArcadeDB migration - Graph data with relationships - Existing Neo4j exports</p> <p>Advantages: - Direct migration - Preserves graph structure - Handles relationships automatically - 3-pass process (nodes, edges, properties)</p> <p>Disadvantages: - Neo4j-specific format - More complex - Requires understanding of both databases</p>"},{"location":"guide/import/#schema-design","title":"Schema Design","text":""},{"location":"guide/import/#pre-create-schema","title":"Pre-create Schema","text":"<p>Recommended: Define schema before importing for better control and validation.</p> <pre><code>with db.transaction():\n    # Define vertex types\n    db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n    db.command(\"sql\", \"CREATE PROPERTY User.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY User.name STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY User.email STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY User.age INTEGER\")\n\n    # Create indexes\n    db.command(\"sql\", \"CREATE INDEX ON User (id) UNIQUE\")\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n\n# Then import\nimporter.import_csv(\"users.csv\", \"User\")\n</code></pre> <p>Benefits: - Type safety - Validation - Better performance - Prevents errors</p>"},{"location":"guide/import/#let-importer-infer","title":"Let Importer Infer","text":"<p>Quick Start: Let importer create schema automatically.</p> <pre><code># No schema definition needed\nimporter.import_csv(\"users.csv\", \"User\")\n</code></pre> <p>Auto-inference: - Creates vertex type if missing - Infers property types from data - Creates properties as needed</p> <p>Trade-offs: - Quick to start - Less control - Types may be wrong - No validation</p>"},{"location":"guide/import/#hybrid-approach","title":"Hybrid Approach","text":"<p>Best of Both: Define critical fields, allow others to be inferred.</p> <pre><code>with db.transaction():\n    # Define critical fields only\n    db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n    db.command(\"sql\", \"CREATE PROPERTY User.id STRING\")\n    db.command(\"sql\", \"CREATE INDEX ON User (id) UNIQUE\")\n\n    # Let importer add other properties\n\n# Import with partial schema\nimporter.import_csv(\"users.csv\", \"User\")\n</code></pre>"},{"location":"guide/import/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guide/import/#batch-size","title":"Batch Size","text":"<p>Control transaction batch size for memory vs. speed trade-off:</p> <pre><code># Small batches: Lower memory, more transactions\nimporter.batch_size = 1000\n\n# Medium batches: Balanced (default)\nimporter.batch_size = 10000\n\n# Large batches: Higher memory, fewer transactions\nimporter.batch_size = 100000\n\n# Apply\nimporter.import_csv(\"large_file.csv\", \"Data\")\n</code></pre> <p>Guidelines:</p> Dataset Size Recommended Batch Size &lt; 100K rows 1,000 - 10,000 100K - 1M 10,000 - 50,000 &gt; 1M rows 50,000 - 100,000 <p>Consider: - Available memory - Record size - Concurrent operations - Disk I/O</p>"},{"location":"guide/import/#parallel-processing","title":"Parallel Processing","text":"<p>Split large files and process in parallel:</p> <pre><code>import concurrent.futures\nimport os\n\ndef split_csv(input_file, chunk_size=100000):\n    \"\"\"Split large CSV into chunks.\"\"\"\n    chunks = []\n    chunk_num = 0\n\n    with open(input_file, 'r') as f:\n        header = f.readline()\n\n        chunk_file = f\"chunk_{chunk_num}.csv\"\n        chunk_writer = open(chunk_file, 'w')\n        chunk_writer.write(header)\n        chunks.append(chunk_file)\n\n        line_count = 0\n        for line in f:\n            chunk_writer.write(line)\n            line_count += 1\n\n            if line_count &gt;= chunk_size:\n                chunk_writer.close()\n                chunk_num += 1\n                chunk_file = f\"chunk_{chunk_num}.csv\"\n                chunk_writer = open(chunk_file, 'w')\n                chunk_writer.write(header)\n                chunks.append(chunk_file)\n                line_count = 0\n\n        chunk_writer.close()\n\n    return chunks\n\ndef import_chunk(db_path, chunk_file, vertex_type):\n    \"\"\"Import single chunk.\"\"\"\n    db = arcadedb.open_database(db_path)\n    importer = db.get_importer()\n    importer.batch_size = 10000\n    importer.import_csv(chunk_file, vertex_type)\n    db.close()\n    os.remove(chunk_file)\n\n# Split file\nchunks = split_csv(\"large_data.csv\", chunk_size=100000)\n\n# Import in parallel\nwith concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n    futures = [\n        executor.submit(import_chunk, \"./mydb\", chunk, \"Data\")\n        for chunk in chunks\n    ]\n\n    for future in concurrent.futures.as_completed(futures):\n        future.result()\n\nprint(f\"Imported {len(chunks)} chunks\")\n</code></pre>"},{"location":"guide/import/#disable-indexes-during-import","title":"Disable Indexes During Import","text":"<p>For massive imports, temporarily disable indexes:</p> <pre><code># 1. Drop indexes\nwith db.transaction():\n    db.command(\"sql\", \"DROP INDEX User.email\")\n    db.command(\"sql\", \"DROP INDEX User.id\")\n\n# 2. Import data\nimporter.batch_size = 100000\nimporter.import_csv(\"huge_file.csv\", \"User\")\n\n# 3. Recreate indexes\nwith db.transaction():\n    db.command(\"sql\", \"CREATE INDEX ON User (id) UNIQUE\")\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n</code></pre> <p>Speed Improvement: 2-5x faster for large imports</p>"},{"location":"guide/import/#memory-management","title":"Memory Management","text":"<p>Monitor and control memory usage:</p> <pre><code>import psutil\nimport gc\n\ndef import_with_memory_monitoring(importer, file_path, vertex_type):\n    \"\"\"Import with memory monitoring.\"\"\"\n    process = psutil.Process()\n\n    # Configure for memory efficiency\n    importer.batch_size = 5000  # Smaller batches\n\n    initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n    print(f\"Initial memory: {initial_memory:.1f} MB\")\n\n    # Import\n    importer.import_csv(file_path, vertex_type)\n\n    # Force garbage collection\n    gc.collect()\n\n    final_memory = process.memory_info().rss / 1024 / 1024\n    print(f\"Final memory: {final_memory:.1f} MB\")\n    print(f\"Memory increase: {final_memory - initial_memory:.1f} MB\")\n\n# Usage\nimport_with_memory_monitoring(importer, \"data.csv\", \"Data\")\n</code></pre>"},{"location":"guide/import/#error-handling","title":"Error Handling","text":""},{"location":"guide/import/#validation-before-import","title":"Validation Before Import","text":"<pre><code>import csv\n\ndef validate_csv(file_path, required_columns):\n    \"\"\"Validate CSV before importing.\"\"\"\n    errors = []\n\n    try:\n        with open(file_path, 'r') as f:\n            reader = csv.DictReader(f)\n\n            # Check headers\n            missing = set(required_columns) - set(reader.fieldnames)\n            if missing:\n                errors.append(f\"Missing columns: {missing}\")\n                return False, errors\n\n            # Check data\n            for i, row in enumerate(reader, start=2):\n                # Validate required fields\n                for col in required_columns:\n                    if not row.get(col):\n                        errors.append(f\"Line {i}: Missing {col}\")\n\n                # Validate types (example)\n                if row.get('age') and not row['age'].isdigit():\n                    errors.append(f\"Line {i}: Invalid age '{row['age']}'\")\n\n                # Stop after 100 errors\n                if len(errors) &gt;= 100:\n                    errors.append(\"... more errors found\")\n                    return False, errors\n\n        return len(errors) == 0, errors\n\n    except Exception as e:\n        return False, [f\"File error: {e}\"]\n\n# Validate before import\nvalid, errors = validate_csv(\"users.csv\", [\"id\", \"name\", \"email\"])\nif valid:\n    importer.import_csv(\"users.csv\", \"User\")\nelse:\n    print(\"Validation errors:\")\n    for error in errors:\n        print(f\"  - {error}\")\n</code></pre>"},{"location":"guide/import/#try-catch-with-logging","title":"Try-Catch with Logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef safe_import(importer, file_path, vertex_type):\n    \"\"\"Import with error handling.\"\"\"\n    try:\n        logger.info(f\"Starting import: {file_path} -&gt; {vertex_type}\")\n\n        importer.import_csv(file_path, vertex_type, header=True)\n\n        logger.info(f\"Import successful: {file_path}\")\n        return True\n\n    except arcadedb.ArcadeDBError as e:\n        logger.error(f\"Import failed: {e}\")\n\n        # Try to recover\n        if \"duplicate\" in str(e).lower():\n            logger.warning(\"Duplicate key error - trying without unique constraint\")\n            # Could drop index and retry\n\n        return False\n\n    except FileNotFoundError:\n        logger.error(f\"File not found: {file_path}\")\n        return False\n\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        return False\n\n# Usage\nsuccess = safe_import(importer, \"data.csv\", \"Data\")\n</code></pre>"},{"location":"guide/import/#partial-import-recovery","title":"Partial Import Recovery","text":"<pre><code>def import_with_recovery(db, file_path, vertex_type, checkpoint_interval=10000):\n    \"\"\"Import with periodic checkpoints.\"\"\"\n    importer = db.get_importer()\n\n    # Track progress\n    checkpoint_file = f\"{file_path}.checkpoint\"\n    start_line = 0\n\n    # Load checkpoint\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            start_line = int(f.read())\n        logger.info(f\"Resuming from line {start_line}\")\n\n    # Import with checkpoints\n    try:\n        imported = 0\n        with open(file_path, 'r') as f:\n            reader = csv.DictReader(f)\n\n            # Skip to start line\n            for _ in range(start_line):\n                next(reader)\n\n            # Import in batches\n            batch = []\n            for i, row in enumerate(reader, start=start_line):\n                batch.append(row)\n\n                if len(batch) &gt;= checkpoint_interval:\n                    # Import batch\n                    with db.transaction():\n                        for record in batch:\n                            vertex = db.new_vertex(vertex_type)\n                            for key, value in record.items():\n                                vertex.set(key, value)\n                            vertex.save()\n\n                    imported += len(batch)\n                    batch = []\n\n                    # Save checkpoint\n                    with open(checkpoint_file, 'w') as cf:\n                        cf.write(str(i + 1))\n\n                    logger.info(f\"Checkpoint: {i + 1} lines imported\")\n\n            # Import remaining\n            if batch:\n                with db.transaction():\n                    for record in batch:\n                        vertex = db.new_vertex(vertex_type)\n                        for key, value in record.items():\n                            vertex.set(key, value)\n                        vertex.save()\n                imported += len(batch)\n\n        # Remove checkpoint file on success\n        if os.path.exists(checkpoint_file):\n            os.remove(checkpoint_file)\n\n        logger.info(f\"Import complete: {imported} records\")\n        return True\n\n    except Exception as e:\n        logger.error(f\"Import failed at checkpoint: {e}\")\n        return False\n\n# Usage - can resume if interrupted\nimport_with_recovery(db, \"large_file.csv\", \"Data\")\n</code></pre>"},{"location":"guide/import/#relationship-mapping","title":"Relationship Mapping","text":""},{"location":"guide/import/#csv-with-relationships","title":"CSV with Relationships","text":"<p>Import entities and relationships from separate CSV files:</p> <pre><code># Step 1: Import users\nimporter.import_csv(\"users.csv\", \"User\")\n\n# Step 2: Import products\nimporter.import_csv(\"products.csv\", \"Product\")\n\n# Step 3: Import relationships from CSV\n# purchases.csv:\n# user_id,product_id,date,amount\n# 1,101,2024-01-15,29.99\n\nimport csv\n\nwith open(\"purchases.csv\", 'r') as f:\n    reader = csv.DictReader(f)\n\n    with db.transaction():\n        for row in reader:\n            # Find vertices\n            user_result = db.query(\"sql\", \n                f\"SELECT FROM User WHERE id = '{row['user_id']}'\")\n            product_result = db.query(\"sql\", \n                f\"SELECT FROM Product WHERE id = '{row['product_id']}'\")\n\n            if user_result.has_next() and product_result.has_next():\n                user = user_result.next()\n                product = product_result.next()\n\n                # Create edge\n                edge = user.new_edge(\"Purchased\", product)\n                edge.set(\"date\", row['date'])\n                edge.set(\"amount\", float(row['amount']))\n                edge.save()\n</code></pre>"},{"location":"guide/import/#json-with-embedded-relationships","title":"JSON with Embedded Relationships","text":"<pre><code># orders.json structure:\n# [\n#   {\n#     \"order_id\": \"ORD123\",\n#     \"customer\": {\"id\": \"CUST1\", \"name\": \"Alice\"},\n#     \"items\": [\n#       {\"product_id\": \"PROD1\", \"qty\": 2},\n#       {\"product_id\": \"PROD2\", \"qty\": 1}\n#     ]\n#   }\n# ]\n\nimport json\n\nwith open(\"orders.json\", 'r') as f:\n    orders = json.load(f)\n\nwith db.transaction():\n    for order in orders:\n        # Create or find customer\n        customer_id = order['customer']['id']\n        customer_result = db.query(\"sql\", \n            f\"SELECT FROM Customer WHERE id = '{customer_id}'\")\n\n        if customer_result.has_next():\n            customer = customer_result.next()\n        else:\n            customer = db.new_vertex(\"Customer\")\n            customer.set(\"id\", customer_id)\n            customer.set(\"name\", order['customer']['name'])\n            customer.save()\n\n        # Create order vertex\n        order_vertex = db.new_vertex(\"Order\")\n        order_vertex.set(\"order_id\", order['order_id'])\n        order_vertex.save()\n\n        # Link customer to order\n        edge = customer.new_edge(\"Placed\", order_vertex)\n        edge.save()\n\n        # Link order to products\n        for item in order['items']:\n            product_result = db.query(\"sql\",\n                f\"SELECT FROM Product WHERE id = '{item['product_id']}'\")\n\n            if product_result.has_next():\n                product = product_result.next()\n\n                contains_edge = order_vertex.new_edge(\"Contains\", product)\n                contains_edge.set(\"quantity\", item['qty'])\n                contains_edge.save()\n</code></pre>"},{"location":"guide/import/#production-patterns","title":"Production Patterns","text":""},{"location":"guide/import/#configuration-file","title":"Configuration File","text":"<pre><code>import yaml\nfrom dataclasses import dataclass\n\n@dataclass\nclass ImportConfig:\n    file_path: str\n    vertex_type: str\n    batch_size: int = 10000\n    delimiter: str = \",\"\n    header: bool = True\n    validate: bool = True\n\ndef load_import_config(config_file):\n    \"\"\"Load import configuration from YAML.\"\"\"\n    with open(config_file, 'r') as f:\n        config_data = yaml.safe_load(f)\n\n    return ImportConfig(**config_data)\n\n# config.yml:\n# file_path: \"data/users.csv\"\n# vertex_type: \"User\"\n# batch_size: 10000\n# delimiter: \",\"\n# header: true\n# validate: true\n\n# Usage\nconfig = load_import_config(\"import_config.yml\")\nimporter.batch_size = config.batch_size\nimporter.import_csv(\n    config.file_path,\n    config.vertex_type,\n    delimiter=config.delimiter,\n    header=config.header\n)\n</code></pre>"},{"location":"guide/import/#import-pipeline","title":"Import Pipeline","text":"<pre><code>class ImportPipeline:\n    def __init__(self, db):\n        self.db = db\n        self.importer = db.get_importer()\n        self.stats = {\n            'files_processed': 0,\n            'records_imported': 0,\n            'errors': []\n        }\n\n    def add_csv_step(self, file_path, vertex_type, **kwargs):\n        \"\"\"Add CSV import step.\"\"\"\n        try:\n            self.importer.import_csv(file_path, vertex_type, **kwargs)\n            self.stats['files_processed'] += 1\n            logger.info(f\"Imported {file_path}\")\n        except Exception as e:\n            self.stats['errors'].append(f\"{file_path}: {e}\")\n            logger.error(f\"Failed to import {file_path}: {e}\")\n\n    def add_json_step(self, file_path, vertex_type):\n        \"\"\"Add JSON import step.\"\"\"\n        try:\n            self.importer.import_json(file_path, vertex_type)\n            self.stats['files_processed'] += 1\n            logger.info(f\"Imported {file_path}\")\n        except Exception as e:\n            self.stats['errors'].append(f\"{file_path}: {e}\")\n            logger.error(f\"Failed to import {file_path}: {e}\")\n\n    def run(self):\n        \"\"\"Execute pipeline.\"\"\"\n        logger.info(\"Starting import pipeline\")\n        # Steps added via add_*_step methods\n        logger.info(f\"Pipeline complete: {self.stats}\")\n        return self.stats\n\n# Usage\npipeline = ImportPipeline(db)\npipeline.add_csv_step(\"users.csv\", \"User\", batch_size=10000)\npipeline.add_csv_step(\"products.csv\", \"Product\", batch_size=10000)\npipeline.add_json_step(\"orders.json\", \"Order\")\nstats = pipeline.run()\n</code></pre>"},{"location":"guide/import/#monitoring-and-progress","title":"Monitoring and Progress","text":"<pre><code>import time\nfrom tqdm import tqdm\n\ndef import_with_progress(file_path, vertex_type, db):\n    \"\"\"Import with progress bar.\"\"\"\n    # Count lines\n    with open(file_path, 'r') as f:\n        total_lines = sum(1 for _ in f) - 1  # Exclude header\n\n    importer = db.get_importer()\n\n    # Import with progress tracking\n    start_time = time.time()\n\n    with tqdm(total=total_lines, desc=f\"Importing {vertex_type}\") as pbar:\n        # Monkey-patch to update progress\n        original_import = importer.import_csv\n\n        def import_with_callback(*args, **kwargs):\n            result = original_import(*args, **kwargs)\n            pbar.update(total_lines)\n            return result\n\n        importer.import_csv = import_with_callback\n        importer.import_csv(file_path, vertex_type, header=True)\n\n    elapsed = time.time() - start_time\n    rate = total_lines / elapsed if elapsed &gt; 0 else 0\n\n    print(f\"Imported {total_lines} records in {elapsed:.1f}s ({rate:.0f} records/sec)\")\n\n# Usage\nimport_with_progress(\"data.csv\", \"Data\", db)\n</code></pre>"},{"location":"guide/import/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/import/#migrate-from-relational-database","title":"Migrate from Relational Database","text":"<pre><code>import sqlite3\nimport arcadedb_embedded as arcadedb\n\n# Export from SQLite\nconn = sqlite3.connect('old_database.db')\ncursor = conn.cursor()\n\n# Create ArcadeDB\ndb = arcadedb.create_database(\"./new_db\")\n\n# Migrate users table\ncursor.execute(\"SELECT id, name, email, created_at FROM users\")\nusers = cursor.fetchall()\n\nwith db.transaction():\n    for user_id, name, email, created_at in users:\n        vertex = db.new_vertex(\"User\")\n        vertex.set(\"id\", str(user_id))\n        vertex.set(\"name\", name)\n        vertex.set(\"email\", email)\n        vertex.set(\"created_at\", created_at)\n        vertex.save()\n\n# Migrate relationships\ncursor.execute(\"\"\"\n    SELECT user_id, friend_id \n    FROM friendships\n\"\"\")\n\nwith db.transaction():\n    for user_id, friend_id in cursor.fetchall():\n        user = db.query(\"sql\", f\"SELECT FROM User WHERE id = '{user_id}'\").next()\n        friend = db.query(\"sql\", f\"SELECT FROM User WHERE id = '{friend_id}'\").next()\n\n        edge = user.new_edge(\"FriendOf\", friend)\n        edge.save()\n\nconn.close()\nprint(\"Migration complete\")\n</code></pre>"},{"location":"guide/import/#import-from-api","title":"Import from API","text":"<pre><code>import requests\n\ndef import_from_api(db, api_url, vertex_type):\n    \"\"\"Import data from REST API.\"\"\"\n    response = requests.get(api_url)\n    response.raise_for_status()\n\n    data = response.json()\n\n    with db.transaction():\n        for item in data:\n            vertex = db.new_vertex(vertex_type)\n            for key, value in item.items():\n                vertex.set(key, value)\n            vertex.save()\n\n    print(f\"Imported {len(data)} records from API\")\n\n# Usage\nimport_from_api(\n    db,\n    \"https://api.example.com/users\",\n    \"User\"\n)\n</code></pre>"},{"location":"guide/import/#incremental-updates","title":"Incremental Updates","text":"<pre><code>from datetime import datetime\n\ndef incremental_import(db, file_path, vertex_type, id_field):\n    \"\"\"Import only new records based on timestamp.\"\"\"\n    # Get last import time\n    last_import_key = f\"last_import_{vertex_type}\"\n    last_import = db.get_metadata(last_import_key) or \"1970-01-01\"\n\n    importer = db.get_importer()\n\n    # Import with filter\n    import csv\n    new_records = 0\n\n    with open(file_path, 'r') as f:\n        reader = csv.DictReader(f)\n\n        with db.transaction():\n            for row in reader:\n                # Check if record is new\n                if row.get('updated_at', '') &gt; last_import:\n                    # Check if exists\n                    result = db.query(\"sql\",\n                        f\"SELECT FROM {vertex_type} WHERE {id_field} = '{row[id_field]}'\")\n\n                    if result.has_next():\n                        # Update existing\n                        vertex = result.next()\n                        for key, value in row.items():\n                            vertex.set(key, value)\n                        vertex.save()\n                    else:\n                        # Create new\n                        vertex = db.new_vertex(vertex_type)\n                        for key, value in row.items():\n                            vertex.set(key, value)\n                        vertex.save()\n\n                    new_records += 1\n\n    # Update last import time\n    current_time = datetime.now().isoformat()\n    db.set_metadata(last_import_key, current_time)\n\n    print(f\"Imported/updated {new_records} records\")\n\n# Usage\nincremental_import(db, \"users.csv\", \"User\", \"id\")\n</code></pre>"},{"location":"guide/import/#see-also","title":"See Also","text":"<ul> <li>Importer API Reference - Complete API documentation</li> <li>Import Examples - Practical code examples</li> <li>Database API - Database operations</li> <li>Transactions - Transaction management</li> </ul>"},{"location":"guide/server/","title":"Server Mode","text":"<p>ArcadeDB Python bindings include a full HTTP server with the Studio web UI. This guide covers server setup, configuration, and management.</p>"},{"location":"guide/server/#overview","title":"Overview","text":"<p>Server mode provides:</p> <ul> <li>HTTP REST API: Access your database via HTTP</li> <li>Studio Web UI: Visual database explorer and query editor</li> <li>Multi-database Management: Host multiple databases</li> <li>Authentication: User management and security</li> <li>Development &amp; Production: Suitable for both environments</li> </ul>"},{"location":"guide/server/#quick-start","title":"Quick Start","text":""},{"location":"guide/server/#basic-server","title":"Basic Server","text":"<p>Start a server with default configuration:</p> <p>```python import arcadedb_embedded as arcadedb</p>"},{"location":"guide/server/#create-and-start-server","title":"Create and start server","text":"<p>server = arcadedb.create_server(\"./databases\") server.start()</p> <p>print(f\"\ud83d\ude80 Server started at: {server.get_studio_url()}\") print(\"\ud83d\udcca Access Studio UI in your browser\")</p>"},{"location":"guide/server/#keep-server-running","title":"Keep server running","text":"<p>input(\"Press Enter to stop server...\") server.stop() ```</p>"},{"location":"guide/server/#context-manager","title":"Context Manager","text":"<p>Use a context manager for automatic cleanup:</p> <p>```python with arcadedb.create_server(\"./databases\") as server:     print(f\"\ud83d\ude80 Server running at: {server.get_studio_url()}\")</p> <pre><code># Server automatically stops on exit\ninput(\"Press Enter to stop...\")\n</code></pre> <p>```</p>"},{"location":"guide/server/#server-configuration","title":"Server Configuration","text":""},{"location":"guide/server/#basic-configuration","title":"Basic Configuration","text":"<p>```python server = arcadedb.create_server(     root_path=\"./databases\",     root_password=\"my_secure_password\",     config={         \"http_port\": 2480,         \"host\": \"0.0.0.0\",         \"mode\": \"development\"     } ) ```</p>"},{"location":"guide/server/#configuration-options","title":"Configuration Options","text":"Option Default Description `root_path` `\"./databases\"` Directory for database storage `root_password` None Root user password (recommended) `http_port` 2480 HTTP API/Studio port `host` `\"0.0.0.0\"` Host to bind to `mode` `\"development\"` Server mode (`development` or `production`)"},{"location":"guide/server/#next-steps","title":"Next Steps","text":"<ul> <li>Graph Operations: Visualize graphs in Studio</li> <li>Vector Search: Add vector search to your server</li> <li>Data Import: Bulk import data into server databases</li> </ul>"},{"location":"guide/vectors/","title":"Vector Search Guide","text":"<p>Vector search enables semantic similarity search using embeddings from machine learning models. This guide covers strategies, best practices, and patterns for implementing vector search with ArcadeDB.</p>"},{"location":"guide/vectors/#overview","title":"Overview","text":"<p>Vector search transforms your data into high-dimensional vectors (embeddings) and finds similar items using distance metrics. Perfect for:</p> <ul> <li>Semantic Search: Find documents by meaning, not just keywords</li> <li>Recommendation Systems: Find similar products, users, or content</li> <li>Image Search: Find similar images using visual embeddings</li> <li>Question Answering: Match questions to relevant answers</li> <li>Anomaly Detection: Find outliers in vector space</li> </ul> <p>How It Works:</p> <ol> <li>Generate embeddings using ML models (Sentence Transformers, OpenAI, etc.)</li> <li>Store vectors in ArcadeDB with HNSW indexing</li> <li>Query with new vectors to find nearest neighbors</li> <li>Get results ranked by similarity</li> </ol>"},{"location":"guide/vectors/#quick-start","title":"Quick Start","text":""},{"location":"guide/vectors/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code>pip install arcadedb-embedded sentence-transformers\n</code></pre>"},{"location":"guide/vectors/#2-create-vector-index","title":"2. Create Vector Index","text":"<pre><code>import arcadedb_embedded as arcadedb\nfrom arcadedb_embedded import to_java_float_array\n\n# Create database and schema\ndb = arcadedb.create_database(\"./vector_demo\")\n\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.text STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding ARRAY_OF_FLOATS\")\n\n# Create vector index\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384,  # Match your model\n    distance_function=\"cosine\"\n)\n</code></pre>"},{"location":"guide/vectors/#3-index-documents","title":"3. Index Documents","text":"<pre><code>from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\ndocuments = [\n    \"Python is a programming language\",\n    \"ArcadeDB is a graph database\",\n    \"Machine learning uses neural networks\"\n]\n\nwith db.transaction():\n    for doc_text in documents:\n        # Generate embedding\n        embedding = model.encode(doc_text)\n\n        # Create vertex\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"text\", doc_text)\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        # Add to index\n        index.add_vertex(vertex)\n</code></pre>"},{"location":"guide/vectors/#4-search","title":"4. Search","text":"<pre><code>query = \"What is Python?\"\nquery_embedding = model.encode(query)\n\nresults = index.find_nearest(query_embedding, k=3)\n\nfor vertex, distance in results:\n    text = vertex.get(\"text\")\n    similarity = 1 - distance  # Convert distance to similarity\n    print(f\"[{similarity:.3f}] {text}\")\n</code></pre>"},{"location":"guide/vectors/#embedding-models","title":"Embedding Models","text":""},{"location":"guide/vectors/#sentence-transformers","title":"Sentence Transformers","text":"<p>Best for text similarity:</p> <pre><code>from sentence_transformers import SentenceTransformer\n\n# All-purpose (384 dimensions)\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# High quality (768 dimensions)\nmodel = SentenceTransformer('all-mpnet-base-v2')\n\n# Multilingual (768 dimensions)\nmodel = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n\n# Generate embedding\nembedding = model.encode(\"Your text here\")\nprint(embedding.shape)  # (384,) or (768,)\n</code></pre> <p>Installation: <pre><code>pip install sentence-transformers\n</code></pre></p>"},{"location":"guide/vectors/#openai-embeddings","title":"OpenAI Embeddings","text":"<p>Commercial API with high quality:</p> <pre><code>from openai import OpenAI\n\nclient = OpenAI(api_key=\"your-api-key\")\n\ndef get_embedding(text, model=\"text-embedding-3-small\"):\n    response = client.embeddings.create(\n        input=text,\n        model=model\n    )\n    return response.data[0].embedding\n\n# text-embedding-3-small: 1536 dimensions\n# text-embedding-3-large: 3072 dimensions\nembedding = get_embedding(\"Your text here\")\n</code></pre> <p>Installation: <pre><code>pip install openai\n</code></pre></p>"},{"location":"guide/vectors/#hugging-face-transformers","title":"Hugging Face Transformers","text":"<p>For custom models:</p> <pre><code>from transformers import AutoTokenizer, AutoModel\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\nmodel = AutoModel.from_pretrained('bert-base-uncased')\n\ndef get_embedding(text):\n    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    # Use [CLS] token embedding\n    embedding = outputs.last_hidden_state[0][0].numpy()\n    return embedding\n\nembedding = get_embedding(\"Your text here\")\n</code></pre>"},{"location":"guide/vectors/#clip-images-text","title":"CLIP (Images + Text)","text":"<p>For multimodal search:</p> <pre><code>from transformers import CLIPProcessor, CLIPModel\nfrom PIL import Image\n\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n# Image embedding\nimage = Image.open(\"photo.jpg\")\ninputs = processor(images=image, return_tensors=\"pt\")\nimage_embedding = model.get_image_features(**inputs)[0].detach().numpy()\n\n# Text embedding\ninputs = processor(text=[\"a photo of a cat\"], return_tensors=\"pt\")\ntext_embedding = model.get_text_features(**inputs)[0].detach().numpy()\n</code></pre>"},{"location":"guide/vectors/#distance-functions","title":"Distance Functions","text":""},{"location":"guide/vectors/#cosine-distance","title":"Cosine Distance","text":"<p>Best for: Text embeddings, normalized vectors</p> <p>Formula: <code>1 - (A \u00b7 B) / (||A|| * ||B||)</code></p> <p>Range: [0, 2], lower is more similar</p> <p>Usage: <pre><code>index = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    distance_function=\"cosine\"  # Default\n)\n</code></pre></p> <p>When to Use: - Text embeddings (Sentence Transformers, OpenAI) - When direction matters more than magnitude - Most common choice for semantic search</p>"},{"location":"guide/vectors/#euclidean-distance","title":"Euclidean Distance","text":"<p>Best for: Image embeddings, spatial data</p> <p>Formula: <code>sqrt(\u03a3(Ai - Bi)\u00b2)</code></p> <p>Range: [0, \u221e), lower is more similar</p> <p>Usage: <pre><code>index = db.create_vector_index(\n    vertex_type=\"Image\",\n    vector_property=\"features\",\n    dimensions=512,\n    distance_function=\"euclidean\"\n)\n</code></pre></p> <p>When to Use: - Image embeddings (ResNet, VGG) - When absolute distance matters - Spatial or geometric data</p>"},{"location":"guide/vectors/#inner-product","title":"Inner Product","text":"<p>Best for: Collaborative filtering, recommendations</p> <p>Formula: <code>-(A \u00b7 B)</code></p> <p>Range: (-\u221e, \u221e), higher is more similar (note: inverted!)</p> <p>Usage: <pre><code>index = db.create_vector_index(\n    vertex_type=\"User\",\n    vector_property=\"preferences\",\n    dimensions=128,\n    distance_function=\"inner_product\"\n)\n</code></pre></p> <p>When to Use: - Recommendation systems - When vectors aren't normalized - When magnitude carries information</p>"},{"location":"guide/vectors/#hnsw-parameters","title":"HNSW Parameters","text":""},{"location":"guide/vectors/#m-parameter","title":"M Parameter","text":"<p>Controls connections per node in the graph.</p> <pre><code>index = db.create_vector_index(\n    vertex_type=\"Doc\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    m=16  # Number of connections\n)\n</code></pre> <p>Trade-offs:</p> M Value Recall Memory Build Speed Search Speed 8-12 Lower Low Fast Fast 16-24 Good Medium Medium Medium 32-48 High High Slow Slow <p>Recommendations: - Small datasets (&lt;100K): M=16 - Medium datasets (100K-1M): M=24 - Large datasets (&gt;1M): M=32-48</p>"},{"location":"guide/vectors/#ef-parameter","title":"ef Parameter","text":"<p>Controls search quality vs speed.</p> <pre><code>index = db.create_vector_index(\n    vertex_type=\"Doc\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    ef=128  # Search candidate list size\n)\n</code></pre> <p>Trade-offs:</p> ef Value Recall Search Speed 50-100 Lower Fast 128-200 Good Medium 200-400 High Slow <p>Recommendations: - Fast search: ef=50-100 - Balanced: ef=128-200 - High accuracy: ef=200-400</p>"},{"location":"guide/vectors/#ef_construction-parameter","title":"ef_construction Parameter","text":"<p>Controls index build quality.</p> <pre><code>index = db.create_vector_index(\n    vertex_type=\"Doc\",\n    vector_property=\"embedding\",\n    dimensions=384,\n    ef_construction=128  # Build candidate list size\n)\n</code></pre> <p>Trade-offs:</p> ef_construction Index Quality Build Time 100-150 Lower Fast 128-256 Good Medium 300-500 High Slow <p>Recommendations: - Fast iteration: ef_construction=100 - Production: ef_construction=200 - Maximum quality: ef_construction=400</p> <p>Note: Higher ef_construction improves recall but only affects index building, not search.</p>"},{"location":"guide/vectors/#schema-design","title":"Schema Design","text":""},{"location":"guide/vectors/#basic-schema","title":"Basic Schema","text":"<pre><code>with db.transaction():\n    # Vertex type for documents\n    db.command(\"sql\", \"CREATE VERTEX TYPE Document\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.text STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Document.embedding ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE INDEX ON Document (id) UNIQUE\")\n\n# Vector index\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=384\n)\n</code></pre>"},{"location":"guide/vectors/#with-metadata","title":"With Metadata","text":"<pre><code>with db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Article\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.id STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.title STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.content STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.category STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.created_at DATETIME\")\n    db.command(\"sql\", \"CREATE PROPERTY Article.embedding ARRAY_OF_FLOATS\")\n\n    # Regular indexes for filtering\n    db.command(\"sql\", \"CREATE INDEX ON Article (id) UNIQUE\")\n    db.command(\"sql\", \"CREATE INDEX ON Article (category) NOTUNIQUE\")\n\n# Vector index\nindex = db.create_vector_index(\n    vertex_type=\"Article\",\n    vector_property=\"embedding\",\n    dimensions=384\n)\n</code></pre>"},{"location":"guide/vectors/#multiple-vector-types","title":"Multiple Vector Types","text":"<pre><code># Products with text and image embeddings\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Product\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.name STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.description STRING\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.text_embedding ARRAY_OF_FLOATS\")\n    db.command(\"sql\", \"CREATE PROPERTY Product.image_embedding ARRAY_OF_FLOATS\")\n\n# Separate indexes for each embedding type\ntext_index = db.create_vector_index(\n    vertex_type=\"Product\",\n    vector_property=\"text_embedding\",\n    dimensions=384,\n    distance_function=\"cosine\"\n)\n\nimage_index = db.create_vector_index(\n    vertex_type=\"Product\",\n    vector_property=\"image_embedding\",\n    dimensions=512,\n    distance_function=\"euclidean\"\n)\n</code></pre>"},{"location":"guide/vectors/#search-patterns","title":"Search Patterns","text":""},{"location":"guide/vectors/#basic-similarity-search","title":"Basic Similarity Search","text":"<pre><code>query_embedding = model.encode(\"machine learning\")\nresults = index.find_nearest(query_embedding, k=10)\n\nfor vertex, distance in results:\n    text = vertex.get(\"text\")\n    print(f\"{text} (distance: {distance:.4f})\")\n</code></pre>"},{"location":"guide/vectors/#hybrid-search-vector-filters","title":"Hybrid Search (Vector + Filters)","text":"<p>Combine vector similarity with metadata filters:</p> <pre><code># Get candidates from vector search\nquery_embedding = model.encode(\"python tutorial\")\ncandidates = index.find_nearest(query_embedding, k=100)\n\n# Filter by metadata\nfiltered_results = []\nfor vertex, distance in candidates:\n    category = vertex.get(\"category\")\n    created_at = vertex.get(\"created_at\")\n\n    # Apply filters\n    if category == \"Programming\" and distance &lt; 0.5:\n        filtered_results.append((vertex, distance))\n\n    if len(filtered_results) &gt;= 10:\n        break\n\n# Display results\nfor vertex, distance in filtered_results:\n    title = vertex.get(\"title\")\n    print(f\"{title} - {distance:.4f}\")\n</code></pre>"},{"location":"guide/vectors/#re-ranking-with-multiple-embeddings","title":"Re-ranking with Multiple Embeddings","text":"<pre><code># First pass: Text search\ntext_query = \"red sports car\"\ntext_embedding = text_model.encode(text_query)\ntext_results = text_index.find_nearest(text_embedding, k=50)\n\n# Second pass: Image search\nimage_embedding = image_model.encode(query_image)\nimage_results = image_index.find_nearest(image_embedding, k=50)\n\n# Combine scores\ncombined_scores = {}\nfor vertex, distance in text_results:\n    rid = vertex.get(\"@rid\")\n    combined_scores[rid] = {\"vertex\": vertex, \"text_dist\": distance, \"image_dist\": None}\n\nfor vertex, distance in image_results:\n    rid = vertex.get(\"@rid\")\n    if rid in combined_scores:\n        combined_scores[rid][\"image_dist\"] = distance\n    else:\n        combined_scores[rid] = {\"vertex\": vertex, \"text_dist\": None, \"image_dist\": distance}\n\n# Weighted combination\nfinal_results = []\nfor rid, data in combined_scores.items():\n    text_dist = data[\"text_dist\"] or 1.0\n    image_dist = data[\"image_dist\"] or 1.0\n\n    # Weighted average\n    combined_dist = 0.6 * text_dist + 0.4 * image_dist\n    final_results.append((data[\"vertex\"], combined_dist))\n\n# Sort by combined score\nfinal_results.sort(key=lambda x: x[1])\n\nfor vertex, score in final_results[:10]:\n    name = vertex.get(\"name\")\n    print(f\"{name} - combined score: {score:.4f}\")\n</code></pre>"},{"location":"guide/vectors/#pagination","title":"Pagination","text":"<pre><code>def paginated_search(query_embedding, page_size=10, page=0):\n    \"\"\"Search with pagination.\"\"\"\n    # Get more results than needed\n    k = (page + 1) * page_size + 10\n    results = index.find_nearest(query_embedding, k=k)\n\n    # Slice for current page\n    start = page * page_size\n    end = start + page_size\n\n    page_results = list(results)[start:end]\n    return page_results\n\n# Page 0\npage1 = paginated_search(query_embedding, page_size=10, page=0)\n\n# Page 1\npage2 = paginated_search(query_embedding, page_size=10, page=1)\n</code></pre>"},{"location":"guide/vectors/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guide/vectors/#batch-indexing","title":"Batch Indexing","text":"<pre><code># Efficient: Batch in single transaction\nbatch_size = 1000\ndocuments = load_documents()  # Your data source\n\nwith db.transaction():\n    for i, doc in enumerate(documents):\n        embedding = model.encode(doc['text'])\n\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"text\", doc['text'])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        index.add_vertex(vertex)\n\n        # Commit every batch_size records\n        if (i + 1) % batch_size == 0:\n            db.commit()\n            db.begin()\n\n    # Commit remaining\n    db.commit()\n</code></pre>"},{"location":"guide/vectors/#embedding-caching","title":"Embedding Caching","text":"<pre><code>import pickle\nfrom pathlib import Path\n\nclass EmbeddingCache:\n    def __init__(self, cache_dir=\"./embedding_cache\"):\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(exist_ok=True)\n\n    def get_cache_path(self, text):\n        import hashlib\n        key = hashlib.md5(text.encode()).hexdigest()\n        return self.cache_dir / f\"{key}.pkl\"\n\n    def get(self, text):\n        cache_path = self.get_cache_path(text)\n        if cache_path.exists():\n            with open(cache_path, 'rb') as f:\n                return pickle.load(f)\n        return None\n\n    def set(self, text, embedding):\n        cache_path = self.get_cache_path(text)\n        with open(cache_path, 'wb') as f:\n            pickle.dump(embedding, f)\n\n# Usage\ncache = EmbeddingCache()\n\ndef get_embedding_cached(text, model):\n    embedding = cache.get(text)\n    if embedding is None:\n        embedding = model.encode(text)\n        cache.set(text, embedding)\n    return embedding\n\n# Much faster on repeated queries\nembedding = get_embedding_cached(\"python tutorial\", model)\n</code></pre>"},{"location":"guide/vectors/#incremental-updates","title":"Incremental Updates","text":"<pre><code>def add_document(db, index, model, doc_data):\n    \"\"\"Add single document efficiently.\"\"\"\n    with db.transaction():\n        # Generate embedding\n        embedding = model.encode(doc_data['text'])\n\n        # Create vertex\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"id\", doc_data['id'])\n        vertex.set(\"text\", doc_data['text'])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        # Add to index\n        index.add_vertex(vertex)\n\n    return vertex\n\ndef update_document(db, index, model, doc_id, new_text):\n    \"\"\"Update document and re-index.\"\"\"\n    with db.transaction():\n        # Find existing\n        result = db.query(\"sql\", f\"SELECT FROM Document WHERE id = '{doc_id}'\")\n        if not result.has_next():\n            raise ValueError(f\"Document {doc_id} not found\")\n\n        vertex = result.next()\n\n        # Remove from index\n        index.remove_vertex(doc_id)\n\n        # Update\n        new_embedding = model.encode(new_text)\n        vertex.set(\"text\", new_text)\n        vertex.set(\"embedding\", to_java_float_array(new_embedding))\n        vertex.save()\n\n        # Re-add to index\n        index.add_vertex(vertex)\n</code></pre>"},{"location":"guide/vectors/#memory-management","title":"Memory Management","text":"<pre><code># For large datasets, process in chunks\ndef index_large_dataset(db, index, model, data_source, chunk_size=1000):\n    \"\"\"Index large dataset with memory management.\"\"\"\n    import gc\n\n    chunk_count = 0\n\n    for chunk in data_source.iter_chunks(chunk_size):\n        # Generate embeddings for chunk\n        texts = [item['text'] for item in chunk]\n        embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)\n\n        # Index chunk\n        with db.transaction():\n            for item, embedding in zip(chunk, embeddings):\n                vertex = db.new_vertex(\"Document\")\n                vertex.set(\"text\", item['text'])\n                vertex.set(\"embedding\", to_java_float_array(embedding))\n                vertex.save()\n\n                index.add_vertex(vertex)\n\n        chunk_count += 1\n        print(f\"Indexed chunk {chunk_count} ({chunk_size} items)\")\n\n        # Force garbage collection\n        gc.collect()\n</code></pre>"},{"location":"guide/vectors/#production-patterns","title":"Production Patterns","text":""},{"location":"guide/vectors/#configuration-management","title":"Configuration Management","text":"<pre><code>import os\nfrom dataclasses import dataclass\n\n@dataclass\nclass VectorSearchConfig:\n    model_name: str = \"all-MiniLM-L6-v2\"\n    dimensions: int = 384\n    distance_function: str = \"cosine\"\n    m: int = 16\n    ef: int = 128\n    ef_construction: int = 128\n    max_items: int = 1000000\n\n# Load from environment\nconfig = VectorSearchConfig(\n    model_name=os.getenv(\"EMBEDDING_MODEL\", \"all-MiniLM-L6-v2\"),\n    dimensions=int(os.getenv(\"VECTOR_DIMENSIONS\", \"384\")),\n    m=int(os.getenv(\"HNSW_M\", \"16\")),\n    ef=int(os.getenv(\"HNSW_EF\", \"128\"))\n)\n\n# Use config\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer(config.model_name)\n\nindex = db.create_vector_index(\n    vertex_type=\"Document\",\n    vector_property=\"embedding\",\n    dimensions=config.dimensions,\n    distance_function=config.distance_function,\n    m=config.m,\n    ef=config.ef,\n    ef_construction=config.ef_construction\n)\n</code></pre>"},{"location":"guide/vectors/#monitoring-and-logging","title":"Monitoring and Logging","text":"<pre><code>import logging\nimport time\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass VectorSearchMetrics:\n    def __init__(self):\n        self.search_times = []\n        self.index_times = []\n\n    def log_search(self, query, results, elapsed):\n        self.search_times.append(elapsed)\n        avg_time = sum(self.search_times) / len(self.search_times)\n\n        logger.info(\n            f\"Search: {len(results)} results in {elapsed:.3f}s \"\n            f\"(avg: {avg_time:.3f}s)\"\n        )\n\n    def log_index(self, count, elapsed):\n        self.index_times.append(elapsed)\n        rate = count / elapsed if elapsed &gt; 0 else 0\n\n        logger.info(\n            f\"Indexed: {count} items in {elapsed:.2f}s \"\n            f\"({rate:.0f} items/sec)\"\n        )\n\n# Usage\nmetrics = VectorSearchMetrics()\n\n# Search with timing\nstart = time.time()\nresults = index.find_nearest(query_embedding, k=10)\nelapsed = time.time() - start\nmetrics.log_search(\"user query\", results, elapsed)\n\n# Indexing with timing\nstart = time.time()\n# ... index documents ...\nelapsed = time.time() - start\nmetrics.log_index(100, elapsed)\n</code></pre>"},{"location":"guide/vectors/#error-handling","title":"Error Handling","text":"<pre><code>from arcadedb_embedded import ArcadeDBError\n\ndef safe_vector_search(index, query_embedding, k=10, retries=3):\n    \"\"\"Vector search with retry logic.\"\"\"\n    for attempt in range(retries):\n        try:\n            results = index.find_nearest(query_embedding, k=k)\n            return results\n\n        except ArcadeDBError as e:\n            if attempt &lt; retries - 1:\n                logger.warning(f\"Search failed (attempt {attempt + 1}): {e}\")\n                time.sleep(0.1 * (attempt + 1))\n                continue\n            else:\n                logger.error(f\"Search failed after {retries} attempts: {e}\")\n                return []\n\n    return []\n\ndef safe_vector_index(db, index, model, document):\n    \"\"\"Index with error handling.\"\"\"\n    try:\n        with db.transaction():\n            embedding = model.encode(document['text'])\n\n            vertex = db.new_vertex(\"Document\")\n            vertex.set(\"text\", document['text'])\n            vertex.set(\"embedding\", to_java_float_array(embedding))\n            vertex.save()\n\n            index.add_vertex(vertex)\n\n            return True\n\n    except ArcadeDBError as e:\n        logger.error(f\"Indexing failed for document {document.get('id')}: {e}\")\n        return False\n</code></pre>"},{"location":"guide/vectors/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guide/vectors/#semantic-document-search","title":"Semantic Document Search","text":"<pre><code># Index documents\ndocuments = [\n    {\"id\": \"doc1\", \"title\": \"Python Tutorial\", \"content\": \"Learn Python...\"},\n    {\"id\": \"doc2\", \"title\": \"ML Guide\", \"content\": \"Machine learning...\"},\n]\n\nfor doc in documents:\n    # Combine title and content for embedding\n    text = f\"{doc['title']}. {doc['content']}\"\n    embedding = model.encode(text)\n\n    with db.transaction():\n        vertex = db.new_vertex(\"Document\")\n        vertex.set(\"id\", doc['id'])\n        vertex.set(\"title\", doc['title'])\n        vertex.set(\"content\", doc['content'])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        index.add_vertex(vertex)\n\n# Search\nquery = \"How do I learn programming?\"\nquery_embedding = model.encode(query)\nresults = index.find_nearest(query_embedding, k=5)\n\nfor vertex, distance in results:\n    print(f\"[{1-distance:.2f}] {vertex.get('title')}\")\n</code></pre>"},{"location":"guide/vectors/#question-answering","title":"Question Answering","text":"<pre><code># Index Q&amp;A pairs\nqa_pairs = [\n    {\"q\": \"What is Python?\", \"a\": \"Python is a programming language...\"},\n    {\"q\": \"How to install Python?\", \"a\": \"Download from python.org...\"},\n]\n\nfor qa in qa_pairs:\n    # Embed the question\n    embedding = model.encode(qa['q'])\n\n    with db.transaction():\n        vertex = db.new_vertex(\"QA\")\n        vertex.set(\"question\", qa['q'])\n        vertex.set(\"answer\", qa['a'])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        index.add_vertex(vertex)\n\n# Find answer for new question\nnew_question = \"Where can I get Python?\"\nquery_embedding = model.encode(new_question)\nresults = index.find_nearest(query_embedding, k=1)\n\nif results:\n    vertex, distance = results[0]\n    print(f\"Q: {vertex.get('question')}\")\n    print(f\"A: {vertex.get('answer')}\")\n    print(f\"Confidence: {1-distance:.2%}\")\n</code></pre>"},{"location":"guide/vectors/#product-recommendations","title":"Product Recommendations","text":"<pre><code># Index products with description embeddings\nproducts = [\n    {\"sku\": \"PROD1\", \"name\": \"Laptop\", \"desc\": \"High performance laptop\"},\n    {\"sku\": \"PROD2\", \"name\": \"Mouse\", \"desc\": \"Wireless mouse\"},\n]\n\nfor prod in products:\n    embedding = model.encode(prod['desc'])\n\n    with db.transaction():\n        vertex = db.new_vertex(\"Product\")\n        vertex.set(\"sku\", prod['sku'])\n        vertex.set(\"name\", prod['name'])\n        vertex.set(\"description\", prod['desc'])\n        vertex.set(\"embedding\", to_java_float_array(embedding))\n        vertex.save()\n\n        index.add_vertex(vertex)\n\n# Find similar products\ntarget_product_desc = \"portable computer\"\nquery_embedding = model.encode(target_product_desc)\nsimilar = index.find_nearest(query_embedding, k=5)\n\nprint(\"Similar products:\")\nfor vertex, distance in similar:\n    print(f\"  {vertex.get('name')} - {1-distance:.2%} match\")\n</code></pre>"},{"location":"guide/vectors/#see-also","title":"See Also","text":"<ul> <li>Vector API Reference - Complete API documentation</li> <li>Vector Examples - Practical code examples</li> <li>Database API - Database operations</li> <li>HNSW Paper - Original HNSW algorithm</li> </ul>"},{"location":"guide/core/database/","title":"Database Management","text":"<p>Comprehensive guide to database lifecycle, configuration, and resource management in ArcadeDB Python bindings.</p>"},{"location":"guide/core/database/#overview","title":"Overview","text":"<p>ArcadeDB databases are embedded, file-based databases stored on your local filesystem. The database lifecycle includes creation, opening, operations, and cleanup.</p> <p>Database Modes:</p> <ul> <li>Embedded: Database runs in your Python process</li> <li>In-Process: Direct Java API access via JPype</li> <li>File-Based: Data persisted to disk</li> </ul>"},{"location":"guide/core/database/#quick-start","title":"Quick Start","text":""},{"location":"guide/core/database/#create-new-database","title":"Create New Database","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Simple creation\ndb = arcadedb.create_database(\"./mydb\")\n\n# Use the database\nwith db.transaction():\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", \"Alice\")\n    vertex.save()\n\n# Always close when done\ndb.close()\n</code></pre>"},{"location":"guide/core/database/#open-existing-database","title":"Open Existing Database","text":"<pre><code># Open existing database\ndb = arcadedb.open_database(\"./mydb\")\n\n# Query data\nresult = db.query(\"sql\", \"SELECT FROM User\")\nfor user in result:\n    print(user.get(\"name\"))\n\ndb.close()\n</code></pre>"},{"location":"guide/core/database/#check-if-database-exists","title":"Check if Database Exists","text":"<pre><code>if arcadedb.database_exists(\"./mydb\"):\n    db = arcadedb.open_database(\"./mydb\")\nelse:\n    db = arcadedb.create_database(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#database-lifecycle","title":"Database Lifecycle","text":""},{"location":"guide/core/database/#1-creation","title":"1. Creation","text":"<pre><code>import arcadedb_embedded as arcadedb\n\n# Create new database\ndb = arcadedb.create_database(\"./mydb\")\n\n# Database is ready to use\nprint(f\"Database created at: {db.get_name()}\")\n\ndb.close()\n</code></pre> <p>What happens during creation:</p> <ol> <li>Directory <code>./mydb</code> created on filesystem</li> <li>Schema files initialized</li> <li>System files created (dictionary, configuration)</li> <li>Database opened in READ_WRITE mode</li> <li>Ready for operations</li> </ol>"},{"location":"guide/core/database/#2-opening","title":"2. Opening","text":"<pre><code># Open existing database\ndb = arcadedb.open_database(\"./mydb\")\n\n# Database is ready for operations\nprint(f\"Database opened: {db.get_name()}\")\n\ndb.close()\n</code></pre> <p>Opening modes:</p> <ul> <li><code>READ_WRITE</code> (default): Full access</li> <li><code>READ_ONLY</code>: Query-only access (coming soon to Python API)</li> </ul>"},{"location":"guide/core/database/#3-using","title":"3. Using","text":"<pre><code>db = arcadedb.open_database(\"./mydb\")\n\n# Create schema\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE Person\")\n    db.command(\"sql\", \"CREATE PROPERTY Person.name STRING\")\n\n# Insert data\nwith db.transaction():\n    person = db.new_vertex(\"Person\")\n    person.set(\"name\", \"Bob\")\n    person.save()\n\n# Query data\nresult = db.query(\"sql\", \"SELECT FROM Person\")\nfor person in result:\n    print(person.get(\"name\"))\n\ndb.close()\n</code></pre>"},{"location":"guide/core/database/#4-closing","title":"4. Closing","text":"<pre><code># Explicit close\ndb.close()\n\n# Or use context manager (recommended)\nwith arcadedb.open_database(\"./mydb\") as db:\n    # Use database\n    pass\n# Automatically closed\n</code></pre> <p>What happens during close:</p> <ol> <li>Active transactions rolled back</li> <li>Buffers flushed to disk</li> <li>Files closed</li> <li>Resources released</li> <li>Database removed from active instances</li> </ol>"},{"location":"guide/core/database/#5-dropping","title":"5. Dropping","text":"<pre><code>db = arcadedb.open_database(\"./mydb\")\n\n# Drop database (deletes all files)\ndb.drop()\n\n# Database and all files are permanently deleted\n</code></pre> <p>\u26a0\ufe0f Warning: <code>drop()</code> is irreversible and deletes all data!</p>"},{"location":"guide/core/database/#databasefactory-class","title":"DatabaseFactory Class","text":"<p>For advanced use cases, use <code>DatabaseFactory</code> directly:</p> <pre><code>import arcadedb_embedded as arcadedb\n\n# Create factory\nfactory = arcadedb.DatabaseFactory(\"./mydb\")\n\n# Check existence\nif factory.exists():\n    print(\"Database exists\")\n    db = factory.open()\nelse:\n    print(\"Creating new database\")\n    db = factory.create()\n\n# Use database\nwith db.transaction():\n    # Operations\n    pass\n\ndb.close()\n</code></pre>"},{"location":"guide/core/database/#factory-pattern-benefits","title":"Factory Pattern Benefits","text":"<ul> <li>Explicit control: Clear separation of creation/opening logic</li> <li>Reusability: One factory for multiple operations</li> <li>Configuration: Set options before creating/opening</li> </ul>"},{"location":"guide/core/database/#context-managers","title":"Context Managers","text":""},{"location":"guide/core/database/#database-context-manager","title":"Database Context Manager","text":"<pre><code># Automatic resource cleanup\nwith arcadedb.open_database(\"./mydb\") as db:\n    # Use database\n    result = db.query(\"sql\", \"SELECT FROM User\")\n    for row in result:\n        print(row.get(\"name\"))\n# Database automatically closed on exit\n</code></pre> <p>Benefits:</p> <ul> <li>\u2705 Automatic close on normal exit</li> <li>\u2705 Automatic close on exception</li> <li>\u2705 Guaranteed resource cleanup</li> <li>\u2705 Pythonic style</li> </ul>"},{"location":"guide/core/database/#nested-context-managers","title":"Nested Context Managers","text":"<pre><code># Open database and use transaction\nwith arcadedb.open_database(\"./mydb\") as db:\n    with db.transaction():\n        vertex = db.new_vertex(\"User\")\n        vertex.set(\"name\", \"Charlie\")\n        vertex.save()\n# Transaction committed, database closed\n</code></pre>"},{"location":"guide/core/database/#configuration","title":"Configuration","text":""},{"location":"guide/core/database/#database-directory-structure","title":"Database Directory Structure","text":"<pre><code>./mydb/\n\u251c\u2500\u2500 configuration.json       # Database configuration\n\u251c\u2500\u2500 schema.json             # Schema definition\n\u251c\u2500\u2500 schema.prev.json        # Schema backup\n\u251c\u2500\u2500 dictionary.*.dict       # String dictionary\n\u251c\u2500\u2500 statistics.json         # Database statistics\n\u251c\u2500\u2500 User_0.*.bucket        # User type data files\n\u251c\u2500\u2500 HasFriend_0.*.bucket   # Edge type data files\n\u2514\u2500\u2500 .lock                  # Lock file (when open)\n</code></pre>"},{"location":"guide/core/database/#database-location","title":"Database Location","text":"<pre><code>import os\n\n# Relative path\ndb = arcadedb.create_database(\"./mydb\")\n\n# Absolute path\ndb = arcadedb.create_database(\"/var/data/mydb\")\n\n# User home directory\nhome = os.path.expanduser(\"~\")\ndb = arcadedb.create_database(f\"{home}/databases/mydb\")\n</code></pre>"},{"location":"guide/core/database/#database-naming","title":"Database Naming","text":"<p>Rules:</p> <ul> <li>\u2705 Use alphanumeric characters</li> <li>\u2705 Use underscores and hyphens</li> <li>\u2705 Use forward slashes for paths</li> <li>\u274c Avoid spaces in names</li> <li>\u274c Avoid special characters</li> </ul> <pre><code># Good names\narcadedb.create_database(\"./my_database\")\narcadedb.create_database(\"./project-data\")\narcadedb.create_database(\"./data/production/main\")\n\n# Bad names\narcadedb.create_database(\"./my database\")      # Space\narcadedb.create_database(\"./data@2024\")        # Special char\n</code></pre>"},{"location":"guide/core/database/#resource-management","title":"Resource Management","text":""},{"location":"guide/core/database/#proper-cleanup","title":"Proper Cleanup","text":"<pre><code># \u2713 Recommended: Context manager\nwith arcadedb.open_database(\"./mydb\") as db:\n    # Use database\n    pass\n\n# \u2713 Acceptable: Explicit close\ndb = arcadedb.open_database(\"./mydb\")\ntry:\n    # Use database\n    pass\nfinally:\n    db.close()\n\n# \u2717 Bad: No cleanup\ndb = arcadedb.open_database(\"./mydb\")\n# Operations...\n# Database never closed!\n</code></pre>"},{"location":"guide/core/database/#multiple-databases","title":"Multiple Databases","text":"<pre><code># Open multiple databases simultaneously\ndb1 = arcadedb.open_database(\"./database1\")\ndb2 = arcadedb.open_database(\"./database2\")\n\ntry:\n    # Use both databases\n    result1 = db1.query(\"sql\", \"SELECT FROM User\")\n    result2 = db2.query(\"sql\", \"SELECT FROM Product\")\nfinally:\n    db1.close()\n    db2.close()\n\n# Or with context managers\nwith arcadedb.open_database(\"./database1\") as db1, \\\n     arcadedb.open_database(\"./database2\") as db2:\n    # Use both databases\n    pass\n</code></pre>"},{"location":"guide/core/database/#database-locking","title":"Database Locking","text":"<p>Lock File:</p> <ul> <li>Created when database opens: <code>.lock</code></li> <li>Prevents concurrent access from same/different processes</li> <li>Automatically removed on clean close</li> <li>Manual removal only if process crashed</li> </ul> <pre><code># If database locked by another process\ntry:\n    db = arcadedb.open_database(\"./mydb\")\nexcept Exception as e:\n    print(f\"Database locked: {e}\")\n\n    # Check if process is still running\n    # If not, remove lock file\n    import os\n    lock_file = \"./mydb/.lock\"\n    if os.path.exists(lock_file):\n        os.remove(lock_file)\n</code></pre>"},{"location":"guide/core/database/#common-patterns","title":"Common Patterns","text":""},{"location":"guide/core/database/#database-initialization","title":"Database Initialization","text":"<pre><code>def init_database(path: str):\n    \"\"\"Initialize database with schema.\"\"\"\n    # Create if doesn't exist\n    if not arcadedb.database_exists(path):\n        db = arcadedb.create_database(path)\n\n        # Create schema\n        with db.transaction():\n            db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n            db.command(\"sql\", \"CREATE PROPERTY User.email STRING\")\n            db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n\n            db.command(\"sql\", \"CREATE VERTEX TYPE Post\")\n            db.command(\"sql\", \"CREATE PROPERTY Post.title STRING\")\n\n            db.command(\"sql\", \"CREATE EDGE TYPE Authored\")\n\n        print(f\"Database initialized at {path}\")\n        return db\n    else:\n        return arcadedb.open_database(path)\n\n# Usage\ndb = init_database(\"./myapp\")\n</code></pre>"},{"location":"guide/core/database/#database-reset","title":"Database Reset","text":"<pre><code>def reset_database(path: str):\n    \"\"\"Drop and recreate database.\"\"\"\n    if arcadedb.database_exists(path):\n        db = arcadedb.open_database(path)\n        db.drop()\n        print(f\"Database dropped: {path}\")\n\n    db = arcadedb.create_database(path)\n    print(f\"Database created: {path}\")\n    return db\n\n# Usage\ndb = reset_database(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#database-backup-pattern","title":"Database Backup Pattern","text":"<pre><code>import shutil\nimport datetime\n\ndef backup_database(db_path: str, backup_dir: str):\n    \"\"\"Backup database files.\"\"\"\n    # Close database first\n    if arcadedb.database_exists(db_path):\n        db = arcadedb.open_database(db_path)\n        db.close()  # Ensure clean state\n\n    # Create backup with timestamp\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    backup_path = f\"{backup_dir}/backup_{timestamp}\"\n\n    # Copy database directory\n    shutil.copytree(db_path, backup_path)\n    print(f\"Backup created: {backup_path}\")\n\n    return backup_path\n\n# Usage\nbackup_path = backup_database(\"./mydb\", \"./backups\")\n</code></pre>"},{"location":"guide/core/database/#database-migration","title":"Database Migration","text":"<pre><code>def migrate_database(old_path: str, new_path: str):\n    \"\"\"Migrate data from old to new database.\"\"\"\n    # Open old database\n    old_db = arcadedb.open_database(old_path)\n\n    # Create new database\n    new_db = arcadedb.create_database(new_path)\n\n    try:\n        # Copy schema\n        with new_db.transaction():\n            # Create types\n            new_db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n            new_db.command(\"sql\", \"CREATE VERTEX TYPE Post\")\n            new_db.command(\"sql\", \"CREATE EDGE TYPE Authored\")\n\n        # Copy data\n        batch_size = 1000\n\n        # Migrate users\n        result = old_db.query(\"sql\", \"SELECT FROM User\")\n        users_batch = []\n        for user in result:\n            users_batch.append(user)\n\n            if len(users_batch) &gt;= batch_size:\n                with new_db.transaction():\n                    for u in users_batch:\n                        new_user = new_db.new_vertex(\"User\")\n                        new_user.set(\"name\", u.get(\"name\"))\n                        new_user.set(\"email\", u.get(\"email\"))\n                        new_user.save()\n                users_batch = []\n\n        # Flush remaining\n        if users_batch:\n            with new_db.transaction():\n                for u in users_batch:\n                    new_user = new_db.new_vertex(\"User\")\n                    new_user.set(\"name\", u.get(\"name\"))\n                    new_user.set(\"email\", u.get(\"email\"))\n                    new_user.save()\n\n        print(\"Migration complete\")\n    finally:\n        old_db.close()\n        new_db.close()\n\n# Usage\nmigrate_database(\"./old_db\", \"./new_db\")\n</code></pre>"},{"location":"guide/core/database/#singleton-database-pattern","title":"Singleton Database Pattern","text":"<pre><code>class DatabaseManager:\n    \"\"\"Singleton database manager.\"\"\"\n\n    _instance = None\n    _db = None\n\n    def __new__(cls, path: str):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._path = path\n        return cls._instance\n\n    def get_database(self):\n        \"\"\"Get or create database connection.\"\"\"\n        if self._db is None:\n            if arcadedb.database_exists(self._path):\n                self._db = arcadedb.open_database(self._path)\n            else:\n                self._db = arcadedb.create_database(self._path)\n        return self._db\n\n    def close(self):\n        \"\"\"Close database connection.\"\"\"\n        if self._db is not None:\n            self._db.close()\n            self._db = None\n\n# Usage\nmanager = DatabaseManager(\"./mydb\")\ndb = manager.get_database()\n\n# Use database\nresult = db.query(\"sql\", \"SELECT FROM User\")\n\n# Later...\nmanager.close()\n</code></pre>"},{"location":"guide/core/database/#database-information","title":"Database Information","text":""},{"location":"guide/core/database/#get-database-name","title":"Get Database Name","text":"<pre><code>db = arcadedb.open_database(\"./mydb\")\nprint(f\"Database: {db.get_name()}\")  # \"mydb\"\n</code></pre>"},{"location":"guide/core/database/#get-database-path","title":"Get Database Path","text":"<pre><code>db = arcadedb.open_database(\"./mydb\")\nprint(f\"Path: {db.get_name()}\")\n# Note: Currently returns name, full path API coming soon\n</code></pre>"},{"location":"guide/core/database/#check-transaction-status","title":"Check Transaction Status","text":"<pre><code>db = arcadedb.open_database(\"./mydb\")\n\nprint(db.is_transaction_active())  # False\n\nwith db.transaction():\n    print(db.is_transaction_active())  # True\n\nprint(db.is_transaction_active())  # False\n</code></pre>"},{"location":"guide/core/database/#error-handling","title":"Error Handling","text":""},{"location":"guide/core/database/#database-already-exists","title":"Database Already Exists","text":"<pre><code>try:\n    db = arcadedb.create_database(\"./mydb\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    # Database already exists\n    db = arcadedb.open_database(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#database-not-found","title":"Database Not Found","text":"<pre><code>try:\n    db = arcadedb.open_database(\"./nonexistent\")\nexcept Exception as e:\n    print(f\"Database not found: {e}\")\n    # Create it\n    db = arcadedb.create_database(\"./nonexistent\")\n</code></pre>"},{"location":"guide/core/database/#database-locked","title":"Database Locked","text":"<pre><code>import time\n\ndef open_with_retry(path, max_retries=3):\n    \"\"\"Open database with retry logic.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return arcadedb.open_database(path)\n        except Exception as e:\n            if \"locked\" in str(e).lower():\n                if attempt &lt; max_retries - 1:\n                    print(f\"Database locked, retry {attempt + 1}/{max_retries}\")\n                    time.sleep(1)\n                    continue\n            raise\n    raise Exception(\"Failed to open database after retries\")\n\n# Usage\ndb = open_with_retry(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#graceful-shutdown","title":"Graceful Shutdown","text":"<pre><code>import atexit\nimport signal\n\ndb = None\n\ndef cleanup():\n    \"\"\"Cleanup on exit.\"\"\"\n    global db\n    if db is not None:\n        try:\n            if db.is_transaction_active():\n                db.rollback()\n            db.close()\n            print(\"Database closed cleanly\")\n        except:\n            pass\n\n# Register cleanup handlers\natexit.register(cleanup)\nsignal.signal(signal.SIGTERM, lambda s, f: cleanup())\nsignal.signal(signal.SIGINT, lambda s, f: cleanup())\n\n# Use database\ndb = arcadedb.open_database(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#best-practices","title":"Best Practices","text":""},{"location":"guide/core/database/#1-always-close-databases","title":"1. Always Close Databases","text":"<pre><code># \u2713 Use context managers\nwith arcadedb.open_database(\"./mydb\") as db:\n    pass\n\n# \u2713 Or explicit close in finally\ndb = arcadedb.open_database(\"./mydb\")\ntry:\n    pass\nfinally:\n    db.close()\n</code></pre>"},{"location":"guide/core/database/#2-check-existence-before-creating","title":"2. Check Existence Before Creating","text":"<pre><code># \u2713 Check first\nif arcadedb.database_exists(\"./mydb\"):\n    db = arcadedb.open_database(\"./mydb\")\nelse:\n    db = arcadedb.create_database(\"./mydb\")\n\n# \u2717 Don't blindly create\ndb = arcadedb.create_database(\"./mydb\")  # Error if exists!\n</code></pre>"},{"location":"guide/core/database/#3-use-absolute-paths-in-production","title":"3. Use Absolute Paths in Production","text":"<pre><code>import os\n\n# \u2713 Absolute path\ndb_path = os.path.abspath(\"./mydb\")\ndb = arcadedb.open_database(db_path)\n\n# \u2717 Relative paths can be ambiguous\ndb = arcadedb.open_database(\"./mydb\")  # Depends on CWD\n</code></pre>"},{"location":"guide/core/database/#4-initialize-schema-on-creation","title":"4. Initialize Schema on Creation","text":"<pre><code>def get_or_create_database(path):\n    if arcadedb.database_exists(path):\n        return arcadedb.open_database(path)\n\n    # Create with schema\n    db = arcadedb.create_database(path)\n\n    with db.transaction():\n        # Define schema here\n        db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n        db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n\n    return db\n</code></pre>"},{"location":"guide/core/database/#5-handle-concurrent-access","title":"5. Handle Concurrent Access","text":"<pre><code># Only one process can open database at a time\n# For multi-process: use server mode instead\n\n# \u2713 Single process, multiple threads\ndb = arcadedb.open_database(\"./mydb\")\n# Each thread uses same db instance\n\n# \u2717 Multiple processes opening same database\n# Process 1: arcadedb.open_database(\"./mydb\")\n# Process 2: arcadedb.open_database(\"./mydb\")  # ERROR!\n</code></pre>"},{"location":"guide/core/database/#6-backup-before-dropping","title":"6. Backup Before Dropping","text":"<pre><code>import shutil\n\ndef safe_drop(db_path, backup_path):\n    \"\"\"Drop database with backup.\"\"\"\n    # Backup first\n    shutil.copytree(db_path, backup_path)\n\n    # Then drop\n    db = arcadedb.open_database(db_path)\n    db.drop()\n\n    print(f\"Database dropped, backup at {backup_path}\")\n</code></pre>"},{"location":"guide/core/database/#7-monitor-database-size","title":"7. Monitor Database Size","text":"<pre><code>import os\n\ndef get_database_size(db_path):\n    \"\"\"Get database size in MB.\"\"\"\n    total_size = 0\n    for dirpath, dirnames, filenames in os.walk(db_path):\n        for filename in filenames:\n            filepath = os.path.join(dirpath, filename)\n            total_size += os.path.getsize(filepath)\n    return total_size / (1024 * 1024)  # MB\n\n# Usage\nsize_mb = get_database_size(\"./mydb\")\nprint(f\"Database size: {size_mb:.2f} MB\")\n</code></pre>"},{"location":"guide/core/database/#advanced-topics","title":"Advanced Topics","text":""},{"location":"guide/core/database/#jvm-lifecycle-and-databases","title":"JVM Lifecycle and Databases","text":"<pre><code># JVM starts on first import\nimport arcadedb_embedded as arcadedb  # JVM starts here\n\n# JVM runs for entire Python process\ndb1 = arcadedb.create_database(\"./db1\")\ndb1.close()\n\ndb2 = arcadedb.open_database(\"./db1\")  # Same JVM\ndb2.close()\n\n# JVM shuts down when Python exits\n</code></pre>"},{"location":"guide/core/database/#multiple-databases-one-jvm","title":"Multiple Databases, One JVM","text":"<pre><code># All databases share the same JVM\ndb1 = arcadedb.open_database(\"./database1\")\ndb2 = arcadedb.open_database(\"./database2\")\ndb3 = arcadedb.open_database(\"./database3\")\n\n# Efficient: shared JVM resources\n# Remember to close all!\ndb1.close()\ndb2.close()\ndb3.close()\n</code></pre>"},{"location":"guide/core/database/#database-path-normalization","title":"Database Path Normalization","text":"<pre><code># ArcadeDB normalizes paths\ndb1 = arcadedb.open_database(\"./mydb\")\ndb2 = arcadedb.open_database(\"./mydb/\")  # Same as above\ndb3 = arcadedb.open_database(\"mydb\")     # Different! (no ./)\n\n# Use consistent paths\ndb1.close()\n</code></pre>"},{"location":"guide/core/database/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/core/database/#database-already-exists_1","title":"\"Database already exists\"","text":"<pre><code># Check first\nif arcadedb.database_exists(\"./mydb\"):\n    db = arcadedb.open_database(\"./mydb\")\nelse:\n    db = arcadedb.create_database(\"./mydb\")\n</code></pre>"},{"location":"guide/core/database/#database-not-found_1","title":"\"Database not found\"","text":"<pre><code># Verify path\nimport os\ndb_path = \"./mydb\"\nif not os.path.exists(db_path):\n    print(f\"Path doesn't exist: {db_path}\")\n    db = arcadedb.create_database(db_path)\n</code></pre>"},{"location":"guide/core/database/#database-is-locked","title":"\"Database is locked\"","text":"<pre><code># Another process has database open\n# Solution 1: Close other process\n# Solution 2: Remove .lock file if process crashed\nimport os\nlock_file = \"./mydb/.lock\"\nif os.path.exists(lock_file):\n    os.remove(lock_file)\n</code></pre>"},{"location":"guide/core/database/#memory-usage","title":"Memory Usage","text":"<pre><code>import gc\n\n# Force garbage collection after closing\ndb.close()\ngc.collect()  # Clean up Java objects\n</code></pre>"},{"location":"guide/core/database/#see-also","title":"See Also","text":"<ul> <li>Database API Reference - Complete API documentation</li> <li>Transactions - Transaction management</li> <li>Quick Start - Getting started guide</li> <li>Server Mode - Multi-process database access</li> </ul>"},{"location":"guide/core/queries/","title":"Query Languages Guide","text":"<p>ArcadeDB supports multiple query languages, each with different strengths. This guide helps you choose the right language and write effective queries.</p>"},{"location":"guide/core/queries/#overview","title":"Overview","text":"<p>Supported Query Languages:</p> <ul> <li>SQL: Primary language, full-featured, best for most use cases</li> <li>Cypher: OpenCypher for graph pattern matching</li> <li>Gremlin: Apache TinkerPop for graph traversals (requires full distribution)</li> <li>MongoDB: MongoDB-compatible syntax (requires mongodbw plugin)</li> <li>GraphQL: GraphQL queries (requires graphql plugin)</li> </ul>"},{"location":"guide/core/queries/#quick-reference","title":"Quick Reference","text":"Language Best For Distribution Learning Curve SQL General queries, analytics All Easy Cypher Graph patterns, relationships All Medium Gremlin Complex graph algorithms Full only Hard MongoDB Document queries Full only Easy GraphQL API queries Full only Medium"},{"location":"guide/core/queries/#sql","title":"SQL","text":""},{"location":"guide/core/queries/#why-sql","title":"Why SQL?","text":"<p>Primary language for ArcadeDB with the most complete feature set.</p> <p>Strengths: - Full CRUD operations - Schema management - Indexes and constraints - Aggregations - Graph traversal extensions - Best performance</p> <p>Use SQL when: - You need full control - Building schema or indexes - Doing analytics - Writing production queries</p>"},{"location":"guide/core/queries/#basic-select","title":"Basic SELECT","text":"<pre><code># Simple select\nresult = db.query(\"sql\", \"SELECT FROM User\")\nfor vertex in result:\n    print(vertex.get(\"name\"))\n\n# With WHERE clause\nresult = db.query(\"sql\", \"SELECT FROM User WHERE age &gt; 25\")\n\n# Projection\nresult = db.query(\"sql\", \"SELECT name, email FROM User\")\n\n# LIMIT and SKIP\nresult = db.query(\"sql\", \"SELECT FROM User LIMIT 10 SKIP 20\")\n\n# ORDER BY\nresult = db.query(\"sql\", \"SELECT FROM User ORDER BY name ASC\")\n</code></pre>"},{"location":"guide/core/queries/#graph-traversal","title":"Graph Traversal","text":"<pre><code># Outgoing edges\nresult = db.query(\"sql\", \"\"\"\n    SELECT expand(out('Follows'))\n    FROM User\n    WHERE name = 'Alice'\n\"\"\")\n\n# Incoming edges\nresult = db.query(\"sql\", \"\"\"\n    SELECT expand(in('Purchased'))\n    FROM Product\n    WHERE id = 'PROD123'\n\"\"\")\n\n# Both directions\nresult = db.query(\"sql\", \"\"\"\n    SELECT expand(both('FriendOf'))\n    FROM User\n    WHERE name = 'Bob'\n\"\"\")\n\n# Multi-hop traversal\nresult = db.query(\"sql\", \"\"\"\n    SELECT expand(out('Follows').out('Follows'))\n    FROM User\n    WHERE name = 'Alice'\n\"\"\")\n# Friends of friends\n\n# Filtered traversal\nresult = db.query(\"sql\", \"\"\"\n    SELECT expand(out('Purchased')[price &gt; 100])\n    FROM User\n    WHERE name = 'Alice'\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#aggregations","title":"Aggregations","text":"<pre><code># COUNT\nresult = db.query(\"sql\", \"SELECT count(*) as total FROM User\")\ntotal = result.next().get(\"total\")\n\n# AVG, SUM, MIN, MAX\nresult = db.query(\"sql\", \"\"\"\n    SELECT \n        avg(age) as avg_age,\n        min(age) as min_age,\n        max(age) as max_age\n    FROM User\n\"\"\")\n\n# GROUP BY\nresult = db.query(\"sql\", \"\"\"\n    SELECT category, count(*) as count\n    FROM Product\n    GROUP BY category\n    ORDER BY count DESC\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#joins-and-subqueries","title":"JOINs and Subqueries","text":"<pre><code># Implicit JOIN via edges\nresult = db.query(\"sql\", \"\"\"\n    SELECT \n        User.name,\n        out('Purchased').name as products\n    FROM User\n    WHERE User.name = 'Alice'\n\"\"\")\n\n# Subquery in WHERE\nresult = db.query(\"sql\", \"\"\"\n    SELECT FROM Product\n    WHERE @rid IN (\n        SELECT out('Purchased')\n        FROM User\n        WHERE name = 'Alice'\n    )\n\"\"\")\n\n# WITH clause (CTE)\nresult = db.query(\"sql\", \"\"\"\n    WITH $active_users = (SELECT FROM User WHERE last_login &gt; sysdate() - 7)\n    SELECT FROM $active_users\n    WHERE age &gt; 25\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#full-text-search","title":"Full-Text Search","text":"<pre><code># Create full-text index\nwith db.transaction():\n    db.command(\"sql\", \"\"\"\n        CREATE INDEX Product.description_idx \n        ON Product (description) FULLTEXT ENGINE LUCENE\n    \"\"\")\n\n# Search\nresult = db.query(\"sql\", \"\"\"\n    SELECT FROM Product\n    WHERE SEARCH_INDEX('Product.description_idx', 'laptop computer') = true\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#parameters","title":"Parameters","text":"<pre><code># Named parameters (RECOMMENDED)\nresult = db.query(\"sql\", \n    \"SELECT FROM User WHERE name = :name AND age &gt; :min_age\",\n    {\n        \"name\": \"Alice\",\n        \"min_age\": 25\n    }\n)\n\n# Positional parameters\nresult = db.query(\"sql\",\n    \"SELECT FROM User WHERE name = ? AND age &gt; ?\",\n    [\"Alice\", 25]\n)\n</code></pre> <p>Always use parameters to prevent SQL injection!</p>"},{"location":"guide/core/queries/#advanced-sql","title":"Advanced SQL","text":"<pre><code># MATCH (graph pattern)\nresult = db.query(\"sql\", \"\"\"\n    MATCH {type: User, as: u}\n        -[:Follows]-&gt;\n        {as: f}\n        -[:Purchased]-&gt;\n        {type: Product, as: p}\n    WHERE u.name = 'Alice'\n    RETURN f.name, p.name\n\"\"\")\n\n# TRAVERSE\nresult = db.query(\"sql\", \"\"\"\n    TRAVERSE out('Knows')\n    FROM (SELECT FROM User WHERE name = 'Alice')\n    MAXDEPTH 3\n\"\"\")\n\n# LET (variables)\nresult = db.query(\"sql\", \"\"\"\n    SELECT name, $friends_count\n    FROM User\n    LET $friends_count = out('Knows').size()\n    WHERE $friends_count &gt; 10\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#cypher","title":"Cypher","text":""},{"location":"guide/core/queries/#why-cypher","title":"Why Cypher?","text":"<p>Graph-first query language from Neo4j, now OpenCypher standard.</p> <p>Strengths: - Intuitive graph patterns - Easy relationship queries - Readable syntax - Industry standard for graphs</p> <p>Use Cypher when: - Your team knows Neo4j - Focus on graph patterns - Migrating from Neo4j - Prefer declarative style</p>"},{"location":"guide/core/queries/#basic-match","title":"Basic MATCH","text":"<pre><code># Match all users\nresult = db.query(\"cypher\", \"MATCH (u:User) RETURN u\")\n\n# Match with properties\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User {name: 'Alice'})\n    RETURN u\n\"\"\")\n\n# Match with WHERE\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)\n    WHERE u.age &gt; 25\n    RETURN u.name, u.email\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#relationship-patterns","title":"Relationship Patterns","text":"<pre><code># Outgoing relationship\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User {name: 'Alice'})-[:FOLLOWS]-&gt;(f)\n    RETURN f.name\n\"\"\")\n\n# Incoming relationship\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (p:Product)&lt;-[:PURCHASED]-(u:User)\n    WHERE p.id = 'PROD123'\n    RETURN u.name\n\"\"\")\n\n# Bidirectional\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u1:User {name: 'Alice'})-[:FRIEND_OF]-(u2:User)\n    RETURN u2.name\n\"\"\")\n\n# Variable length paths\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u1:User {name: 'Alice'})-[:FOLLOWS*1..3]-&gt;(u2:User)\n    RETURN u2.name\n\"\"\")\n# 1 to 3 hops\n\n# Path with properties\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)-[r:PURCHASED {verified: true}]-&gt;(p:Product)\n    RETURN u.name, p.name, r.date\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#create-and-merge","title":"CREATE and MERGE","text":"<pre><code># Create node\nresult = db.query(\"cypher\", \"\"\"\n    CREATE (u:User {name: 'Alice', age: 30})\n    RETURN u\n\"\"\")\n\n# Create relationship\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u1:User {name: 'Alice'}), (u2:User {name: 'Bob'})\n    CREATE (u1)-[:FOLLOWS]-&gt;(u2)\n\"\"\")\n\n# MERGE (create if not exists)\nresult = db.query(\"cypher\", \"\"\"\n    MERGE (u:User {email: 'alice@example.com'})\n    ON CREATE SET u.created_at = timestamp()\n    ON MATCH SET u.last_seen = timestamp()\n    RETURN u\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#aggregations_1","title":"Aggregations","text":"<pre><code># COUNT\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)\n    RETURN count(u) as total\n\"\"\")\n\n# AVG, MIN, MAX\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)\n    RETURN avg(u.age) as avg_age,\n           min(u.age) as min_age,\n           max(u.age) as max_age\n\"\"\")\n\n# GROUP BY (implicit)\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)-[:PURCHASED]-&gt;(p:Product)\n    RETURN p.category, count(u) as buyers\n    ORDER BY buyers DESC\n\"\"\")\n\n# COLLECT\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User {name: 'Alice'})-[:FOLLOWS]-&gt;(f)\n    RETURN collect(f.name) as following\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#parameters_1","title":"Parameters","text":"<pre><code># Named parameters\nresult = db.query(\"cypher\",\n    \"MATCH (u:User {name: $name}) WHERE u.age &gt; $min_age RETURN u\",\n    {\n        \"name\": \"Alice\",\n        \"min_age\": 25\n    }\n)\n</code></pre>"},{"location":"guide/core/queries/#advanced-patterns","title":"Advanced Patterns","text":"<pre><code># Optional match (like LEFT JOIN)\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User)\n    OPTIONAL MATCH (u)-[:PURCHASED]-&gt;(p:Product)\n    RETURN u.name, p.name\n\"\"\")\n\n# Multiple patterns\nresult = db.query(\"cypher\", \"\"\"\n    MATCH (u:User {name: 'Alice'})-[:FOLLOWS]-&gt;(f)\n    MATCH (f)-[:PURCHASED]-&gt;(p:Product)\n    RETURN DISTINCT p.name\n\"\"\")\n\n# Path\nresult = db.query(\"cypher\", \"\"\"\n    MATCH path = (u1:User {name: 'Alice'})-[:KNOWS*]-(u2:User {name: 'Bob'})\n    RETURN path\n\"\"\")\n\n# Shortest path\nresult = db.query(\"cypher\", \"\"\"\n    MATCH path = shortestPath(\n        (u1:User {name: 'Alice'})-[:KNOWS*]-(u2:User {name: 'Bob'})\n    )\n    RETURN length(path) as degrees_of_separation\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#gremlin","title":"Gremlin","text":""},{"location":"guide/core/queries/#why-gremlin","title":"Why Gremlin?","text":"<p>Traversal-based graph query language from Apache TinkerPop.</p> <p>Requirements: - Full distribution only - More complex setup</p> <p>Strengths: - Powerful graph algorithms - Imperative traversal style - Industry standard - Rich graph analytics</p> <p>Use Gremlin when: - Need complex graph algorithms - PageRank, community detection - Your team knows TinkerPop - Building graph analytics</p>"},{"location":"guide/core/queries/#basic-traversals","title":"Basic Traversals","text":"<pre><code># Get all vertices\nresult = db.query(\"gremlin\", \"g.V()\")\n\n# Filter by label\nresult = db.query(\"gremlin\", \"g.V().hasLabel('User')\")\n\n# Filter by property\nresult = db.query(\"gremlin\", \"g.V().has('User', 'name', 'Alice')\")\n\n# Range filter\nresult = db.query(\"gremlin\", \"g.V().has('User', 'age', gt(25))\")\n</code></pre>"},{"location":"guide/core/queries/#graph-traversals","title":"Graph Traversals","text":"<pre><code># Outgoing edges\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice').out('Follows')\n\"\"\")\n\n# Incoming edges\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('Product', 'id', 'PROD123').in('Purchased')\n\"\"\")\n\n# Multi-hop\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice')\n        .out('Follows')\n        .out('Follows')\n\"\"\")\n\n# Repeat\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice')\n        .repeat(out('Knows'))\n        .times(3)\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#aggregations_2","title":"Aggregations","text":"<pre><code># Count\nresult = db.query(\"gremlin\", \"g.V().hasLabel('User').count()\")\n\n# Group by\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().hasLabel('Product')\n        .group()\n        .by('category')\n        .by(count())\n\"\"\")\n\n# Statistics\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().hasLabel('User')\n        .values('age')\n        .mean()\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#path-queries","title":"Path Queries","text":"<pre><code># Find paths\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice')\n        .repeat(out('Knows'))\n        .until(has('name', 'Bob'))\n        .path()\n\"\"\")\n\n# Shortest path\nresult = db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice')\n        .repeat(out('Knows').simplePath())\n        .until(has('name', 'Bob'))\n        .path()\n        .limit(1)\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#mongodb-syntax","title":"MongoDB Syntax","text":""},{"location":"guide/core/queries/#why-mongodb","title":"Why MongoDB?","text":"<p>Document-oriented query syntax for document databases.</p> <p>Requirements: - Full distribution only - mongodbw plugin</p> <p>Strengths: - Familiar to MongoDB users - Good for documents - JSON-like syntax</p> <p>Use MongoDB syntax when: - Migrating from MongoDB - Team knows MongoDB - Primarily document operations</p>"},{"location":"guide/core/queries/#basic-queries","title":"Basic Queries","text":"<pre><code># Find all\nresult = db.query(\"mongodb\", \"\"\"\n    db.User.find()\n\"\"\")\n\n# Find with filter\nresult = db.query(\"mongodb\", \"\"\"\n    db.User.find({name: 'Alice'})\n\"\"\")\n\n# Find with operators\nresult = db.query(\"mongodb\", \"\"\"\n    db.User.find({age: {$gt: 25}})\n\"\"\")\n\n# Projection\nresult = db.query(\"mongodb\", \"\"\"\n    db.User.find({}, {name: 1, email: 1})\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#aggregation-pipeline","title":"Aggregation Pipeline","text":"<pre><code># Group and count\nresult = db.query(\"mongodb\", \"\"\"\n    db.Product.aggregate([\n        {$group: {\n            _id: '$category',\n            count: {$sum: 1}\n        }}\n    ])\n\"\"\")\n\n# Match, group, sort\nresult = db.query(\"mongodb\", \"\"\"\n    db.User.aggregate([\n        {$match: {age: {$gt: 25}}},\n        {$group: {\n            _id: '$city',\n            avg_age: {$avg: '$age'}\n        }},\n        {$sort: {avg_age: -1}}\n    ])\n\"\"\")\n</code></pre>"},{"location":"guide/core/queries/#language-comparison","title":"Language Comparison","text":""},{"location":"guide/core/queries/#finding-users","title":"Finding Users","text":"<p>SQL: <pre><code>db.query(\"sql\", \"SELECT FROM User WHERE age &gt; 25\")\n</code></pre></p> <p>Cypher: <pre><code>db.query(\"cypher\", \"MATCH (u:User) WHERE u.age &gt; 25 RETURN u\")\n</code></pre></p> <p>Gremlin: <pre><code>db.query(\"gremlin\", \"g.V().hasLabel('User').has('age', gt(25))\")\n</code></pre></p> <p>MongoDB: <pre><code>db.query(\"mongodb\", \"db.User.find({age: {$gt: 25}})\")\n</code></pre></p>"},{"location":"guide/core/queries/#following-relationships","title":"Following Relationships","text":"<p>SQL: <pre><code>db.query(\"sql\", \"\"\"\n    SELECT expand(out('Follows'))\n    FROM User\n    WHERE name = 'Alice'\n\"\"\")\n</code></pre></p> <p>Cypher: <pre><code>db.query(\"cypher\", \"\"\"\n    MATCH (u:User {name: 'Alice'})-[:FOLLOWS]-&gt;(f)\n    RETURN f\n\"\"\")\n</code></pre></p> <p>Gremlin: <pre><code>db.query(\"gremlin\", \"\"\"\n    g.V().has('User', 'name', 'Alice').out('Follows')\n\"\"\")\n</code></pre></p>"},{"location":"guide/core/queries/#aggregation","title":"Aggregation","text":"<p>SQL: <pre><code>db.query(\"sql\", \"\"\"\n    SELECT category, count(*) as count\n    FROM Product\n    GROUP BY category\n\"\"\")\n</code></pre></p> <p>Cypher: <pre><code>db.query(\"cypher\", \"\"\"\n    MATCH (p:Product)\n    RETURN p.category, count(p) as count\n\"\"\")\n</code></pre></p> <p>Gremlin: <pre><code>db.query(\"gremlin\", \"\"\"\n    g.V().hasLabel('Product')\n        .group()\n        .by('category')\n        .by(count())\n\"\"\")\n</code></pre></p> <p>MongoDB: <pre><code>db.query(\"mongodb\", \"\"\"\n    db.Product.aggregate([\n        {$group: {_id: '$category', count: {$sum: 1}}}\n    ])\n\"\"\")\n</code></pre></p>"},{"location":"guide/core/queries/#query-optimization","title":"Query Optimization","text":""},{"location":"guide/core/queries/#use-indexes","title":"Use Indexes","text":"<pre><code># Create index first\nwith db.transaction():\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n    db.command(\"sql\", \"CREATE INDEX ON Product (category) NOTUNIQUE\")\n\n# Query with indexed fields\nresult = db.query(\"sql\", \"\"\"\n    SELECT FROM User\n    WHERE email = 'alice@example.com'\n\"\"\")\n# Uses index - fast!\n\nresult = db.query(\"sql\", \"\"\"\n    SELECT FROM Product\n    WHERE category = 'Electronics'\n\"\"\")\n# Uses index - fast!\n</code></pre>"},{"location":"guide/core/queries/#explain-plans","title":"EXPLAIN Plans","text":"<pre><code># Analyze query execution\nresult = db.query(\"sql\", \"\"\"\n    EXPLAIN\n    SELECT FROM User\n    WHERE email = 'alice@example.com'\n\"\"\")\n\nfor row in result:\n    print(row.to_dict())\n# Shows: index usage, estimated cost, execution plan\n</code></pre>"},{"location":"guide/core/queries/#limit-results","title":"Limit Results","text":"<pre><code># Bad: Load everything\nresult = db.query(\"sql\", \"SELECT FROM User\")\n# Could be millions of rows!\n\n# Good: Use LIMIT\nresult = db.query(\"sql\", \"SELECT FROM User LIMIT 100\")\n\n# Pagination\nresult = db.query(\"sql\", \"SELECT FROM User LIMIT 100 SKIP 200\")\n</code></pre>"},{"location":"guide/core/queries/#projection-select-specific-fields","title":"Projection (Select Specific Fields)","text":"<pre><code># Bad: Load all properties\nresult = db.query(\"sql\", \"SELECT FROM User\")\n# Loads everything!\n\n# Good: Project only needed fields\nresult = db.query(\"sql\", \"SELECT name, email FROM User\")\n# Much faster!\n</code></pre>"},{"location":"guide/core/queries/#batch-operations","title":"Batch Operations","text":"<pre><code># Bad: Many small queries\nfor user_id in user_ids:\n    result = db.query(\"sql\", f\"SELECT FROM User WHERE id = '{user_id}'\")\n    # 100 round trips!\n\n# Good: Single query with IN\nids_str = \"', '\".join(user_ids)\nresult = db.query(\"sql\", f\"SELECT FROM User WHERE id IN ['{ids_str}']\")\n# 1 round trip!\n\n# Better: Use parameters\nresult = db.query(\"sql\",\n    \"SELECT FROM User WHERE id IN :ids\",\n    {\"ids\": user_ids}\n)\n</code></pre>"},{"location":"guide/core/queries/#transaction-size","title":"Transaction Size","text":"<pre><code># Bad: Huge transaction\nwith db.transaction():\n    for i in range(1000000):\n        # Memory exhaustion!\n        pass\n\n# Good: Batch transactions\nbatch_size = 10000\nfor i in range(0, 1000000, batch_size):\n    with db.transaction():\n        for j in range(i, min(i + batch_size, 1000000)):\n            # Process batch\n            pass\n</code></pre>"},{"location":"guide/core/queries/#best-practices","title":"Best Practices","text":"<ol> <li>Use SQL for Most Queries: Most complete, best performance</li> <li>Use Cypher for Graph Patterns: More readable for relationships</li> <li>Always Use Parameters: Prevent SQL injection</li> <li>Create Indexes: For frequently queried fields</li> <li>Use EXPLAIN: Analyze slow queries</li> <li>Limit Results: Always use LIMIT in production</li> <li>Project Fields: Don't select * unless you need everything</li> <li>Batch Operations: Reduce round trips</li> <li>Right-Size Transactions: Not too big, not too small</li> <li>Test Performance: Profile with realistic data</li> </ol>"},{"location":"guide/core/queries/#common-patterns","title":"Common Patterns","text":""},{"location":"guide/core/queries/#pagination","title":"Pagination","text":"<pre><code>def paginate(db, page, page_size=20):\n    \"\"\"Paginate query results.\"\"\"\n    skip = page * page_size\n    result = db.query(\"sql\", \n        f\"SELECT FROM User ORDER BY name LIMIT {page_size} SKIP {skip}\")\n    return list(result)\n\n# Usage\npage_1 = paginate(db, 0)\npage_2 = paginate(db, 1)\n</code></pre>"},{"location":"guide/core/queries/#search-with-filters","title":"Search with Filters","text":"<pre><code>def search_users(db, name_filter=None, min_age=None, max_age=None):\n    \"\"\"Flexible search with optional filters.\"\"\"\n    conditions = []\n    params = {}\n\n    if name_filter:\n        conditions.append(\"name LIKE :name\")\n        params[\"name\"] = f\"%{name_filter}%\"\n\n    if min_age:\n        conditions.append(\"age &gt;= :min_age\")\n        params[\"min_age\"] = min_age\n\n    if max_age:\n        conditions.append(\"age &lt;= :max_age\")\n        params[\"max_age\"] = max_age\n\n    where_clause = \" AND \".join(conditions) if conditions else \"1=1\"\n    query = f\"SELECT FROM User WHERE {where_clause}\"\n\n    return db.query(\"sql\", query, params)\n\n# Usage\nresults = search_users(db, name_filter=\"Ali\", min_age=25, max_age=35)\n</code></pre>"},{"location":"guide/core/queries/#graph-recommendations","title":"Graph Recommendations","text":"<pre><code>def recommend_products(db, user_name, k=5):\n    \"\"\"Recommend products based on friends' purchases.\"\"\"\n    result = db.query(\"sql\", \"\"\"\n        SELECT \n            product.name,\n            count(*) as friend_purchases\n        FROM (\n            SELECT expand(out('Follows'))\n            FROM User\n            WHERE name = :name\n        ) as friends\n        LET product = friends.out('Purchased')\n        WHERE product NOT IN (\n            SELECT out('Purchased')\n            FROM User\n            WHERE name = :name\n        )\n        GROUP BY product\n        ORDER BY friend_purchases DESC\n        LIMIT :k\n    \"\"\", {\"name\": user_name, \"k\": k})\n\n    return [(row.get(\"name\"), row.get(\"friend_purchases\")) \n            for row in result]\n\n# Usage\nrecommendations = recommend_products(db, \"Alice\", k=5)\nfor product, count in recommendations:\n    print(f\"{product} ({count} friends bought this)\")\n</code></pre>"},{"location":"guide/core/queries/#see-also","title":"See Also","text":"<ul> <li>Database API Reference - query() and command() methods</li> <li>Results API Reference - Working with query results</li> <li>Transactions - Transaction management</li> <li>ArcadeDB SQL Reference - Official SQL documentation</li> </ul>"},{"location":"guide/core/transactions/","title":"Transactions","text":"<p>Comprehensive guide to transaction management in ArcadeDB Python bindings.</p>"},{"location":"guide/core/transactions/#overview","title":"Overview","text":"<p>ArcadeDB provides ACID-compliant transactions with automatic lifecycle management through Python context managers.</p> <p>Transaction Lifecycle: <pre><code>BEGIN \u2192 OPERATIONS \u2192 COMMIT (success) or ROLLBACK (failure)\n</code></pre></p> <p>Key Features:</p> <ul> <li>\u2705 Atomicity: All operations commit together or none commit</li> <li>\u2705 Consistency: Schema validation and constraint enforcement  </li> <li>\u2705 Isolation: Read committed isolation level</li> <li>\u2705 Durability: Changes persisted to WAL (Write-Ahead Log) on commit</li> </ul>"},{"location":"guide/core/transactions/#quick-start","title":"Quick Start","text":""},{"location":"guide/core/transactions/#context-manager-recommended","title":"Context Manager (Recommended)","text":"<pre><code>import arcadedb_embedded as arcadedb\n\ndb = arcadedb.open_database(\"./mydb\")\n\n# Automatic transaction management\nwith db.transaction():\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", \"Alice\")\n    vertex.set(\"email\", \"alice@example.com\")\n    vertex.save()\n\n    # If this block completes successfully \u2192 COMMIT\n    # If exception occurs \u2192 ROLLBACK\n</code></pre> <p>Why Context Manager?</p> <ul> <li>\u2705 Automatic commit on success</li> <li>\u2705 Automatic rollback on exception</li> <li>\u2705 Clean, Pythonic syntax</li> <li>\u2705 Prevents transaction leaks</li> </ul>"},{"location":"guide/core/transactions/#manual-control","title":"Manual Control","text":"<pre><code>db.begin()\ntry:\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", \"Bob\")\n    vertex.save()\n    db.commit()\nexcept Exception as e:\n    db.rollback()\n    raise\n</code></pre>"},{"location":"guide/core/transactions/#acid-guarantees","title":"ACID Guarantees","text":""},{"location":"guide/core/transactions/#atomicity","title":"Atomicity","text":"<p>All operations in a transaction are treated as a single unit:</p> <pre><code>with db.transaction():\n    # Create user\n    user = db.new_vertex(\"User\")\n    user.set(\"name\", \"Charlie\")\n    user.save()\n\n    # Create user's profile\n    profile = db.new_document(\"Profile\")\n    profile.set(\"bio\", \"Software Engineer\")\n    profile.save()\n\n    # Link them\n    edge = db.new_edge(\"HasProfile\", user, profile)\n    edge.save()\n\n    # Either ALL three operations succeed, or NONE do\n\n# If any operation fails, entire transaction rolls back\n</code></pre>"},{"location":"guide/core/transactions/#consistency","title":"Consistency","text":"<p>Schema validation enforced at transaction commit:</p> <pre><code># Create schema with constraints\nwith db.transaction():\n    db.command(\"sql\", \"CREATE VERTEX TYPE User\")\n    db.command(\"sql\", \"CREATE PROPERTY User.email STRING\")\n    db.command(\"sql\", \"CREATE INDEX ON User (email) UNIQUE\")\n\n# Constraint violation causes rollback\ntry:\n    with db.transaction():\n        user1 = db.new_vertex(\"User\")\n        user1.set(\"email\", \"same@example.com\")\n        user1.save()\n\n        user2 = db.new_vertex(\"User\")\n        user2.set(\"email\", \"same@example.com\")  # Duplicate!\n        user2.save()  # This will fail\nexcept Exception:\n    print(\"Transaction rolled back - unique constraint violated\")\n</code></pre>"},{"location":"guide/core/transactions/#isolation","title":"Isolation","text":"<p>Isolation Level: READ_COMMITTED (default)</p> <ul> <li>Transactions see only committed data</li> <li>Dirty reads are prevented</li> <li>Non-repeatable reads possible (data can change between reads)</li> </ul> <pre><code># Transaction A\nwith db.transaction():\n    result = db.query(\"sql\", \"SELECT FROM User WHERE name = 'Alice'\")\n    user = list(result)[0]\n\n    # Transaction B commits changes to Alice here\n\n    result2 = db.query(\"sql\", \"SELECT FROM User WHERE name = 'Alice'\")\n    user2 = list(result2)[0]\n\n    # user and user2 may have different data (non-repeatable read)\n</code></pre> <p>Available Isolation Levels:</p> <ul> <li><code>READ_COMMITTED</code> (default) - Prevents dirty reads</li> <li><code>REPEATABLE_READ</code> - Prevents dirty and non-repeatable reads</li> </ul> <p>Currently, Python bindings use the default (<code>READ_COMMITTED</code>). Custom isolation levels coming soon.</p>"},{"location":"guide/core/transactions/#durability","title":"Durability","text":"<p>Changes are persisted to Write-Ahead Log (WAL) on commit:</p> <pre><code>with db.transaction():\n    vertex = db.new_vertex(\"Data\")\n    vertex.set(\"value\", 42)\n    vertex.save()\n    # On successful exit, changes written to WAL\n    # Crash recovery uses WAL to restore state\n</code></pre> <p>WAL Configuration:</p> <p>ArcadeDB uses WAL for crash recovery. Configuration handled at database level:</p> <ul> <li>WAL entries written before commit</li> <li>Automatic recovery on database open</li> <li>Configurable flush strategy (sync, async)</li> </ul>"},{"location":"guide/core/transactions/#error-handling","title":"Error Handling","text":""},{"location":"guide/core/transactions/#automatic-rollback","title":"Automatic Rollback","text":"<p>Context manager automatically rolls back on any exception:</p> <pre><code>try:\n    with db.transaction():\n        vertex = db.new_vertex(\"User\")\n        vertex.set(\"name\", \"Dave\")\n        vertex.save()\n\n        raise ValueError(\"Something went wrong!\")\n        # ROLLBACK happens automatically\nexcept ValueError:\n    print(\"Transaction rolled back\")\n</code></pre>"},{"location":"guide/core/transactions/#explicit-rollback","title":"Explicit Rollback","text":"<pre><code>with db.transaction():\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", \"Eve\")\n    vertex.save()\n\n    # Check some condition\n    if not validate_user(vertex):\n        # Force rollback without raising exception\n        db.rollback()\n        return\n\n    # Continue with transaction\n</code></pre>"},{"location":"guide/core/transactions/#nested-transactions-not-supported","title":"Nested Transactions Not Supported","text":"<pre><code># \u2717 This will fail!\nwith db.transaction():\n    with db.transaction():  # ERROR: Transaction already active\n        pass\n\n# \u2713 Use sequential transactions instead\nwith db.transaction():\n    # First transaction\n    pass\n\nwith db.transaction():\n    # Second transaction\n    pass\n</code></pre>"},{"location":"guide/core/transactions/#transaction-conflicts","title":"Transaction Conflicts","text":"<p>Concurrent modifications can cause conflicts:</p> <pre><code>import time\n\ndef update_with_retry(db, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            with db.transaction():\n                result = db.query(\"sql\", \"SELECT FROM Counter WHERE name = 'global'\")\n                counter = list(result)[0]\n\n                count = counter.get(\"value\")\n                counter.set(\"value\", count + 1)\n                counter.save()\n\n                return count + 1\n        except Exception as e:\n            if \"concurrent modification\" in str(e).lower():\n                if attempt &lt; max_retries - 1:\n                    time.sleep(0.1 * (attempt + 1))  # Exponential backoff\n                    continue\n            raise\n\n    raise Exception(\"Max retries exceeded\")\n</code></pre>"},{"location":"guide/core/transactions/#transaction-patterns","title":"Transaction Patterns","text":""},{"location":"guide/core/transactions/#batch-operations","title":"Batch Operations","text":"<p>Process multiple items in batches:</p> <pre><code>def import_users(db, users, batch_size=1000):\n    for i in range(0, len(users), batch_size):\n        batch = users[i:i+batch_size]\n\n        with db.transaction():\n            for user_data in batch:\n                user = db.new_vertex(\"User\")\n                for key, value in user_data.items():\n                    user.set(key, value)\n                user.save()\n\n        print(f\"Imported batch {i//batch_size + 1}\")\n</code></pre>"},{"location":"guide/core/transactions/#conditional-commit","title":"Conditional Commit","text":"<pre><code>def create_user_if_valid(db, name, email):\n    with db.transaction():\n        # Check if email exists\n        result = db.query(\"sql\", \n            \"SELECT FROM User WHERE email = :email\",\n            {\"email\": email}\n        )\n\n        if result.has_next():\n            # Email exists - rollback\n            db.rollback()\n            return None\n\n        # Create user\n        user = db.new_vertex(\"User\")\n        user.set(\"name\", name)\n        user.set(\"email\", email)\n        user.save()\n\n        return user\n</code></pre>"},{"location":"guide/core/transactions/#long-running-operations","title":"Long-Running Operations","text":"<p>Split into smaller transactions to avoid locks:</p> <pre><code>def process_large_dataset(db, records):\n    batch_size = 1000\n    total = 0\n\n    for i in range(0, len(records), batch_size):\n        batch = records[i:i+batch_size]\n\n        # Each batch in separate transaction\n        with db.transaction():\n            for record in batch:\n                process_record(db, record)\n\n        total += len(batch)\n        print(f\"Processed {total}/{len(records)}\")\n\n        # Transaction committed, locks released\n</code></pre>"},{"location":"guide/core/transactions/#upsert-pattern","title":"Upsert Pattern","text":"<p>Insert or update based on existence:</p> <pre><code>def upsert_user(db, email, name):\n    with db.transaction():\n        result = db.query(\"sql\",\n            \"SELECT FROM User WHERE email = :email\",\n            {\"email\": email}\n        )\n\n        if result.has_next():\n            # Update existing\n            user = list(result)[0]\n            user.set(\"name\", name)\n            user.set(\"updated\", int(time.time()))\n            user.save()\n        else:\n            # Create new\n            user = db.new_vertex(\"User\")\n            user.set(\"email\", email)\n            user.set(\"name\", name)\n            user.set(\"created\", int(time.time()))\n            user.save()\n\n        return user\n</code></pre>"},{"location":"guide/core/transactions/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guide/core/transactions/#transaction-size","title":"Transaction Size","text":"<p>Rule of Thumb:</p> <ul> <li>Small transactions: &lt; 1,000 operations</li> <li>Medium transactions: 1,000 - 10,000 operations  </li> <li>Large transactions: 10,000+ operations (use batching)</li> </ul> <pre><code># \u2717 Too large - single transaction\nwith db.transaction():\n    for i in range(1_000_000):\n        vertex = db.new_vertex(\"Data\")\n        vertex.set(\"value\", i)\n        vertex.save()\n\n# \u2713 Better - batched transactions\nbatch_size = 10_000\nfor i in range(0, 1_000_000, batch_size):\n    with db.transaction():\n        for j in range(batch_size):\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"value\", i + j)\n            vertex.save()\n</code></pre>"},{"location":"guide/core/transactions/#lock-contention","title":"Lock Contention","text":"<p>Minimize time holding locks:</p> <pre><code># \u2717 External operations inside transaction\nwith db.transaction():\n    vertex = db.new_vertex(\"Data\")\n    vertex.set(\"value\", expensive_computation())  # Slow!\n    vertex.save()\n\n# \u2713 Compute before transaction\nvalue = expensive_computation()\nwith db.transaction():\n    vertex = db.new_vertex(\"Data\")\n    vertex.set(\"value\", value)\n    vertex.save()\n</code></pre>"},{"location":"guide/core/transactions/#read-vs-write-transactions","title":"Read vs Write Transactions","text":"<p>Queries outside transactions are read-only and more efficient:</p> <pre><code># \u2713 Read without transaction\nresult = db.query(\"sql\", \"SELECT FROM User WHERE active = true\")\nfor user in result:\n    print(user.get(\"name\"))\n\n# \u2717 Unnecessary transaction for reads\nwith db.transaction():\n    result = db.query(\"sql\", \"SELECT FROM User WHERE active = true\")\n    for user in result:\n        print(user.get(\"name\"))\n</code></pre>"},{"location":"guide/core/transactions/#transaction-overhead","title":"Transaction Overhead","text":"<p>Each transaction has overhead (~100\u03bcs). For high-throughput scenarios, batch operations:</p> <pre><code>import time\n\n# Measure overhead\ndef benchmark_transactions(db, count):\n    # Individual transactions\n    start = time.time()\n    for i in range(count):\n        with db.transaction():\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"value\", i)\n            vertex.save()\n    individual_time = time.time() - start\n\n    # Batched transaction\n    start = time.time()\n    with db.transaction():\n        for i in range(count):\n            vertex = db.new_vertex(\"Data\")\n            vertex.set(\"value\", i)\n            vertex.save()\n    batched_time = time.time() - start\n\n    print(f\"Individual: {individual_time:.2f}s\")\n    print(f\"Batched: {batched_time:.2f}s\")\n    print(f\"Speedup: {individual_time/batched_time:.1f}x\")\n\nbenchmark_transactions(db, 1000)\n# Individual: 0.85s\n# Batched: 0.08s\n# Speedup: 10.6x\n</code></pre>"},{"location":"guide/core/transactions/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"guide/core/transactions/#transaction-checkpoint","title":"Transaction Checkpoint","text":"<p>Save progress during long operations:</p> <pre><code>def import_with_checkpoints(db, records, checkpoint_file=\"checkpoint.txt\"):\n    batch_size = 1000\n\n    # Load last checkpoint\n    start_idx = 0\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file) as f:\n            start_idx = int(f.read())\n\n    for i in range(start_idx, len(records), batch_size):\n        batch = records[i:i+batch_size]\n\n        try:\n            with db.transaction():\n                for record in batch:\n                    import_record(db, record)\n\n            # Save checkpoint\n            with open(checkpoint_file, \"w\") as f:\n                f.write(str(i + batch_size))\n\n        except Exception as e:\n            print(f\"Failed at batch {i}: {e}\")\n            raise\n</code></pre>"},{"location":"guide/core/transactions/#transaction-hooks","title":"Transaction Hooks","text":"<p>Execute logic on commit/rollback:</p> <pre><code>class TransactionWithHooks:\n    def __init__(self, db, on_commit=None, on_rollback=None):\n        self.db = db\n        self.on_commit = on_commit\n        self.on_rollback = on_rollback\n\n    def __enter__(self):\n        self.db.begin()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is None:\n            self.db.commit()\n            if self.on_commit:\n                self.on_commit()\n        else:\n            self.db.rollback()\n            if self.on_rollback:\n                self.on_rollback()\n\n# Usage\ndef notify_success():\n    print(\"Transaction committed!\")\n\ndef notify_failure():\n    print(\"Transaction rolled back!\")\n\nwith TransactionWithHooks(db, on_commit=notify_success, on_rollback=notify_failure):\n    # Operations here\n    pass\n</code></pre>"},{"location":"guide/core/transactions/#distributed-transaction-pattern","title":"Distributed Transaction Pattern","text":"<p>For operations across multiple databases (use multiprocessing):</p> <pre><code>from multiprocessing import Process, Queue\n\ndef transactional_operation(db_path, data, result_queue):\n    db = arcadedb.open_database(db_path)\n    try:\n        with db.transaction():\n            # Perform operations\n            result = process_data(db, data)\n            result_queue.put((\"success\", result))\n    except Exception as e:\n        result_queue.put((\"error\", str(e)))\n    finally:\n        db.close()\n\ndef distributed_transaction(db_paths, data_list):\n    result_queue = Queue()\n    processes = []\n\n    # Start all processes\n    for db_path, data in zip(db_paths, data_list):\n        p = Process(target=transactional_operation, \n                   args=(db_path, data, result_queue))\n        p.start()\n        processes.append(p)\n\n    # Wait for all\n    for p in processes:\n        p.join()\n\n    # Check results\n    results = []\n    while not result_queue.empty():\n        results.append(result_queue.get())\n\n    return results\n</code></pre>"},{"location":"guide/core/transactions/#best-practices","title":"Best Practices","text":""},{"location":"guide/core/transactions/#1-always-use-context-managers","title":"1. Always Use Context Managers","text":"<pre><code># \u2713 Recommended\nwith db.transaction():\n    # Operations\n\n# \u2717 Avoid manual control unless necessary\ndb.begin()\ntry:\n    # Operations\n    db.commit()\nexcept:\n    db.rollback()\n</code></pre>"},{"location":"guide/core/transactions/#2-keep-transactions-short","title":"2. Keep Transactions Short","text":"<pre><code># \u2713 Short transaction\nwith db.transaction():\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"name\", name)\n    vertex.save()\n\n# \u2717 Long-running transaction\nwith db.transaction():\n    time.sleep(10)  # Holds locks!\n</code></pre>"},{"location":"guide/core/transactions/#3-dont-ignore-exceptions","title":"3. Don't Ignore Exceptions","text":"<pre><code># \u2717 Silently catch exceptions\ntry:\n    with db.transaction():\n        # Operations\nexcept:\n    pass  # Don't do this!\n\n# \u2713 Log and handle properly\nimport logging\n\ntry:\n    with db.transaction():\n        # Operations\nexcept Exception as e:\n    logging.error(f\"Transaction failed: {e}\")\n    raise\n</code></pre>"},{"location":"guide/core/transactions/#4-batch-operations","title":"4. Batch Operations","text":"<pre><code># \u2713 Batch for efficiency\nbatch_size = 1000\nfor i in range(0, len(items), batch_size):\n    with db.transaction():\n        for item in items[i:i+batch_size]:\n            process_item(db, item)\n</code></pre>"},{"location":"guide/core/transactions/#5-retry-on-conflicts","title":"5. Retry on Conflicts","text":"<pre><code>def retry_transaction(db, operation, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            with db.transaction():\n                return operation(db)\n        except Exception as e:\n            if \"concurrent\" in str(e).lower() and attempt &lt; max_retries - 1:\n                time.sleep(0.1 * (2 ** attempt))\n                continue\n            raise\n</code></pre>"},{"location":"guide/core/transactions/#6-validate-before-commit","title":"6. Validate Before Commit","text":"<pre><code>with db.transaction():\n    vertex = db.new_vertex(\"User\")\n    vertex.set(\"email\", email)\n\n    # Validate\n    if not is_valid_email(email):\n        db.rollback()\n        raise ValueError(\"Invalid email\")\n\n    vertex.save()\n</code></pre>"},{"location":"guide/core/transactions/#7-monitor-transaction-duration","title":"7. Monitor Transaction Duration","text":"<pre><code>import time\n\ndef monitored_transaction(db, operation, max_duration=5.0):\n    start = time.time()\n    with db.transaction():\n        result = operation(db)\n        duration = time.time() - start\n\n        if duration &gt; max_duration:\n            logging.warning(f\"Long transaction: {duration:.2f}s\")\n\n        return result\n</code></pre>"},{"location":"guide/core/transactions/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"guide/core/transactions/#nested-transactions","title":"\u274c Nested Transactions","text":"<pre><code># \u2717 Will fail!\nwith db.transaction():\n    with db.transaction():\n        pass\n</code></pre>"},{"location":"guide/core/transactions/#transaction-leaks","title":"\u274c Transaction Leaks","text":"<pre><code># \u2717 Transaction never committed/rolled back\ndb.begin()\n# ... operations ...\n# Forgot to commit or rollback!\n</code></pre>"},{"location":"guide/core/transactions/#large-transactions","title":"\u274c Large Transactions","text":"<pre><code># \u2717 Too much in single transaction\nwith db.transaction():\n    for i in range(10_000_000):  # Too many!\n        vertex = db.new_vertex(\"Data\")\n        vertex.save()\n</code></pre>"},{"location":"guide/core/transactions/#external-operations-inside-transaction","title":"\u274c External Operations Inside Transaction","text":"<pre><code># \u2717 Network call while holding locks\nwith db.transaction():\n    vertex = db.new_vertex(\"Data\")\n    vertex.set(\"value\", requests.get(\"http://api.example.com/data\").json())\n    vertex.save()\n</code></pre>"},{"location":"guide/core/transactions/#debugging","title":"Debugging","text":""},{"location":"guide/core/transactions/#enable-transaction-logging","title":"Enable Transaction Logging","text":"<pre><code>import logging\n\n# Enable debug logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nwith db.transaction():\n    # Transaction events will be logged\n    pass\n</code></pre>"},{"location":"guide/core/transactions/#transaction-statistics","title":"Transaction Statistics","text":"<pre><code>def transaction_stats(db, operation):\n    import time\n\n    start = time.time()\n\n    with db.transaction():\n        result = operation(db)\n\n    duration = time.time() - start\n\n    print(f\"Transaction completed in {duration:.3f}s\")\n    return result\n</code></pre>"},{"location":"guide/core/transactions/#monitor-active-transactions","title":"Monitor Active Transactions","text":"<pre><code># Check if transaction is active\nif db.is_transaction_active():\n    print(\"Transaction in progress\")\nelse:\n    print(\"No active transaction\")\n</code></pre>"},{"location":"guide/core/transactions/#see-also","title":"See Also","text":"<ul> <li>Transactions API Reference - Complete API documentation</li> <li>Database API - Database operations</li> <li>Error Handling - Exception handling</li> <li>Performance Guide - Optimization strategies</li> </ul>"}]}